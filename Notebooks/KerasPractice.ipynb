{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "try:\n",
    "    import deephyper\n",
    "    print(deephyper.__version__)\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install deephyper\n",
    "\n",
    "try:\n",
    "    import ray\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install ray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = str(3)\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == \"GPU\"]\n",
    "\n",
    "\n",
    "n_gpus = len(get_available_gpus())\n",
    "if n_gpus > 1:\n",
    "    n_gpus -= 1\n",
    "\n",
    "is_gpu_available = n_gpus > 0\n",
    "\n",
    "if is_gpu_available:\n",
    "    print(f\"{n_gpus} GPU{'s are' if n_gpus > 1 else ' is'} available.\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "    dataframe = pd.read_csv(file_url)\n",
    "\n",
    "    val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "    train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "    return train_dataframe, val_dataframe\n",
    "\n",
    "\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = tf.keras.layers.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = (\n",
    "        tf.keras.layers.StringLookup if is_string else tf.keras.layers.IntegerLookup\n",
    "    )\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model: tf.keras.Model) -> dict:\n",
    "    \"\"\"Evaluate the number of parameters of a Keras model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): a Keras model.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with the number of trainable ``\"num_parameters_train\"`` and\n",
    "        non-trainable parameters ``\"num_parameters\"``.\n",
    "    \"\"\"\n",
    "\n",
    "    def count_or_null(p):\n",
    "        try:\n",
    "            return K.count_params(p)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    num_parameters_train = int(\n",
    "        np.sum([count_or_null(p) for p in model.trainable_weights])\n",
    "    )\n",
    "    num_parameters = int(\n",
    "        np.sum([count_or_null(p) for p in model.non_trainable_weights])\n",
    "    )\n",
    "    return {\n",
    "        \"num_parameters\": num_parameters,\n",
    "        \"num_parameters_train\": num_parameters_train,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config: dict):\n",
    "    tf.autograph.set_verbosity(0)\n",
    "    # Load data and split into validation set\n",
    "    train_dataframe, val_dataframe = load_data()\n",
    "    train_ds = dataframe_to_dataset(train_dataframe)\n",
    "    val_ds = dataframe_to_dataset(val_dataframe)\n",
    "    print(type(val_ds))\n",
    "    train_ds = train_ds.batch(config[\"batch_size\"])\n",
    "    val_ds = val_ds.batch(config[\"batch_size\"])\n",
    "\n",
    "    # Categorical features encoded as integers\n",
    "    sex = tf.keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "    cp = tf.keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "    fbs = tf.keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "    restecg = tf.keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "    exang = tf.keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "    ca = tf.keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "    # Categorical feature encoded as string\n",
    "    thal = tf.keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "    # Numerical features\n",
    "    age = tf.keras.Input(shape=(1,), name=\"age\")\n",
    "    trestbps = tf.keras.Input(shape=(1,), name=\"trestbps\")\n",
    "    chol = tf.keras.Input(shape=(1,), name=\"chol\")\n",
    "    thalach = tf.keras.Input(shape=(1,), name=\"thalach\")\n",
    "    oldpeak = tf.keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "    slope = tf.keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "    all_inputs = [\n",
    "        sex,\n",
    "        cp,\n",
    "        fbs,\n",
    "        restecg,\n",
    "        exang,\n",
    "        ca,\n",
    "        thal,\n",
    "        age,\n",
    "        trestbps,\n",
    "        chol,\n",
    "        thalach,\n",
    "        oldpeak,\n",
    "        slope,\n",
    "    ]\n",
    "\n",
    "    # Integer categorical features\n",
    "    sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "    cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "    fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "    restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "    exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "    ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "    # String categorical features\n",
    "    thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "    # Numerical features\n",
    "    age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "    trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "    chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "    thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "    oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "    slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "    all_features = tf.keras.layers.concatenate(\n",
    "        [\n",
    "            sex_encoded,\n",
    "            cp_encoded,\n",
    "            fbs_encoded,\n",
    "            restecg_encoded,\n",
    "            exang_encoded,\n",
    "            slope_encoded,\n",
    "            ca_encoded,\n",
    "            thal_encoded,\n",
    "            age_encoded,\n",
    "            trestbps_encoded,\n",
    "            chol_encoded,\n",
    "            thalach_encoded,\n",
    "            oldpeak_encoded,\n",
    "        ]\n",
    "    )\n",
    "    x = tf.keras.layers.Dense(config[\"units\"], activation=config[\"activation\"])(\n",
    "        all_features\n",
    "    )\n",
    "    x = tf.keras.layers.Dropout(config[\"dropout_rate\"])(x)\n",
    "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=config[\"learning_rate\"])\n",
    "    model.compile(optimizer, \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=config[\"num_epochs\"], validation_data=val_ds, verbose=0\n",
    "    )\n",
    "\n",
    "    objective = history.history[\"val_accuracy\"][-1]\n",
    "    metadata = {\n",
    "        \"loss\": history.history[\"loss\"],\n",
    "        \"val_loss\": history.history[\"val_loss\"],\n",
    "        \"accuracy\": history.history[\"accuracy\"],\n",
    "        \"val_accuracy\": history.history[\"val_accuracy\"],\n",
    "    }\n",
    "    metadata = {k:json.dumps(v) for k,v in metadata.items()}\n",
    "    metadata.update(count_params(model))\n",
    "\n",
    "    return {\"objective\": objective, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"units\": 32,\n",
    "    \"num_epochs\": 50,\n",
    "    \"activation\": \"relu\",\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.shuffle_op._ShuffleDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 0.8032786846160889,\n",
       " 'metadata': {'loss': '[0.6590251326560974, 0.46409645676612854, 0.400582492351532, 0.3622403144836426, 0.3443019390106201, 0.29800042510032654, 0.31638312339782715, 0.2848178744316101, 0.2628200352191925, 0.28951215744018555, 0.23098239302635193, 0.2705039083957672, 0.28956982493400574, 0.25219056010246277, 0.2243718057870865, 0.2326989322900772, 0.21913976967334747, 0.22717320919036865, 0.21675658226013184, 0.22217915952205658, 0.2140892893075943, 0.21859543025493622, 0.2243438959121704, 0.18741491436958313, 0.19602732360363007, 0.20250175893306732, 0.1748477667570114, 0.18798236548900604, 0.1608825922012329, 0.1926903873682022, 0.18271303176879883, 0.16100607812404633, 0.18716049194335938, 0.1611517071723938, 0.16545140743255615, 0.16983340680599213, 0.14234162867069244, 0.16992168128490448, 0.1758517324924469, 0.15040525794029236, 0.14620423316955566, 0.1430954784154892, 0.1451125144958496, 0.12721391022205353, 0.12883782386779785, 0.12680873274803162, 0.13117288053035736, 0.12896408140659332, 0.11847173422574997, 0.12423574924468994]',\n",
       "  'val_loss': '[0.4360072910785675, 0.4046685993671417, 0.42288926243782043, 0.41884565353393555, 0.4139311611652374, 0.4104953110218048, 0.40438932180404663, 0.4016342759132385, 0.4051443040370941, 0.41233518719673157, 0.4156378507614136, 0.4019152522087097, 0.3904659152030945, 0.3902549147605896, 0.38655799627304077, 0.39668983221054077, 0.3967687785625458, 0.3901318609714508, 0.4022360146045685, 0.40350058674812317, 0.3940865993499756, 0.3886086344718933, 0.3802602291107178, 0.36748215556144714, 0.37296435236930847, 0.3822871446609497, 0.3837895691394806, 0.4006149172782898, 0.42002174258232117, 0.4167543053627014, 0.4120829105377197, 0.41913023591041565, 0.41753968596458435, 0.3884618878364563, 0.3995603024959564, 0.395020991563797, 0.41185441613197327, 0.4234788119792938, 0.4233190417289734, 0.4143427312374115, 0.4012167751789093, 0.40453577041625977, 0.42259129881858826, 0.4670085608959198, 0.4878649115562439, 0.47119760513305664, 0.4677432179450989, 0.48090794682502747, 0.4896812438964844, 0.49840351939201355]',\n",
       "  'accuracy': '[0.64462810754776, 0.8057851195335388, 0.8223140239715576, 0.8429751992225647, 0.8719007968902588, 0.8677685856819153, 0.8636363744735718, 0.8842975497245789, 0.8760330677032471, 0.8719007968902588, 0.9049586653709412, 0.8677685856819153, 0.8760330677032471, 0.8966942429542542, 0.8966942429542542, 0.8884297609329224, 0.93388432264328, 0.8884297609329224, 0.9173553586006165, 0.9173553586006165, 0.9173553586006165, 0.9173553586006165, 0.8925619721412659, 0.9256198406219482, 0.9173553586006165, 0.9214876294136047, 0.9256198406219482, 0.9214876294136047, 0.9173553586006165, 0.9297520518302917, 0.913223147392273, 0.9256198406219482, 0.913223147392273, 0.93388432264328, 0.9214876294136047, 0.9214876294136047, 0.9504132270812988, 0.9214876294136047, 0.9214876294136047, 0.9214876294136047, 0.9380165338516235, 0.9462810158729553, 0.942148745059967, 0.93388432264328, 0.942148745059967, 0.9504132270812988, 0.942148745059967, 0.942148745059967, 0.9462810158729553, 0.942148745059967]',\n",
       "  'val_accuracy': '[0.7704917788505554, 0.7868852615356445, 0.8360655903816223, 0.8196721076965332, 0.8360655903816223, 0.8196721076965332, 0.8196721076965332, 0.8360655903816223, 0.8196721076965332, 0.8196721076965332, 0.8032786846160889, 0.7868852615356445, 0.8032786846160889, 0.8032786846160889, 0.8032786846160889, 0.8032786846160889, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.7868852615356445, 0.7868852615356445, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.8196721076965332, 0.8032786846160889, 0.8196721076965332, 0.8032786846160889, 0.7868852615356445, 0.8196721076965332, 0.8032786846160889, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.8032786846160889]',\n",
       "  'num_parameters': 18,\n",
       "  'num_parameters_train': 1217}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation, Type: Categorical, Choices: {elu, gelu, hard_sigmoid, linear, relu, selu, sigmoid, softplus, softsign, swish, tanh}, Default: relu\n",
       "    batch_size, Type: UniformInteger, Range: [8, 256], Default: 32, on log-scale\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.5\n",
       "    learning_rate, Type: UniformFloat, Range: [1e-05, 0.01], Default: 0.001, on log-scale\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 50\n",
       "    units, Type: UniformInteger, Range: [8, 128], Default: 32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deephyper.problem import HpProblem\n",
    "\n",
    "\n",
    "# Creation of an hyperparameter problem\n",
    "problem = HpProblem()\n",
    "\n",
    "# Discrete hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((8, 128), \"units\", default_value=32)\n",
    "problem.add_hyperparameter((10, 100), \"num_epochs\", default_value=50)\n",
    "\n",
    "\n",
    "# Categorical hyperparameter (sampled with uniform prior)\n",
    "ACTIVATIONS = [\n",
    "    \"elu\", \"gelu\", \"hard_sigmoid\", \"linear\", \"relu\", \"selu\",\n",
    "    \"sigmoid\", \"softplus\", \"softsign\", \"swish\", \"tanh\",\n",
    "]\n",
    "problem.add_hyperparameter(ACTIVATIONS, \"activation\", default_value=\"relu\")\n",
    "\n",
    "\n",
    "# Real hyperparameter (sampled with uniform prior)\n",
    "problem.add_hyperparameter((0.0, 0.6), \"dropout_rate\", default_value=0.5)\n",
    "\n",
    "\n",
    "# Discrete and Real hyperparameters (sampled with log-uniform)\n",
    "problem.add_hyperparameter((8, 256, \"log-uniform\"), \"batch_size\", default_value=32)\n",
    "problem.add_hyperparameter((1e-5, 1e-2, \"log-uniform\"), \"learning_rate\", default_value=1e-3)\n",
    "\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Default Configuration:  0.820\n",
      "Metadata Default Configuration\n",
      "\t- loss: [0.6449450850486755, 0.6258721351623535, 0.5693280696868896, 0.5669292211532593, 0.5373427271842957, 0.5173834562301636, 0.5023466944694519, 0.473899781703949, 0.4907035529613495, 0.457693874835968, 0.46679970622062683, 0.45268362760543823, 0.4380912184715271, 0.42332226037979126, 0.3996010422706604, 0.4230843186378479, 0.3641856610774994, 0.36569902300834656, 0.41107380390167236, 0.3936554193496704, 0.361078679561615, 0.37040218710899353, 0.34861424565315247, 0.37382614612579346, 0.3762359023094177, 0.3746526539325714, 0.3527545630931854, 0.3465075194835663, 0.3395349085330963, 0.3229503929615021, 0.3385264277458191, 0.3326880931854248, 0.3275114893913269, 0.33196547627449036, 0.30965518951416016, 0.34289878606796265, 0.30882149934768677, 0.33752453327178955, 0.3196878731250763, 0.3316396474838257, 0.3186350464820862, 0.30759963393211365, 0.30333226919174194, 0.30026713013648987, 0.294312447309494, 0.3011039197444916, 0.27603453397750854, 0.2769354581832886, 0.30510860681533813, 0.2878566384315491]\n",
      "\t- val_loss: [0.5701069831848145, 0.5279152393341064, 0.4984595775604248, 0.47368139028549194, 0.4548039138317108, 0.4409060478210449, 0.4291919469833374, 0.41859856247901917, 0.4101817309856415, 0.4030006527900696, 0.39747369289398193, 0.3936786949634552, 0.3896327316761017, 0.38692617416381836, 0.38450905680656433, 0.38271564245224, 0.3817574977874756, 0.38003990054130554, 0.3791128695011139, 0.37783339619636536, 0.3795972764492035, 0.3778615891933441, 0.37937942147254944, 0.380402535200119, 0.38106831908226013, 0.3802776336669922, 0.3796820044517517, 0.3788146376609802, 0.3788778483867645, 0.3799990117549896, 0.38000544905662537, 0.3806378245353699, 0.38114434480667114, 0.38202643394470215, 0.3818359375, 0.382071316242218, 0.3817223012447357, 0.38187745213508606, 0.38162511587142944, 0.381274938583374, 0.3801060616970062, 0.37978672981262207, 0.38080787658691406, 0.3829289674758911, 0.3838827610015869, 0.38597071170806885, 0.38675636053085327, 0.3882450759410858, 0.3873905837535858, 0.3880958557128906]\n",
      "\t- accuracy: [0.6074380278587341, 0.6900826692581177, 0.702479362487793, 0.6983470916748047, 0.7066115736961365, 0.7438016533851624, 0.7685950398445129, 0.7851239442825317, 0.7561983466148376, 0.7727272510528564, 0.7809917330741882, 0.8057851195335388, 0.8099173307418823, 0.7809917330741882, 0.8347107172012329, 0.8099173307418823, 0.8677685856819153, 0.8305785059928894, 0.7933884263038635, 0.8264462947845459, 0.8347107172012329, 0.85537189245224, 0.8264462947845459, 0.8264462947845459, 0.8223140239715576, 0.8305785059928894, 0.8636363744735718, 0.8388429880142212, 0.8677685856819153, 0.8842975497245789, 0.8512396812438965, 0.8512396812438965, 0.8429751992225647, 0.8512396812438965, 0.8801652789115906, 0.8512396812438965, 0.8636363744735718, 0.8471074104309082, 0.8719007968902588, 0.85537189245224, 0.8884297609329224, 0.8760330677032471, 0.8760330677032471, 0.8636363744735718, 0.8595041036605835, 0.8719007968902588, 0.8884297609329224, 0.8801652789115906, 0.8677685856819153, 0.8842975497245789]\n",
      "\t- val_accuracy: [0.7540983557701111, 0.7540983557701111, 0.7377049326896667, 0.7704917788505554, 0.8032786846160889, 0.8196721076965332, 0.7868852615356445, 0.7868852615356445, 0.8032786846160889, 0.8032786846160889, 0.8032786846160889, 0.8196721076965332, 0.8360655903816223, 0.8360655903816223, 0.8360655903816223, 0.8360655903816223, 0.8360655903816223, 0.8360655903816223, 0.8524590134620667, 0.8524590134620667, 0.8524590134620667, 0.8524590134620667, 0.868852436542511, 0.8524590134620667, 0.8524590134620667, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.8524590134620667, 0.8524590134620667, 0.8524590134620667, 0.8524590134620667, 0.8360655903816223, 0.8360655903816223, 0.8196721076965332, 0.8196721076965332, 0.8196721076965332, 0.8196721076965332, 0.8196721076965332]\n",
      "\t- num_parameters: 18\n",
      "\t- num_parameters_train: 1217\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "# We launch the Ray run-time depending of the detected local ressources\n",
    "# and execute the `run` function with the default configuration\n",
    "# WARNING: in the case of GPUs it is important to follow this scheme\n",
    "# to avoid multiple processes (Ray workers vs current process) to lock\n",
    "# the same GPU.\n",
    "if is_gpu_available:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=n_gpus, num_gpus=n_gpus, log_to_driver=False)\n",
    "\n",
    "    run_default = ray.remote(num_cpus=1, num_gpus=1)(run)\n",
    "    out = ray.get(run_default.remote(problem.default_configuration))\n",
    "else:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=1, log_to_driver=False)\n",
    "    run_default = run\n",
    "    out = run_default(problem.default_configuration)\n",
    "\n",
    "objective_default = out[\"objective\"]\n",
    "metadata_default = out[\"metadata\"]\n",
    "\n",
    "print(f\"Accuracy Default Configuration:  {objective_default:.3f}\")\n",
    "\n",
    "print(\"Metadata Default Configuration\")\n",
    "for k,v in out[\"metadata\"].items():\n",
    "    print(f\"\\t- {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x301e27430>]}\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import TqdmCallback\n",
    "\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [TqdmCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function,\n",
    "        method=\"ray\",\n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "\n",
    "    return evaluator\n",
    "\n",
    "evaluator_1 = get_evaluator(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Results file already exists, it will be renamed to /Users/victorsu-ortiz/Desktop/ORNL_Summer/results_20240702-135055.csv\n"
     ]
    }
   ],
   "source": [
    "from deephyper.search.hps import CBO\n",
    "# Uncomment the following line to show the arguments of CBO.\n",
    "# help(CBO)\n",
    "# Instanciate the search with the problem and the evaluator that we created before\n",
    "search = CBO(problem, evaluator_1, initial_points=[problem.default_configuration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c513677a3f4d9482c95747e1dcd088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = search.search(max_evals=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "      <th>m:loss</th>\n",
       "      <th>m:val_loss</th>\n",
       "      <th>m:accuracy</th>\n",
       "      <th>m:val_accuracy</th>\n",
       "      <th>m:num_parameters</th>\n",
       "      <th>m:num_parameters_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0</td>\n",
       "      <td>3.834054</td>\n",
       "      <td>5.947541</td>\n",
       "      <td>[0.7808094620704651, 0.7111438512802124, 0.646...</td>\n",
       "      <td>[0.702677845954895, 0.6320067644119263, 0.5747...</td>\n",
       "      <td>[0.4752066135406494, 0.5619834661483765, 0.599...</td>\n",
       "      <td>[0.49180328845977783, 0.6721311211585999, 0.77...</td>\n",
       "      <td>18</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gelu</td>\n",
       "      <td>14</td>\n",
       "      <td>0.361774</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>93</td>\n",
       "      <td>42</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>1</td>\n",
       "      <td>6.007420</td>\n",
       "      <td>8.693748</td>\n",
       "      <td>[0.6810137033462524, 0.6927006244659424, 0.706...</td>\n",
       "      <td>[0.6666766405105591, 0.6627156138420105, 0.658...</td>\n",
       "      <td>[0.5785123705863953, 0.5247933864593506, 0.512...</td>\n",
       "      <td>[0.5737704634666443, 0.5901639461517334, 0.622...</td>\n",
       "      <td>18</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>220</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>2</td>\n",
       "      <td>8.714586</td>\n",
       "      <td>10.530900</td>\n",
       "      <td>[0.801559329032898, 0.8501983880996704, 0.7510...</td>\n",
       "      <td>[0.7569047212600708, 0.7465746998786926, 0.736...</td>\n",
       "      <td>[0.5247933864593506, 0.42148759961128235, 0.52...</td>\n",
       "      <td>[0.44262295961380005, 0.4590163826942444, 0.47...</td>\n",
       "      <td>18</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softsign</td>\n",
       "      <td>231</td>\n",
       "      <td>0.351987</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>48</td>\n",
       "      <td>84</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>3</td>\n",
       "      <td>10.551754</td>\n",
       "      <td>11.826193</td>\n",
       "      <td>[0.6304690837860107, 0.6313081979751587, 0.628...</td>\n",
       "      <td>[0.562753438949585, 0.5581142902374268, 0.5539...</td>\n",
       "      <td>[0.6611570119857788, 0.6900826692581177, 0.665...</td>\n",
       "      <td>[0.7868852615356445, 0.7868852615356445, 0.786...</td>\n",
       "      <td>18</td>\n",
       "      <td>3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elu</td>\n",
       "      <td>46</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>4</td>\n",
       "      <td>11.847148</td>\n",
       "      <td>13.114381</td>\n",
       "      <td>[0.8530883193016052, 0.8459160327911377, 0.845...</td>\n",
       "      <td>[0.8290221691131592, 0.826231062412262, 0.8235...</td>\n",
       "      <td>[0.28099173307418823, 0.2851239740848541, 0.29...</td>\n",
       "      <td>[0.37704917788505554, 0.37704917788505554, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>71</td>\n",
       "      <td>0.253341</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>5</td>\n",
       "      <td>13.136196</td>\n",
       "      <td>14.563797</td>\n",
       "      <td>[0.658219039440155, 0.5700154304504395, 0.5358...</td>\n",
       "      <td>[0.5507251620292664, 0.4919049143791199, 0.458...</td>\n",
       "      <td>[0.5909090638160706, 0.7355371713638306, 0.719...</td>\n",
       "      <td>[0.7868852615356445, 0.8032786846160889, 0.786...</td>\n",
       "      <td>18</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>softsign</td>\n",
       "      <td>250</td>\n",
       "      <td>0.344377</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>6</td>\n",
       "      <td>14.585100</td>\n",
       "      <td>15.821577</td>\n",
       "      <td>[0.7235867381095886, 0.7136470675468445, 0.738...</td>\n",
       "      <td>[0.7078008651733398, 0.7073135375976562, 0.706...</td>\n",
       "      <td>[0.5082644820213318, 0.5413222908973694, 0.508...</td>\n",
       "      <td>[0.5409836173057556, 0.5409836173057556, 0.540...</td>\n",
       "      <td>18</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>softplus</td>\n",
       "      <td>220</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>7</td>\n",
       "      <td>15.843169</td>\n",
       "      <td>17.278762</td>\n",
       "      <td>[0.944303572177887, 0.9194084405899048, 0.8835...</td>\n",
       "      <td>[0.8775652050971985, 0.8581626415252686, 0.839...</td>\n",
       "      <td>[0.32231405377388, 0.32231405377388, 0.3677685...</td>\n",
       "      <td>[0.2295081913471222, 0.21311475336551666, 0.22...</td>\n",
       "      <td>18</td>\n",
       "      <td>4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>57</td>\n",
       "      <td>0.160272</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>8</td>\n",
       "      <td>17.409882</td>\n",
       "      <td>18.788312</td>\n",
       "      <td>[0.5765562653541565, 0.4299267530441284, 0.374...</td>\n",
       "      <td>[0.44439399242401123, 0.3810850977897644, 0.37...</td>\n",
       "      <td>[0.7066115736961365, 0.8140496015548706, 0.809...</td>\n",
       "      <td>[0.7704917788505554, 0.8196721076965332, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>31</td>\n",
       "      <td>0.334903</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>9</td>\n",
       "      <td>18.809638</td>\n",
       "      <td>20.553262</td>\n",
       "      <td>[1.1083784103393555, 1.0162237882614136, 0.923...</td>\n",
       "      <td>[1.0996410846710205, 1.000662922859192, 0.9125...</td>\n",
       "      <td>[0.3305785059928894, 0.3388429880142212, 0.413...</td>\n",
       "      <td>[0.32786884903907776, 0.39344263076782227, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>elu</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021621</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>74</td>\n",
       "      <td>91</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>10</td>\n",
       "      <td>20.639394</td>\n",
       "      <td>22.755311</td>\n",
       "      <td>[0.7378655076026917, 0.6833291053771973, 0.628...</td>\n",
       "      <td>[0.6795907020568848, 0.6176944971084595, 0.568...</td>\n",
       "      <td>[0.43388429284095764, 0.5743801593780518, 0.68...</td>\n",
       "      <td>[0.5245901346206665, 0.6721311211585999, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linear</td>\n",
       "      <td>35</td>\n",
       "      <td>0.289329</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>83</td>\n",
       "      <td>64</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>11</td>\n",
       "      <td>22.845946</td>\n",
       "      <td>24.764881</td>\n",
       "      <td>[0.8553311228752136, 0.8393846750259399, 0.832...</td>\n",
       "      <td>[0.8287315368652344, 0.8259304165840149, 0.823...</td>\n",
       "      <td>[0.44214877486228943, 0.42975205183029175, 0.4...</td>\n",
       "      <td>[0.39344263076782227, 0.39344263076782227, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>75</td>\n",
       "      <td>0.313159</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>12</td>\n",
       "      <td>24.852412</td>\n",
       "      <td>33.270141</td>\n",
       "      <td>[0.772885799407959, 0.6148455142974854, 0.5892...</td>\n",
       "      <td>[0.609428882598877, 0.5143787264823914, 0.4708...</td>\n",
       "      <td>[0.44628098607063293, 0.6694214940071106, 0.69...</td>\n",
       "      <td>[0.7704917788505554, 0.7704917788505554, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>152</td>\n",
       "      <td>0.513044</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>13</td>\n",
       "      <td>33.359176</td>\n",
       "      <td>34.491374</td>\n",
       "      <td>[0.6861885786056519, 0.6387695670127869, 0.554...</td>\n",
       "      <td>[0.5122544765472412, 0.4610251188278198, 0.438...</td>\n",
       "      <td>[0.5702479481697083, 0.6570248007774353, 0.714...</td>\n",
       "      <td>[0.7704917788505554, 0.7704917788505554, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>selu</td>\n",
       "      <td>108</td>\n",
       "      <td>0.509290</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>14</td>\n",
       "      <td>34.580531</td>\n",
       "      <td>35.874435</td>\n",
       "      <td>[0.8489587306976318, 0.4972350597381592, 0.462...</td>\n",
       "      <td>[0.45274341106414795, 0.3674491047859192, 0.36...</td>\n",
       "      <td>[0.5330578684806824, 0.7561983466148376, 0.764...</td>\n",
       "      <td>[0.8032786846160889, 0.8032786846160889, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tanh</td>\n",
       "      <td>241</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>15</td>\n",
       "      <td>35.966007</td>\n",
       "      <td>37.310064</td>\n",
       "      <td>[0.7925623059272766, 0.492719829082489, 0.4797...</td>\n",
       "      <td>[0.46594902873039246, 0.3910246789455414, 0.37...</td>\n",
       "      <td>[0.42561984062194824, 0.7685950398445129, 0.75...</td>\n",
       "      <td>[0.7704917788505554, 0.8196721076965332, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>softsign</td>\n",
       "      <td>77</td>\n",
       "      <td>0.275286</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>16</td>\n",
       "      <td>37.465714</td>\n",
       "      <td>38.850616</td>\n",
       "      <td>[0.610711932182312, 0.575690507888794, 0.52702...</td>\n",
       "      <td>[0.5252042412757874, 0.49164584279060364, 0.46...</td>\n",
       "      <td>[0.6776859760284424, 0.7190082669258118, 0.756...</td>\n",
       "      <td>[0.7540983557701111, 0.7704917788505554, 0.754...</td>\n",
       "      <td>18</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>softplus</td>\n",
       "      <td>139</td>\n",
       "      <td>0.565840</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>17</td>\n",
       "      <td>38.941785</td>\n",
       "      <td>40.194959</td>\n",
       "      <td>[0.870384931564331, 0.886029839515686, 0.82698...</td>\n",
       "      <td>[0.6739388704299927, 0.6541799306869507, 0.635...</td>\n",
       "      <td>[0.5330578684806824, 0.5123966932296753, 0.578...</td>\n",
       "      <td>[0.6065573692321777, 0.6393442749977112, 0.672...</td>\n",
       "      <td>18</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>13</td>\n",
       "      <td>0.048939</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>18</td>\n",
       "      <td>40.286145</td>\n",
       "      <td>42.085069</td>\n",
       "      <td>[0.5705435872077942, 0.5144209861755371, 0.479...</td>\n",
       "      <td>[0.5015382766723633, 0.453066885471344, 0.4234...</td>\n",
       "      <td>[0.7148760557174683, 0.7190082669258118, 0.723...</td>\n",
       "      <td>[0.7704917788505554, 0.7868852615356445, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gelu</td>\n",
       "      <td>9</td>\n",
       "      <td>0.145624</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>19</td>\n",
       "      <td>42.180412</td>\n",
       "      <td>43.787748</td>\n",
       "      <td>[0.4326395094394684, 0.3077292740345001, 0.282...</td>\n",
       "      <td>[0.373115599155426, 0.40893104672431946, 0.400...</td>\n",
       "      <td>[0.7809917330741882, 0.8512396812438965, 0.876...</td>\n",
       "      <td>[0.8360655903816223, 0.8196721076965332, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>linear</td>\n",
       "      <td>46</td>\n",
       "      <td>0.049349</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>20</td>\n",
       "      <td>43.883687</td>\n",
       "      <td>45.246478</td>\n",
       "      <td>[0.546433687210083, 0.3429906368255615, 0.2962...</td>\n",
       "      <td>[0.3656468689441681, 0.4212121367454529, 0.462...</td>\n",
       "      <td>[0.6900826692581177, 0.8347107172012329, 0.859...</td>\n",
       "      <td>[0.7868852615356445, 0.8524590134620667, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elu</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>21</td>\n",
       "      <td>45.342026</td>\n",
       "      <td>46.673406</td>\n",
       "      <td>[0.52560955286026, 0.34316012263298035, 0.3126...</td>\n",
       "      <td>[0.3640640377998352, 0.3640632629394531, 0.386...</td>\n",
       "      <td>[0.7355371713638306, 0.8429751992225647, 0.880...</td>\n",
       "      <td>[0.7868852615356445, 0.8360655903816223, 0.836...</td>\n",
       "      <td>18</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>elu</td>\n",
       "      <td>129</td>\n",
       "      <td>0.467615</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>22</td>\n",
       "      <td>46.769448</td>\n",
       "      <td>47.986056</td>\n",
       "      <td>[0.6751319169998169, 0.5231389403343201, 0.481...</td>\n",
       "      <td>[0.4926149249076843, 0.4179950952529907, 0.377...</td>\n",
       "      <td>[0.6570248007774353, 0.7603305578231812, 0.752...</td>\n",
       "      <td>[0.8032786846160889, 0.8196721076965332, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>selu</td>\n",
       "      <td>26</td>\n",
       "      <td>0.491795</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>23</td>\n",
       "      <td>48.081178</td>\n",
       "      <td>49.380528</td>\n",
       "      <td>[0.49345046281814575, 0.3731127679347992, 0.38...</td>\n",
       "      <td>[0.38888120651245117, 0.41984766721725464, 0.4...</td>\n",
       "      <td>[0.7603305578231812, 0.8388429880142212, 0.818...</td>\n",
       "      <td>[0.8196721076965332, 0.8360655903816223, 0.836...</td>\n",
       "      <td>18</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>softsign</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>24</td>\n",
       "      <td>49.544641</td>\n",
       "      <td>50.902924</td>\n",
       "      <td>[0.5573824048042297, 0.37266382575035095, 0.32...</td>\n",
       "      <td>[0.3933885991573334, 0.37639108300209045, 0.38...</td>\n",
       "      <td>[0.6859503984451294, 0.8305785059928894, 0.859...</td>\n",
       "      <td>[0.8032786846160889, 0.868852436542511, 0.8524...</td>\n",
       "      <td>18</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p:activation  p:batch_size  p:dropout_rate  p:learning_rate  p:num_epochs  \\\n",
       "0           relu            32        0.500000         0.001000            50   \n",
       "1           gelu            14        0.361774         0.000027            93   \n",
       "2           tanh           220        0.566210         0.000192            87   \n",
       "3       softsign           231        0.351987         0.000177            48   \n",
       "4            elu            46        0.095004         0.000015            16   \n",
       "5   hard_sigmoid            71        0.253341         0.004306            56   \n",
       "6       softsign           250        0.344377         0.000031            43   \n",
       "7       softplus           220        0.139808         0.000164            52   \n",
       "8         linear            57        0.160272         0.003064            53   \n",
       "9         linear            31        0.334903         0.000293            74   \n",
       "10           elu            25        0.021621         0.000252            74   \n",
       "11        linear            35        0.289329         0.000014            83   \n",
       "12  hard_sigmoid            75        0.313159         0.006197            17   \n",
       "13  hard_sigmoid           152        0.513044         0.008372            19   \n",
       "14          selu           108        0.509290         0.006670            15   \n",
       "15          tanh           241        0.534061         0.009077            29   \n",
       "16      softsign            77        0.275286         0.002149            11   \n",
       "17      softplus           139        0.565840         0.001047            12   \n",
       "18  hard_sigmoid            13        0.048939         0.002026            10   \n",
       "19          gelu             9        0.145624         0.005667            12   \n",
       "20        linear            46        0.049349         0.007786            10   \n",
       "21           elu            10        0.013754         0.003504            11   \n",
       "22           elu           129        0.467615         0.004831            13   \n",
       "23          selu            26        0.491795         0.007216            19   \n",
       "24      softsign            12        0.005680         0.001927            17   \n",
       "\n",
       "    p:units  objective  job_id  m:timestamp_submit  m:timestamp_gather  \\\n",
       "0        32   0.786885       0            3.834054            5.947541   \n",
       "1        42   0.819672       1            6.007420            8.693748   \n",
       "2        51   0.803279       2            8.714586           10.530900   \n",
       "3        84   0.786885       3           10.551754           11.826193   \n",
       "4        63   0.393443       4           11.847148           13.114381   \n",
       "5        26   0.836066       5           13.136196           14.563797   \n",
       "6        57   0.573770       6           14.585100           15.821577   \n",
       "7       125   0.786885       7           15.843169           17.278762   \n",
       "8        64   0.819672       8           17.409882           18.788312   \n",
       "9        69   0.836066       9           18.809638           20.553262   \n",
       "10       91   0.819672      10           20.639394           22.755311   \n",
       "11       64   0.573770      11           22.845946           24.764881   \n",
       "12       34   0.852459      12           24.852412           33.270141   \n",
       "13       53   0.852459      13           33.359176           34.491374   \n",
       "14       41   0.852459      14           34.580531           35.874435   \n",
       "15       65   0.836066      15           35.966007           37.310064   \n",
       "16       24   0.852459      16           37.465714           38.850616   \n",
       "17       15   0.836066      17           38.941785           40.194959   \n",
       "18       36   0.852459      18           40.286145           42.085069   \n",
       "19       58   0.770492      19           42.180412           43.787748   \n",
       "20       51   0.803279      20           43.883687           45.246478   \n",
       "21       22   0.803279      21           45.342026           46.673406   \n",
       "22       48   0.836066      22           46.769448           47.986056   \n",
       "23       31   0.803279      23           48.081178           49.380528   \n",
       "24      108   0.803279      24           49.544641           50.902924   \n",
       "\n",
       "                                               m:loss  \\\n",
       "0   [0.7808094620704651, 0.7111438512802124, 0.646...   \n",
       "1   [0.6810137033462524, 0.6927006244659424, 0.706...   \n",
       "2   [0.801559329032898, 0.8501983880996704, 0.7510...   \n",
       "3   [0.6304690837860107, 0.6313081979751587, 0.628...   \n",
       "4   [0.8530883193016052, 0.8459160327911377, 0.845...   \n",
       "5   [0.658219039440155, 0.5700154304504395, 0.5358...   \n",
       "6   [0.7235867381095886, 0.7136470675468445, 0.738...   \n",
       "7   [0.944303572177887, 0.9194084405899048, 0.8835...   \n",
       "8   [0.5765562653541565, 0.4299267530441284, 0.374...   \n",
       "9   [1.1083784103393555, 1.0162237882614136, 0.923...   \n",
       "10  [0.7378655076026917, 0.6833291053771973, 0.628...   \n",
       "11  [0.8553311228752136, 0.8393846750259399, 0.832...   \n",
       "12  [0.772885799407959, 0.6148455142974854, 0.5892...   \n",
       "13  [0.6861885786056519, 0.6387695670127869, 0.554...   \n",
       "14  [0.8489587306976318, 0.4972350597381592, 0.462...   \n",
       "15  [0.7925623059272766, 0.492719829082489, 0.4797...   \n",
       "16  [0.610711932182312, 0.575690507888794, 0.52702...   \n",
       "17  [0.870384931564331, 0.886029839515686, 0.82698...   \n",
       "18  [0.5705435872077942, 0.5144209861755371, 0.479...   \n",
       "19  [0.4326395094394684, 0.3077292740345001, 0.282...   \n",
       "20  [0.546433687210083, 0.3429906368255615, 0.2962...   \n",
       "21  [0.52560955286026, 0.34316012263298035, 0.3126...   \n",
       "22  [0.6751319169998169, 0.5231389403343201, 0.481...   \n",
       "23  [0.49345046281814575, 0.3731127679347992, 0.38...   \n",
       "24  [0.5573824048042297, 0.37266382575035095, 0.32...   \n",
       "\n",
       "                                           m:val_loss  \\\n",
       "0   [0.702677845954895, 0.6320067644119263, 0.5747...   \n",
       "1   [0.6666766405105591, 0.6627156138420105, 0.658...   \n",
       "2   [0.7569047212600708, 0.7465746998786926, 0.736...   \n",
       "3   [0.562753438949585, 0.5581142902374268, 0.5539...   \n",
       "4   [0.8290221691131592, 0.826231062412262, 0.8235...   \n",
       "5   [0.5507251620292664, 0.4919049143791199, 0.458...   \n",
       "6   [0.7078008651733398, 0.7073135375976562, 0.706...   \n",
       "7   [0.8775652050971985, 0.8581626415252686, 0.839...   \n",
       "8   [0.44439399242401123, 0.3810850977897644, 0.37...   \n",
       "9   [1.0996410846710205, 1.000662922859192, 0.9125...   \n",
       "10  [0.6795907020568848, 0.6176944971084595, 0.568...   \n",
       "11  [0.8287315368652344, 0.8259304165840149, 0.823...   \n",
       "12  [0.609428882598877, 0.5143787264823914, 0.4708...   \n",
       "13  [0.5122544765472412, 0.4610251188278198, 0.438...   \n",
       "14  [0.45274341106414795, 0.3674491047859192, 0.36...   \n",
       "15  [0.46594902873039246, 0.3910246789455414, 0.37...   \n",
       "16  [0.5252042412757874, 0.49164584279060364, 0.46...   \n",
       "17  [0.6739388704299927, 0.6541799306869507, 0.635...   \n",
       "18  [0.5015382766723633, 0.453066885471344, 0.4234...   \n",
       "19  [0.373115599155426, 0.40893104672431946, 0.400...   \n",
       "20  [0.3656468689441681, 0.4212121367454529, 0.462...   \n",
       "21  [0.3640640377998352, 0.3640632629394531, 0.386...   \n",
       "22  [0.4926149249076843, 0.4179950952529907, 0.377...   \n",
       "23  [0.38888120651245117, 0.41984766721725464, 0.4...   \n",
       "24  [0.3933885991573334, 0.37639108300209045, 0.38...   \n",
       "\n",
       "                                           m:accuracy  \\\n",
       "0   [0.4752066135406494, 0.5619834661483765, 0.599...   \n",
       "1   [0.5785123705863953, 0.5247933864593506, 0.512...   \n",
       "2   [0.5247933864593506, 0.42148759961128235, 0.52...   \n",
       "3   [0.6611570119857788, 0.6900826692581177, 0.665...   \n",
       "4   [0.28099173307418823, 0.2851239740848541, 0.29...   \n",
       "5   [0.5909090638160706, 0.7355371713638306, 0.719...   \n",
       "6   [0.5082644820213318, 0.5413222908973694, 0.508...   \n",
       "7   [0.32231405377388, 0.32231405377388, 0.3677685...   \n",
       "8   [0.7066115736961365, 0.8140496015548706, 0.809...   \n",
       "9   [0.3305785059928894, 0.3388429880142212, 0.413...   \n",
       "10  [0.43388429284095764, 0.5743801593780518, 0.68...   \n",
       "11  [0.44214877486228943, 0.42975205183029175, 0.4...   \n",
       "12  [0.44628098607063293, 0.6694214940071106, 0.69...   \n",
       "13  [0.5702479481697083, 0.6570248007774353, 0.714...   \n",
       "14  [0.5330578684806824, 0.7561983466148376, 0.764...   \n",
       "15  [0.42561984062194824, 0.7685950398445129, 0.75...   \n",
       "16  [0.6776859760284424, 0.7190082669258118, 0.756...   \n",
       "17  [0.5330578684806824, 0.5123966932296753, 0.578...   \n",
       "18  [0.7148760557174683, 0.7190082669258118, 0.723...   \n",
       "19  [0.7809917330741882, 0.8512396812438965, 0.876...   \n",
       "20  [0.6900826692581177, 0.8347107172012329, 0.859...   \n",
       "21  [0.7355371713638306, 0.8429751992225647, 0.880...   \n",
       "22  [0.6570248007774353, 0.7603305578231812, 0.752...   \n",
       "23  [0.7603305578231812, 0.8388429880142212, 0.818...   \n",
       "24  [0.6859503984451294, 0.8305785059928894, 0.859...   \n",
       "\n",
       "                                       m:val_accuracy  m:num_parameters  \\\n",
       "0   [0.49180328845977783, 0.6721311211585999, 0.77...                18   \n",
       "1   [0.5737704634666443, 0.5901639461517334, 0.622...                18   \n",
       "2   [0.44262295961380005, 0.4590163826942444, 0.47...                18   \n",
       "3   [0.7868852615356445, 0.7868852615356445, 0.786...                18   \n",
       "4   [0.37704917788505554, 0.37704917788505554, 0.3...                18   \n",
       "5   [0.7868852615356445, 0.8032786846160889, 0.786...                18   \n",
       "6   [0.5409836173057556, 0.5409836173057556, 0.540...                18   \n",
       "7   [0.2295081913471222, 0.21311475336551666, 0.22...                18   \n",
       "8   [0.7704917788505554, 0.8196721076965332, 0.803...                18   \n",
       "9   [0.32786884903907776, 0.39344263076782227, 0.3...                18   \n",
       "10  [0.5245901346206665, 0.6721311211585999, 0.770...                18   \n",
       "11  [0.39344263076782227, 0.39344263076782227, 0.3...                18   \n",
       "12  [0.7704917788505554, 0.7704917788505554, 0.770...                18   \n",
       "13  [0.7704917788505554, 0.7704917788505554, 0.770...                18   \n",
       "14  [0.8032786846160889, 0.8032786846160889, 0.819...                18   \n",
       "15  [0.7704917788505554, 0.8196721076965332, 0.819...                18   \n",
       "16  [0.7540983557701111, 0.7704917788505554, 0.754...                18   \n",
       "17  [0.6065573692321777, 0.6393442749977112, 0.672...                18   \n",
       "18  [0.7704917788505554, 0.7868852615356445, 0.803...                18   \n",
       "19  [0.8360655903816223, 0.8196721076965332, 0.803...                18   \n",
       "20  [0.7868852615356445, 0.8524590134620667, 0.819...                18   \n",
       "21  [0.7868852615356445, 0.8360655903816223, 0.836...                18   \n",
       "22  [0.8032786846160889, 0.8196721076965332, 0.819...                18   \n",
       "23  [0.8196721076965332, 0.8360655903816223, 0.836...                18   \n",
       "24  [0.8032786846160889, 0.868852436542511, 0.8524...                18   \n",
       "\n",
       "    m:num_parameters_train  \n",
       "0                     1217  \n",
       "1                     1597  \n",
       "2                     1939  \n",
       "3                     3193  \n",
       "4                     2395  \n",
       "5                      989  \n",
       "6                     2167  \n",
       "7                     4751  \n",
       "8                     2433  \n",
       "9                     2623  \n",
       "10                    3459  \n",
       "11                    2433  \n",
       "12                    1293  \n",
       "13                    2015  \n",
       "14                    1559  \n",
       "15                    2471  \n",
       "16                     913  \n",
       "17                     571  \n",
       "18                    1369  \n",
       "19                    2205  \n",
       "20                    1939  \n",
       "21                     837  \n",
       "22                    1825  \n",
       "23                    1179  \n",
       "24                    4105  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4ad4f254144dafb27806c6b47a9b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p:activation</th>\n",
       "      <th>p:batch_size</th>\n",
       "      <th>p:dropout_rate</th>\n",
       "      <th>p:learning_rate</th>\n",
       "      <th>p:num_epochs</th>\n",
       "      <th>p:units</th>\n",
       "      <th>objective</th>\n",
       "      <th>job_id</th>\n",
       "      <th>m:timestamp_submit</th>\n",
       "      <th>m:timestamp_gather</th>\n",
       "      <th>m:loss</th>\n",
       "      <th>m:val_loss</th>\n",
       "      <th>m:accuracy</th>\n",
       "      <th>m:val_accuracy</th>\n",
       "      <th>m:num_parameters</th>\n",
       "      <th>m:num_parameters_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0</td>\n",
       "      <td>3.834054</td>\n",
       "      <td>5.947541</td>\n",
       "      <td>[0.7808094620704651, 0.7111438512802124, 0.646...</td>\n",
       "      <td>[0.702677845954895, 0.6320067644119263, 0.5747...</td>\n",
       "      <td>[0.4752066135406494, 0.5619834661483765, 0.599...</td>\n",
       "      <td>[0.49180328845977783, 0.6721311211585999, 0.77...</td>\n",
       "      <td>18</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gelu</td>\n",
       "      <td>14</td>\n",
       "      <td>0.361774</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>93</td>\n",
       "      <td>42</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>1</td>\n",
       "      <td>6.007420</td>\n",
       "      <td>8.693748</td>\n",
       "      <td>[0.6810137033462524, 0.6927006244659424, 0.706...</td>\n",
       "      <td>[0.6666766405105591, 0.6627156138420105, 0.658...</td>\n",
       "      <td>[0.5785123705863953, 0.5247933864593506, 0.512...</td>\n",
       "      <td>[0.5737704634666443, 0.5901639461517334, 0.622...</td>\n",
       "      <td>18</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>220</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>2</td>\n",
       "      <td>8.714586</td>\n",
       "      <td>10.530900</td>\n",
       "      <td>[0.801559329032898, 0.8501983880996704, 0.7510...</td>\n",
       "      <td>[0.7569047212600708, 0.7465746998786926, 0.736...</td>\n",
       "      <td>[0.5247933864593506, 0.42148759961128235, 0.52...</td>\n",
       "      <td>[0.44262295961380005, 0.4590163826942444, 0.47...</td>\n",
       "      <td>18</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>softsign</td>\n",
       "      <td>231</td>\n",
       "      <td>0.351987</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>48</td>\n",
       "      <td>84</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>3</td>\n",
       "      <td>10.551754</td>\n",
       "      <td>11.826193</td>\n",
       "      <td>[0.6304690837860107, 0.6313081979751587, 0.628...</td>\n",
       "      <td>[0.562753438949585, 0.5581142902374268, 0.5539...</td>\n",
       "      <td>[0.6611570119857788, 0.6900826692581177, 0.665...</td>\n",
       "      <td>[0.7868852615356445, 0.7868852615356445, 0.786...</td>\n",
       "      <td>18</td>\n",
       "      <td>3193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>elu</td>\n",
       "      <td>46</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>0.393443</td>\n",
       "      <td>4</td>\n",
       "      <td>11.847148</td>\n",
       "      <td>13.114381</td>\n",
       "      <td>[0.8530883193016052, 0.8459160327911377, 0.845...</td>\n",
       "      <td>[0.8290221691131592, 0.826231062412262, 0.8235...</td>\n",
       "      <td>[0.28099173307418823, 0.2851239740848541, 0.29...</td>\n",
       "      <td>[0.37704917788505554, 0.37704917788505554, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>71</td>\n",
       "      <td>0.253341</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>5</td>\n",
       "      <td>13.136196</td>\n",
       "      <td>14.563797</td>\n",
       "      <td>[0.658219039440155, 0.5700154304504395, 0.5358...</td>\n",
       "      <td>[0.5507251620292664, 0.4919049143791199, 0.458...</td>\n",
       "      <td>[0.5909090638160706, 0.7355371713638306, 0.719...</td>\n",
       "      <td>[0.7868852615356445, 0.8032786846160889, 0.786...</td>\n",
       "      <td>18</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>softsign</td>\n",
       "      <td>250</td>\n",
       "      <td>0.344377</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>6</td>\n",
       "      <td>14.585100</td>\n",
       "      <td>15.821577</td>\n",
       "      <td>[0.7235867381095886, 0.7136470675468445, 0.738...</td>\n",
       "      <td>[0.7078008651733398, 0.7073135375976562, 0.706...</td>\n",
       "      <td>[0.5082644820213318, 0.5413222908973694, 0.508...</td>\n",
       "      <td>[0.5409836173057556, 0.5409836173057556, 0.540...</td>\n",
       "      <td>18</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>softplus</td>\n",
       "      <td>220</td>\n",
       "      <td>0.139808</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>52</td>\n",
       "      <td>125</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>7</td>\n",
       "      <td>15.843169</td>\n",
       "      <td>17.278762</td>\n",
       "      <td>[0.944303572177887, 0.9194084405899048, 0.8835...</td>\n",
       "      <td>[0.8775652050971985, 0.8581626415252686, 0.839...</td>\n",
       "      <td>[0.32231405377388, 0.32231405377388, 0.3677685...</td>\n",
       "      <td>[0.2295081913471222, 0.21311475336551666, 0.22...</td>\n",
       "      <td>18</td>\n",
       "      <td>4751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear</td>\n",
       "      <td>57</td>\n",
       "      <td>0.160272</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>53</td>\n",
       "      <td>64</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>8</td>\n",
       "      <td>17.409882</td>\n",
       "      <td>18.788312</td>\n",
       "      <td>[0.5765562653541565, 0.4299267530441284, 0.374...</td>\n",
       "      <td>[0.44439399242401123, 0.3810850977897644, 0.37...</td>\n",
       "      <td>[0.7066115736961365, 0.8140496015548706, 0.809...</td>\n",
       "      <td>[0.7704917788505554, 0.8196721076965332, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>linear</td>\n",
       "      <td>31</td>\n",
       "      <td>0.334903</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>74</td>\n",
       "      <td>69</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>9</td>\n",
       "      <td>18.809638</td>\n",
       "      <td>20.553262</td>\n",
       "      <td>[1.1083784103393555, 1.0162237882614136, 0.923...</td>\n",
       "      <td>[1.0996410846710205, 1.000662922859192, 0.9125...</td>\n",
       "      <td>[0.3305785059928894, 0.3388429880142212, 0.413...</td>\n",
       "      <td>[0.32786884903907776, 0.39344263076782227, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>elu</td>\n",
       "      <td>25</td>\n",
       "      <td>0.021621</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>74</td>\n",
       "      <td>91</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>10</td>\n",
       "      <td>20.639394</td>\n",
       "      <td>22.755311</td>\n",
       "      <td>[0.7378655076026917, 0.6833291053771973, 0.628...</td>\n",
       "      <td>[0.6795907020568848, 0.6176944971084595, 0.568...</td>\n",
       "      <td>[0.43388429284095764, 0.5743801593780518, 0.68...</td>\n",
       "      <td>[0.5245901346206665, 0.6721311211585999, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>3459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linear</td>\n",
       "      <td>35</td>\n",
       "      <td>0.289329</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>83</td>\n",
       "      <td>64</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>11</td>\n",
       "      <td>22.845946</td>\n",
       "      <td>24.764881</td>\n",
       "      <td>[0.8553311228752136, 0.8393846750259399, 0.832...</td>\n",
       "      <td>[0.8287315368652344, 0.8259304165840149, 0.823...</td>\n",
       "      <td>[0.44214877486228943, 0.42975205183029175, 0.4...</td>\n",
       "      <td>[0.39344263076782227, 0.39344263076782227, 0.3...</td>\n",
       "      <td>18</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>75</td>\n",
       "      <td>0.313159</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>12</td>\n",
       "      <td>24.852412</td>\n",
       "      <td>33.270141</td>\n",
       "      <td>[0.772885799407959, 0.6148455142974854, 0.5892...</td>\n",
       "      <td>[0.609428882598877, 0.5143787264823914, 0.4708...</td>\n",
       "      <td>[0.44628098607063293, 0.6694214940071106, 0.69...</td>\n",
       "      <td>[0.7704917788505554, 0.7704917788505554, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>152</td>\n",
       "      <td>0.513044</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>19</td>\n",
       "      <td>53</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>13</td>\n",
       "      <td>33.359176</td>\n",
       "      <td>34.491374</td>\n",
       "      <td>[0.6861885786056519, 0.6387695670127869, 0.554...</td>\n",
       "      <td>[0.5122544765472412, 0.4610251188278198, 0.438...</td>\n",
       "      <td>[0.5702479481697083, 0.6570248007774353, 0.714...</td>\n",
       "      <td>[0.7704917788505554, 0.7704917788505554, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>selu</td>\n",
       "      <td>108</td>\n",
       "      <td>0.509290</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>14</td>\n",
       "      <td>34.580531</td>\n",
       "      <td>35.874435</td>\n",
       "      <td>[0.8489587306976318, 0.4972350597381592, 0.462...</td>\n",
       "      <td>[0.45274341106414795, 0.3674491047859192, 0.36...</td>\n",
       "      <td>[0.5330578684806824, 0.7561983466148376, 0.764...</td>\n",
       "      <td>[0.8032786846160889, 0.8032786846160889, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tanh</td>\n",
       "      <td>241</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.009077</td>\n",
       "      <td>29</td>\n",
       "      <td>65</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>15</td>\n",
       "      <td>35.966007</td>\n",
       "      <td>37.310064</td>\n",
       "      <td>[0.7925623059272766, 0.492719829082489, 0.4797...</td>\n",
       "      <td>[0.46594902873039246, 0.3910246789455414, 0.37...</td>\n",
       "      <td>[0.42561984062194824, 0.7685950398445129, 0.75...</td>\n",
       "      <td>[0.7704917788505554, 0.8196721076965332, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>softsign</td>\n",
       "      <td>77</td>\n",
       "      <td>0.275286</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>16</td>\n",
       "      <td>37.465714</td>\n",
       "      <td>38.850616</td>\n",
       "      <td>[0.610711932182312, 0.575690507888794, 0.52702...</td>\n",
       "      <td>[0.5252042412757874, 0.49164584279060364, 0.46...</td>\n",
       "      <td>[0.6776859760284424, 0.7190082669258118, 0.756...</td>\n",
       "      <td>[0.7540983557701111, 0.7704917788505554, 0.754...</td>\n",
       "      <td>18</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>softplus</td>\n",
       "      <td>139</td>\n",
       "      <td>0.565840</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>17</td>\n",
       "      <td>38.941785</td>\n",
       "      <td>40.194959</td>\n",
       "      <td>[0.870384931564331, 0.886029839515686, 0.82698...</td>\n",
       "      <td>[0.6739388704299927, 0.6541799306869507, 0.635...</td>\n",
       "      <td>[0.5330578684806824, 0.5123966932296753, 0.578...</td>\n",
       "      <td>[0.6065573692321777, 0.6393442749977112, 0.672...</td>\n",
       "      <td>18</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>13</td>\n",
       "      <td>0.048939</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>18</td>\n",
       "      <td>40.286145</td>\n",
       "      <td>42.085069</td>\n",
       "      <td>[0.5705435872077942, 0.5144209861755371, 0.479...</td>\n",
       "      <td>[0.5015382766723633, 0.453066885471344, 0.4234...</td>\n",
       "      <td>[0.7148760557174683, 0.7190082669258118, 0.723...</td>\n",
       "      <td>[0.7704917788505554, 0.7868852615356445, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>1369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gelu</td>\n",
       "      <td>9</td>\n",
       "      <td>0.145624</td>\n",
       "      <td>0.005667</td>\n",
       "      <td>12</td>\n",
       "      <td>58</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>19</td>\n",
       "      <td>42.180412</td>\n",
       "      <td>43.787748</td>\n",
       "      <td>[0.4326395094394684, 0.3077292740345001, 0.282...</td>\n",
       "      <td>[0.373115599155426, 0.40893104672431946, 0.400...</td>\n",
       "      <td>[0.7809917330741882, 0.8512396812438965, 0.876...</td>\n",
       "      <td>[0.8360655903816223, 0.8196721076965332, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>2205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>linear</td>\n",
       "      <td>46</td>\n",
       "      <td>0.049349</td>\n",
       "      <td>0.007786</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>20</td>\n",
       "      <td>43.883687</td>\n",
       "      <td>45.246478</td>\n",
       "      <td>[0.546433687210083, 0.3429906368255615, 0.2962...</td>\n",
       "      <td>[0.3656468689441681, 0.4212121367454529, 0.462...</td>\n",
       "      <td>[0.6900826692581177, 0.8347107172012329, 0.859...</td>\n",
       "      <td>[0.7868852615356445, 0.8524590134620667, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>elu</td>\n",
       "      <td>10</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.003504</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>21</td>\n",
       "      <td>45.342026</td>\n",
       "      <td>46.673406</td>\n",
       "      <td>[0.52560955286026, 0.34316012263298035, 0.3126...</td>\n",
       "      <td>[0.3640640377998352, 0.3640632629394531, 0.386...</td>\n",
       "      <td>[0.7355371713638306, 0.8429751992225647, 0.880...</td>\n",
       "      <td>[0.7868852615356445, 0.8360655903816223, 0.836...</td>\n",
       "      <td>18</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>elu</td>\n",
       "      <td>129</td>\n",
       "      <td>0.467615</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>22</td>\n",
       "      <td>46.769448</td>\n",
       "      <td>47.986056</td>\n",
       "      <td>[0.6751319169998169, 0.5231389403343201, 0.481...</td>\n",
       "      <td>[0.4926149249076843, 0.4179950952529907, 0.377...</td>\n",
       "      <td>[0.6570248007774353, 0.7603305578231812, 0.752...</td>\n",
       "      <td>[0.8032786846160889, 0.8196721076965332, 0.819...</td>\n",
       "      <td>18</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>selu</td>\n",
       "      <td>26</td>\n",
       "      <td>0.491795</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>23</td>\n",
       "      <td>48.081178</td>\n",
       "      <td>49.380528</td>\n",
       "      <td>[0.49345046281814575, 0.3731127679347992, 0.38...</td>\n",
       "      <td>[0.38888120651245117, 0.41984766721725464, 0.4...</td>\n",
       "      <td>[0.7603305578231812, 0.8388429880142212, 0.818...</td>\n",
       "      <td>[0.8196721076965332, 0.8360655903816223, 0.836...</td>\n",
       "      <td>18</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>softsign</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>24</td>\n",
       "      <td>49.544641</td>\n",
       "      <td>50.902924</td>\n",
       "      <td>[0.5573824048042297, 0.37266382575035095, 0.32...</td>\n",
       "      <td>[0.3933885991573334, 0.37639108300209045, 0.38...</td>\n",
       "      <td>[0.6859503984451294, 0.8305785059928894, 0.859...</td>\n",
       "      <td>[0.8032786846160889, 0.868852436542511, 0.8524...</td>\n",
       "      <td>18</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>softsign</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>25</td>\n",
       "      <td>83.570844</td>\n",
       "      <td>85.098006</td>\n",
       "      <td>[0.48767781257629395, 0.3392634093761444, 0.30...</td>\n",
       "      <td>[0.36803916096687317, 0.37145382165908813, 0.3...</td>\n",
       "      <td>[0.7685950398445129, 0.85537189245224, 0.87190...</td>\n",
       "      <td>[0.8196721076965332, 0.8524590134620667, 0.852...</td>\n",
       "      <td>18</td>\n",
       "      <td>4105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>swish</td>\n",
       "      <td>92</td>\n",
       "      <td>0.293657</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>26</td>\n",
       "      <td>85.223487</td>\n",
       "      <td>86.449097</td>\n",
       "      <td>[0.5902856588363647, 0.4663049280643463, 0.396...</td>\n",
       "      <td>[0.45265552401542664, 0.38533690571784973, 0.3...</td>\n",
       "      <td>[0.702479362487793, 0.7644628286361694, 0.8016...</td>\n",
       "      <td>[0.7704917788505554, 0.7704917788505554, 0.852...</td>\n",
       "      <td>18</td>\n",
       "      <td>2471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hard_sigmoid</td>\n",
       "      <td>12</td>\n",
       "      <td>0.140305</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>27</td>\n",
       "      <td>86.555735</td>\n",
       "      <td>88.031418</td>\n",
       "      <td>[0.5709083080291748, 0.5268552303314209, 0.478...</td>\n",
       "      <td>[0.48047083616256714, 0.4440501928329468, 0.40...</td>\n",
       "      <td>[0.7148760557174683, 0.7396694421768188, 0.735...</td>\n",
       "      <td>[0.7704917788505554, 0.8032786846160889, 0.803...</td>\n",
       "      <td>18</td>\n",
       "      <td>1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>softsign</td>\n",
       "      <td>124</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>28</td>\n",
       "      <td>88.128388</td>\n",
       "      <td>89.273253</td>\n",
       "      <td>[0.7323880791664124, 0.6122469305992126, 0.505...</td>\n",
       "      <td>[0.6058762073516846, 0.4980878233909607, 0.435...</td>\n",
       "      <td>[0.4793388545513153, 0.6322314143180847, 0.760...</td>\n",
       "      <td>[0.7540983557701111, 0.8032786846160889, 0.852...</td>\n",
       "      <td>18</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>softplus</td>\n",
       "      <td>64</td>\n",
       "      <td>0.368432</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>29</td>\n",
       "      <td>89.373880</td>\n",
       "      <td>90.595998</td>\n",
       "      <td>[0.6271360516548157, 0.5913099646568298, 0.565...</td>\n",
       "      <td>[0.4851932227611542, 0.4552323818206787, 0.434...</td>\n",
       "      <td>[0.7190082669258118, 0.702479362487793, 0.7066...</td>\n",
       "      <td>[0.7704917788505554, 0.7868852615356445, 0.770...</td>\n",
       "      <td>18</td>\n",
       "      <td>1407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    p:activation  p:batch_size  p:dropout_rate  p:learning_rate  p:num_epochs  \\\n",
       "0           relu            32        0.500000         0.001000            50   \n",
       "1           gelu            14        0.361774         0.000027            93   \n",
       "2           tanh           220        0.566210         0.000192            87   \n",
       "3       softsign           231        0.351987         0.000177            48   \n",
       "4            elu            46        0.095004         0.000015            16   \n",
       "5   hard_sigmoid            71        0.253341         0.004306            56   \n",
       "6       softsign           250        0.344377         0.000031            43   \n",
       "7       softplus           220        0.139808         0.000164            52   \n",
       "8         linear            57        0.160272         0.003064            53   \n",
       "9         linear            31        0.334903         0.000293            74   \n",
       "10           elu            25        0.021621         0.000252            74   \n",
       "11        linear            35        0.289329         0.000014            83   \n",
       "12  hard_sigmoid            75        0.313159         0.006197            17   \n",
       "13  hard_sigmoid           152        0.513044         0.008372            19   \n",
       "14          selu           108        0.509290         0.006670            15   \n",
       "15          tanh           241        0.534061         0.009077            29   \n",
       "16      softsign            77        0.275286         0.002149            11   \n",
       "17      softplus           139        0.565840         0.001047            12   \n",
       "18  hard_sigmoid            13        0.048939         0.002026            10   \n",
       "19          gelu             9        0.145624         0.005667            12   \n",
       "20        linear            46        0.049349         0.007786            10   \n",
       "21           elu            10        0.013754         0.003504            11   \n",
       "22           elu           129        0.467615         0.004831            13   \n",
       "23          selu            26        0.491795         0.007216            19   \n",
       "24      softsign            12        0.005680         0.001927            17   \n",
       "25      softsign            12        0.005680         0.001927            17   \n",
       "26         swish            92        0.293657         0.006329            16   \n",
       "27  hard_sigmoid            12        0.140305         0.002071            15   \n",
       "28      softsign           124        0.332451         0.007500            20   \n",
       "29      softplus            64        0.368432         0.002269            10   \n",
       "\n",
       "    p:units  objective  job_id  m:timestamp_submit  m:timestamp_gather  \\\n",
       "0        32   0.786885       0            3.834054            5.947541   \n",
       "1        42   0.819672       1            6.007420            8.693748   \n",
       "2        51   0.803279       2            8.714586           10.530900   \n",
       "3        84   0.786885       3           10.551754           11.826193   \n",
       "4        63   0.393443       4           11.847148           13.114381   \n",
       "5        26   0.836066       5           13.136196           14.563797   \n",
       "6        57   0.573770       6           14.585100           15.821577   \n",
       "7       125   0.786885       7           15.843169           17.278762   \n",
       "8        64   0.819672       8           17.409882           18.788312   \n",
       "9        69   0.836066       9           18.809638           20.553262   \n",
       "10       91   0.819672      10           20.639394           22.755311   \n",
       "11       64   0.573770      11           22.845946           24.764881   \n",
       "12       34   0.852459      12           24.852412           33.270141   \n",
       "13       53   0.852459      13           33.359176           34.491374   \n",
       "14       41   0.852459      14           34.580531           35.874435   \n",
       "15       65   0.836066      15           35.966007           37.310064   \n",
       "16       24   0.852459      16           37.465714           38.850616   \n",
       "17       15   0.836066      17           38.941785           40.194959   \n",
       "18       36   0.852459      18           40.286145           42.085069   \n",
       "19       58   0.770492      19           42.180412           43.787748   \n",
       "20       51   0.803279      20           43.883687           45.246478   \n",
       "21       22   0.803279      21           45.342026           46.673406   \n",
       "22       48   0.836066      22           46.769448           47.986056   \n",
       "23       31   0.803279      23           48.081178           49.380528   \n",
       "24      108   0.803279      24           49.544641           50.902924   \n",
       "25      108   0.786885      25           83.570844           85.098006   \n",
       "26       65   0.786885      26           85.223487           86.449097   \n",
       "27       45   0.836066      27           86.555735           88.031418   \n",
       "28       33   0.819672      28           88.128388           89.273253   \n",
       "29       37   0.819672      29           89.373880           90.595998   \n",
       "\n",
       "                                               m:loss  \\\n",
       "0   [0.7808094620704651, 0.7111438512802124, 0.646...   \n",
       "1   [0.6810137033462524, 0.6927006244659424, 0.706...   \n",
       "2   [0.801559329032898, 0.8501983880996704, 0.7510...   \n",
       "3   [0.6304690837860107, 0.6313081979751587, 0.628...   \n",
       "4   [0.8530883193016052, 0.8459160327911377, 0.845...   \n",
       "5   [0.658219039440155, 0.5700154304504395, 0.5358...   \n",
       "6   [0.7235867381095886, 0.7136470675468445, 0.738...   \n",
       "7   [0.944303572177887, 0.9194084405899048, 0.8835...   \n",
       "8   [0.5765562653541565, 0.4299267530441284, 0.374...   \n",
       "9   [1.1083784103393555, 1.0162237882614136, 0.923...   \n",
       "10  [0.7378655076026917, 0.6833291053771973, 0.628...   \n",
       "11  [0.8553311228752136, 0.8393846750259399, 0.832...   \n",
       "12  [0.772885799407959, 0.6148455142974854, 0.5892...   \n",
       "13  [0.6861885786056519, 0.6387695670127869, 0.554...   \n",
       "14  [0.8489587306976318, 0.4972350597381592, 0.462...   \n",
       "15  [0.7925623059272766, 0.492719829082489, 0.4797...   \n",
       "16  [0.610711932182312, 0.575690507888794, 0.52702...   \n",
       "17  [0.870384931564331, 0.886029839515686, 0.82698...   \n",
       "18  [0.5705435872077942, 0.5144209861755371, 0.479...   \n",
       "19  [0.4326395094394684, 0.3077292740345001, 0.282...   \n",
       "20  [0.546433687210083, 0.3429906368255615, 0.2962...   \n",
       "21  [0.52560955286026, 0.34316012263298035, 0.3126...   \n",
       "22  [0.6751319169998169, 0.5231389403343201, 0.481...   \n",
       "23  [0.49345046281814575, 0.3731127679347992, 0.38...   \n",
       "24  [0.5573824048042297, 0.37266382575035095, 0.32...   \n",
       "25  [0.48767781257629395, 0.3392634093761444, 0.30...   \n",
       "26  [0.5902856588363647, 0.4663049280643463, 0.396...   \n",
       "27  [0.5709083080291748, 0.5268552303314209, 0.478...   \n",
       "28  [0.7323880791664124, 0.6122469305992126, 0.505...   \n",
       "29  [0.6271360516548157, 0.5913099646568298, 0.565...   \n",
       "\n",
       "                                           m:val_loss  \\\n",
       "0   [0.702677845954895, 0.6320067644119263, 0.5747...   \n",
       "1   [0.6666766405105591, 0.6627156138420105, 0.658...   \n",
       "2   [0.7569047212600708, 0.7465746998786926, 0.736...   \n",
       "3   [0.562753438949585, 0.5581142902374268, 0.5539...   \n",
       "4   [0.8290221691131592, 0.826231062412262, 0.8235...   \n",
       "5   [0.5507251620292664, 0.4919049143791199, 0.458...   \n",
       "6   [0.7078008651733398, 0.7073135375976562, 0.706...   \n",
       "7   [0.8775652050971985, 0.8581626415252686, 0.839...   \n",
       "8   [0.44439399242401123, 0.3810850977897644, 0.37...   \n",
       "9   [1.0996410846710205, 1.000662922859192, 0.9125...   \n",
       "10  [0.6795907020568848, 0.6176944971084595, 0.568...   \n",
       "11  [0.8287315368652344, 0.8259304165840149, 0.823...   \n",
       "12  [0.609428882598877, 0.5143787264823914, 0.4708...   \n",
       "13  [0.5122544765472412, 0.4610251188278198, 0.438...   \n",
       "14  [0.45274341106414795, 0.3674491047859192, 0.36...   \n",
       "15  [0.46594902873039246, 0.3910246789455414, 0.37...   \n",
       "16  [0.5252042412757874, 0.49164584279060364, 0.46...   \n",
       "17  [0.6739388704299927, 0.6541799306869507, 0.635...   \n",
       "18  [0.5015382766723633, 0.453066885471344, 0.4234...   \n",
       "19  [0.373115599155426, 0.40893104672431946, 0.400...   \n",
       "20  [0.3656468689441681, 0.4212121367454529, 0.462...   \n",
       "21  [0.3640640377998352, 0.3640632629394531, 0.386...   \n",
       "22  [0.4926149249076843, 0.4179950952529907, 0.377...   \n",
       "23  [0.38888120651245117, 0.41984766721725464, 0.4...   \n",
       "24  [0.3933885991573334, 0.37639108300209045, 0.38...   \n",
       "25  [0.36803916096687317, 0.37145382165908813, 0.3...   \n",
       "26  [0.45265552401542664, 0.38533690571784973, 0.3...   \n",
       "27  [0.48047083616256714, 0.4440501928329468, 0.40...   \n",
       "28  [0.6058762073516846, 0.4980878233909607, 0.435...   \n",
       "29  [0.4851932227611542, 0.4552323818206787, 0.434...   \n",
       "\n",
       "                                           m:accuracy  \\\n",
       "0   [0.4752066135406494, 0.5619834661483765, 0.599...   \n",
       "1   [0.5785123705863953, 0.5247933864593506, 0.512...   \n",
       "2   [0.5247933864593506, 0.42148759961128235, 0.52...   \n",
       "3   [0.6611570119857788, 0.6900826692581177, 0.665...   \n",
       "4   [0.28099173307418823, 0.2851239740848541, 0.29...   \n",
       "5   [0.5909090638160706, 0.7355371713638306, 0.719...   \n",
       "6   [0.5082644820213318, 0.5413222908973694, 0.508...   \n",
       "7   [0.32231405377388, 0.32231405377388, 0.3677685...   \n",
       "8   [0.7066115736961365, 0.8140496015548706, 0.809...   \n",
       "9   [0.3305785059928894, 0.3388429880142212, 0.413...   \n",
       "10  [0.43388429284095764, 0.5743801593780518, 0.68...   \n",
       "11  [0.44214877486228943, 0.42975205183029175, 0.4...   \n",
       "12  [0.44628098607063293, 0.6694214940071106, 0.69...   \n",
       "13  [0.5702479481697083, 0.6570248007774353, 0.714...   \n",
       "14  [0.5330578684806824, 0.7561983466148376, 0.764...   \n",
       "15  [0.42561984062194824, 0.7685950398445129, 0.75...   \n",
       "16  [0.6776859760284424, 0.7190082669258118, 0.756...   \n",
       "17  [0.5330578684806824, 0.5123966932296753, 0.578...   \n",
       "18  [0.7148760557174683, 0.7190082669258118, 0.723...   \n",
       "19  [0.7809917330741882, 0.8512396812438965, 0.876...   \n",
       "20  [0.6900826692581177, 0.8347107172012329, 0.859...   \n",
       "21  [0.7355371713638306, 0.8429751992225647, 0.880...   \n",
       "22  [0.6570248007774353, 0.7603305578231812, 0.752...   \n",
       "23  [0.7603305578231812, 0.8388429880142212, 0.818...   \n",
       "24  [0.6859503984451294, 0.8305785059928894, 0.859...   \n",
       "25  [0.7685950398445129, 0.85537189245224, 0.87190...   \n",
       "26  [0.702479362487793, 0.7644628286361694, 0.8016...   \n",
       "27  [0.7148760557174683, 0.7396694421768188, 0.735...   \n",
       "28  [0.4793388545513153, 0.6322314143180847, 0.760...   \n",
       "29  [0.7190082669258118, 0.702479362487793, 0.7066...   \n",
       "\n",
       "                                       m:val_accuracy  m:num_parameters  \\\n",
       "0   [0.49180328845977783, 0.6721311211585999, 0.77...                18   \n",
       "1   [0.5737704634666443, 0.5901639461517334, 0.622...                18   \n",
       "2   [0.44262295961380005, 0.4590163826942444, 0.47...                18   \n",
       "3   [0.7868852615356445, 0.7868852615356445, 0.786...                18   \n",
       "4   [0.37704917788505554, 0.37704917788505554, 0.3...                18   \n",
       "5   [0.7868852615356445, 0.8032786846160889, 0.786...                18   \n",
       "6   [0.5409836173057556, 0.5409836173057556, 0.540...                18   \n",
       "7   [0.2295081913471222, 0.21311475336551666, 0.22...                18   \n",
       "8   [0.7704917788505554, 0.8196721076965332, 0.803...                18   \n",
       "9   [0.32786884903907776, 0.39344263076782227, 0.3...                18   \n",
       "10  [0.5245901346206665, 0.6721311211585999, 0.770...                18   \n",
       "11  [0.39344263076782227, 0.39344263076782227, 0.3...                18   \n",
       "12  [0.7704917788505554, 0.7704917788505554, 0.770...                18   \n",
       "13  [0.7704917788505554, 0.7704917788505554, 0.770...                18   \n",
       "14  [0.8032786846160889, 0.8032786846160889, 0.819...                18   \n",
       "15  [0.7704917788505554, 0.8196721076965332, 0.819...                18   \n",
       "16  [0.7540983557701111, 0.7704917788505554, 0.754...                18   \n",
       "17  [0.6065573692321777, 0.6393442749977112, 0.672...                18   \n",
       "18  [0.7704917788505554, 0.7868852615356445, 0.803...                18   \n",
       "19  [0.8360655903816223, 0.8196721076965332, 0.803...                18   \n",
       "20  [0.7868852615356445, 0.8524590134620667, 0.819...                18   \n",
       "21  [0.7868852615356445, 0.8360655903816223, 0.836...                18   \n",
       "22  [0.8032786846160889, 0.8196721076965332, 0.819...                18   \n",
       "23  [0.8196721076965332, 0.8360655903816223, 0.836...                18   \n",
       "24  [0.8032786846160889, 0.868852436542511, 0.8524...                18   \n",
       "25  [0.8196721076965332, 0.8524590134620667, 0.852...                18   \n",
       "26  [0.7704917788505554, 0.7704917788505554, 0.852...                18   \n",
       "27  [0.7704917788505554, 0.8032786846160889, 0.803...                18   \n",
       "28  [0.7540983557701111, 0.8032786846160889, 0.852...                18   \n",
       "29  [0.7704917788505554, 0.7868852615356445, 0.770...                18   \n",
       "\n",
       "    m:num_parameters_train  \n",
       "0                     1217  \n",
       "1                     1597  \n",
       "2                     1939  \n",
       "3                     3193  \n",
       "4                     2395  \n",
       "5                      989  \n",
       "6                     2167  \n",
       "7                     4751  \n",
       "8                     2433  \n",
       "9                     2623  \n",
       "10                    3459  \n",
       "11                    2433  \n",
       "12                    1293  \n",
       "13                    2015  \n",
       "14                    1559  \n",
       "15                    2471  \n",
       "16                     913  \n",
       "17                     571  \n",
       "18                    1369  \n",
       "19                    2205  \n",
       "20                    1939  \n",
       "21                     837  \n",
       "22                    1825  \n",
       "23                    1179  \n",
       "24                    4105  \n",
       "25                    4105  \n",
       "26                    2471  \n",
       "27                    1711  \n",
       "28                    1255  \n",
       "29                    1407  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = search.search(max_evals=5)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default configuration has an accuracy of 0.820. \n",
      "The best configuration found by DeepHyper has an accuracy 0.852, \n",
      "discovered after 33.27 secondes of search.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'p:activation': 'hard_sigmoid',\n",
       " 'p:batch_size': 75,\n",
       " 'p:dropout_rate': 0.3131586959081994,\n",
       " 'p:learning_rate': 0.0061972641193831,\n",
       " 'p:num_epochs': 17,\n",
       " 'p:units': 34,\n",
       " 'objective': 0.8524590134620667,\n",
       " 'job_id': 12,\n",
       " 'm:timestamp_submit': 24.85241198539734,\n",
       " 'm:timestamp_gather': 33.27014112472534,\n",
       " 'm:loss': '[0.772885799407959, 0.6148455142974854, 0.589241087436676, 0.5471585392951965, 0.5306645631790161, 0.47473737597465515, 0.43660449981689453, 0.4510563910007477, 0.410198450088501, 0.3966231644153595, 0.36866071820259094, 0.37438079714775085, 0.37871572375297546, 0.35891813039779663, 0.3588075637817383, 0.33439165353775024, 0.3641141951084137]',\n",
       " 'm:val_loss': '[0.609428882598877, 0.5143787264823914, 0.4708523750305176, 0.4455874562263489, 0.42168256640434265, 0.4029122591018677, 0.39155715703964233, 0.3871890604496002, 0.3851461112499237, 0.3790770173072815, 0.3721647560596466, 0.3687947392463684, 0.3666684627532959, 0.36339071393013, 0.36051642894744873, 0.3616732954978943, 0.3629875183105469]',\n",
       " 'm:accuracy': '[0.44628098607063293, 0.6694214940071106, 0.6983470916748047, 0.7272727489471436, 0.7231404781341553, 0.7479338645935059, 0.7727272510528564, 0.7809917330741882, 0.8140496015548706, 0.8223140239715576, 0.8512396812438965, 0.8512396812438965, 0.8264462947845459, 0.8347107172012329, 0.8264462947845459, 0.85537189245224, 0.8429751992225647]',\n",
       " 'm:val_accuracy': '[0.7704917788505554, 0.7704917788505554, 0.7704917788505554, 0.7704917788505554, 0.7868852615356445, 0.8032786846160889, 0.7704917788505554, 0.7868852615356445, 0.8196721076965332, 0.8524590134620667, 0.8524590134620667, 0.868852436542511, 0.868852436542511, 0.868852436542511, 0.8524590134620667, 0.8524590134620667, 0.8524590134620667]',\n",
       " 'm:num_parameters': 18,\n",
       " 'm:num_parameters_train': 1293}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_max = results.objective.argmax()\n",
    "best_job = results.iloc[i_max].to_dict()\n",
    "\n",
    "\n",
    "print(f\"The default configuration has an accuracy of {objective_default:.3f}. \\n\"\n",
    "      f\"The best configuration found by DeepHyper has an accuracy {results['objective'].iloc[i_max]:.3f}, \\n\"\n",
    "      f\"discovered after {results['m:timestamp_gather'].iloc[i_max]:.2f} secondes of search.\\n\")\n",
    "\n",
    "best_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGiCAYAAAAfnjf+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACfqElEQVR4nOzdeXxU9bn48c+ZPclkT0gChIR93xdZFAXZFdxQWi2KYq2l7q2tXuv9XdSWq7WKtsWrV5HWonLdrbKIFQQFFdkEgbATCAnZ18ns5/fHSSYJWWcyWRie9+vFi5kzZ86cyUkyT77f5/s8iqqqKkIIIYQQFzhdR5+AEEIIIUQwSFAjhBBCiJAgQY0QQgghQoIENUIIIYQICRLUCCGEECIkSFAjhBBCiJAgQY0QQgghQoIENUIIIYQICRLUCCGEECIkSFAjhBBCiJAQUFCzYsUKevbsicViYfTo0WzdurXJ/f/2t78xcOBAwsLC6N+/P//4xz/q7fPee+8xaNAgzGYzgwYN4oMPPgjk1IQQQghxkfI7qFmzZg0PPPAAjz32GLt37+ayyy5j9uzZZGZmNrj/Sy+9xKOPPsp//dd/8eOPP7J06VJ+9atf8a9//cu3z/bt21mwYAELFy5k7969LFy4kJtuuolvv/028HcmhBBCiIuK4m9Dy0suuYRRo0bx0ksv+bYNHDiQa6+9lmXLltXbf+LEiUyaNIk//elPvm0PPPAA33//PV999RUACxYsoLS0lHXr1vn2mTVrFrGxsbz11lt+vykhhBBCXHwM/uzsdDrZuXMnjzzySJ3tM2bMYNu2bQ0+x+FwYLFY6mwLCwvju+++w+VyYTQa2b59Ow8++GCdfWbOnMny5csbPReHw4HD4fDd93q9FBYWEh8fj6Io/rwtIYQQQnQQVVUpKyuja9eu6HStS/X1K6jJz8/H4/GQlJRUZ3tSUhI5OTkNPmfmzJm8+uqrXHvttYwaNYqdO3eycuVKXC4X+fn5pKSkkJOT49cxAZYtW8bSpUv9OX0hhBBCdFKnT5+me/furTqGX0FNtfNHQlRVbXR05PHHHycnJ4fx48ejqipJSUksWrSIZ555Br1eH9AxAR599FEeeugh3/2SkhJ69OjB4cOHiYuLC+RtiSBxuVxs2rSJKVOmYDQaO/p0LmpyLToPuRadi1yPzqOwsJB+/foRGRnZ6mP5FdQkJCSg1+vrjaDk5ubWG2mpFhYWxsqVK3n55Zc5d+4cKSkpvPLKK0RGRpKQkABAcnKyX8cEMJvNmM3metvj4uKIj4/3522JIHO5XISHhxMfHy+/LDqYXIvOQ65F5yLXo/MJRuqIX5NXJpOJ0aNHs3HjxjrbN27cyMSJE5t8rtFopHv37uj1et5++22uvvpq39zZhAkT6h3zs88+a/aYQgghhBDV/J5+euihh1i4cCFjxoxhwoQJvPLKK2RmZnL33XcD2rRQVlaWrxbN4cOH+e6777jkkksoKiriueeeY//+/fz973/3HfP+++9n8uTJPP3001xzzTV89NFHfP75577VUUIIIYQQzfE7qFmwYAEFBQU88cQTZGdnM2TIENauXUtaWhoA2dnZdWrWeDwe/vznP5ORkYHRaGTKlCls27aN9PR03z4TJ07k7bff5ve//z2PP/44vXv3Zs2aNVxyySWtf4dCCCGEuCgElCi8ZMkSlixZ0uBjq1atqnN/4MCB7N69u9ljzp8/n/nz5wdyOkIIIYQQ0vtJCCGEEKFBghohhBBChISApp+EEEKIC1WJ08O27EocxrCOPpV2sSffjkEHQ+Isze98gZORGiGEEBeVjGInewudHE8ZRanT29Gn06aOljj5d1Y5SWEXxxiGBDVCCCEuKsPjzUQatUJvH5yqwO4JzcDG4fGy4XQ5XhUOFNX0SixxejrwrNqWBDVCCCEuKma9jp/0tGJwO8l3ePnwRBkeVe3o0wq6zWdtlLm8RBp1TEwOByCz3MXLB4rYcrYCbwi+ZwlqhBBCXDQcVaMyUSYd3fMOYNTByTIXGzLLUUPoQz6z3MXufDsAs3tYMeq0kalTZU68Kmw7V8mao6VUuEJrlEqCGiGEaIXcSjfrMsvYfLaio09FNMOrqrxyoIi/ZxRT6vQS5qrgqu7hKMAPhQ62n6vs6FMMCpdXZV1mGaBNtaVFmnyPXZYSwdw0K0YdnCp3sSqjmDPlrqCfQ0cFiBLUCCFEK1S4vOwtcPBDgT0kh/NDyZkKNxVulSKHh4iqnJreUUamd49AAcIMrW+o2Bl8lW2jyOHFatQxpVtEvccHx1m4rV8M8WY9ZS4vbx4pYUduZdACkaMlTv55pIR8uzsox/OHBDVCCBGAjGIHPxba6RFpxKJXsLlVzpS3/y9x0XIZxVqybJ9oE/paHaFHJYZx58AYRiaExhJvq1GHQYGZqRFY9A1/zCeEGbi1fzQDY0x4gX9nVXCstPUjNtXJyVkVbvYVOJp/QpBdHGu8hBAiiGxuL+tPl1Pp1v6y7RttYl+hg0PFDnpEGjv47PznVVVWHykB4Oa+0XU+8EOFqqocLnYC0D/GVO/xeEvNx2Gl24vdoxJr1rfb+QXT2C5hDIo1E2FsetzCrNcxLz2S7vl2zla46R3V+u/dTVlacnKsWcelKeGtPp6/ZKRGCCH89PmZCirdKokWPQNizPSPMQNwuMR5QSabHi91kVXhJqvCjct74Z1/S5y1uSlzeTHpFHpG1g9qqhU7PPzjcDFrjpZgu8CSaGt/7zUX0FRTFIXRiWFcnWZFqQpmvaqKJ4Dvg1NlTvYUaMnJs1JrkpPbkwQ1Qgjhh6MlTg4UOVCAOT2s6HUK6ZFGTDqFcpeXs7YLbwpqf6H2QTQm0dLodMWFLqNqlKZPtAlDEx+2Rp2CV4Vip5d3j5deMEFefqWblYeKOR1g0m91QOPyqnxwooy1fq4G05KTywEYEW+pk5zcnkLzu1cIIdpAdb4AaEP8KRHacL1Bp9AnWvslXv3heaGodHs5UqKd89AQLaOvqqovn6ZfA1NPtUUYddzUOwqLXuGszc0np8rIqnCRVeGqs/zZ7vb6tmdVuCh2dFxBO6+qsu50OXl2D9+cs7XqWDk2N0dLnPxY5OCrnJYfa2u2jWKnVhNnSrf2n3aqJjk1QgjRQrXzBS47L1+gf4yJbJsLawuH/TuLg0UOPCokWvR0CdNzskwLcNI76C/ttqACl6dEcKTEQa8WvK94i4Hre0Wx5mgJGcVOX6A6K9XKiAQt8Mu2uVlzrLTO86Z0DeeSpPb/QN+VZyerwo1JpzAz1dqqY6VajcxMtbL+dDlf51QSY9IzNL7pYNejqr4RopmpVswdONonQY0QQrRAod3TZL5Av2gT/aJNvmH8C8X+Qm0EY2i8hd35dj47U0HXcAPp/UMnqNEpCoPizAyKM7f4OT2sRq5Jj2Rrts03BWWqdc0NOoUYk/bhrQIlTi+bztqINukZENvy12mtYoeHL7O1GklTuoUTZWp9cvOIBAslTg/bz1WyLrOcSJOuySBXrygs7BfN0RKnb8Syo0hQI4QQLRBn0fPTPlGcqXA3mC9woQUzAAV2N2dtbhRgcNUH8cYzFZy1uSmwu+usCLoY9Ysx0y+m4QAl1Wrk7sFxvvsbz5SzM8/Ov06VYTXq6G5t+1Vwqqqy/nQ5Li+kWg2MaGZExR+TU8Ipdng4WOzkgxNlLOwbTUITTTF1itLo16o9XVjjpEII0YHSIk1MSm56esHtVTlRemGsgjLoFMYkWhgSpy3/jTDq6FW1rLd6BKczUFWVoyVObG7/VyMV2j1sy7FR0MaF4K7sFkGfaBMeFbIqgl+htyH7Ch2cLHNhUGB2amRQA2tFUbgqLZLuEQYcHpUPTpbVKy6ZV+lmS3YF7k6UTC1BjRBCNCGv0t3iJFCPqrLix0LWHCsl3975OyFHm/RM627lqrRI37bqZOH9hY5OUyH5h0IH7x4v5e2jJX43njxY7GBLto0vstq2jYVOUZiXFsn1PSPbLa8mp2ql3WUp4cRZgl9Tx6BTuL5XFN0jDFzVw4quVtDkVbXVTttyKtnUiVqESFAjhBCN8HhVPj5ZxmuHijhe2vyqJr2ikBKuDdFfaKugqvWJNmHWK5S5vGSWtc+IQ1NUVfWt6Mmt9PCdn/2ZDhVpI07922FqxKSvOwXj8qptOooxvXsEV/WwMrZL21VCDjfouKVvNF0j6k6nfZ9n56zNjVmnML4NX99fF/eEqeg4OSfhveegrCh4x9TpYPAkmPNzuADzGy4EPxTYMeoUBrZjIqTbq7L9nM1Xvbc9Zdvc5Nk9GBRtldDRkuYDleoZku/zKutMl3i8XnJie/H52Ur0uo6f2sm3ax9IVqOu3rRFpFGHw+Nhw5nyJgvVtYdSp4cih/Z1TLTo/Ur2LXJ4yLN7UNCqPrenCpdW5ybGpFXtDdbUkNOjYtBpI0OKojS7MikYap97js3NvkI7e6s6gE/pFkFkEJKTg0WCGtH+3C4toMk7Hfxj71gH3frAiKnBP3YDylwe9hc4GJ0Yhkkf2oFURrGDtVXFtaxGHantkAgJ8OXZCnbk2dvltRrjVrX8BX/YPSq78s8778gUigovnBGcIoeXIkfHfu1rs7m9mP2oUltdmyYt0kiYoX0nJgrsHs7Z3GTbICbbxuVd6zeW9JdHVfngRCkGncK89Mh2r9hbUdX80lk1+tTDamR4fMcnB9cmQY1of1vfrQloLBEQEd36Y6oqFGZrt9evhN4jIDKuyacEw79OlpNZ7iLb5ub6XlFt/nodpdLt5bOqonMAazPLuGNAbJv/Us2qcPkCmjGJFsztGDhmFDvJt3uINesYGOPfUu0fCx0UO72kWQ2+VTBej5cjR4/Qt09fdB1ctfeczc3RUhdheoWRCeZ6701VVcrdKlaD0qGruirdXnbla4FJpFGhzKXyxdkK5vSIpNzlbbYmUEYTvZ7aWo9II7N7WPk0s5zt57R6L8MTAh9VUVWVz06Xc6LMhVGnjUJ1aWI1UluIMOqYmBzG5rM2LTm5h7XTrfqToEa0r5wTsPU97bZOD7c9CSk9g3Ps956HfVvAXgGfvgILftfm01CZVQWnDrdgWuJC9u+sCircKnFmPS6vSpHDy9ZsG1O7tf6vz8a4vapvZGhInJlp3VtXVMwfdo+Xb6tyN+alRfoqB7dUpFHP+tPlOLxwWYr2NXK5XBTvPM3EpKEYjR3b9HL1kWIAxnUJY0Izq7k6kpak7QUFJiSFs/pICT8UOChzejlT4WLxgFhiGmk6WeL0kF2VSNsvumNGE4bGWyh2evg6p5L1p8uJMunoGRVYgPVtbiV7C7T2HPPSI9s9oKl2SZcw4sx6ok36TtnwUxKFRfvxeOCjv4K3alXIpdcHL6ABmLUYwqtGSw59Cwe2Be/YDajd8G1R/5g2fa2OdLzU6Vvee1Wa1VexdEduJWfbcOnq1zk2CuweIgwKV7Zh8NSQjCInbhXiLXqSw/3/8OgbbUJByz8odXauVVDFDg+ny7UP+8EtyE9xe1Ucno5p7JgYZuCmPtHc0DOKVKuR0YnaSEdmuQuXF9afbrw/UV6lB5NOIdVqaHFzx7ZwaXI4g2PNqMAHJ8rIrfR/afnBIgebz2rJ0tO6R9C3g4I00PJr+sWYSQrg56I9SFAj2s+2DyH7uHY7MRUm3xjc40dEwZy7au5/+gpUlDa+fytVL9k16xWSwjrfXyzB4PB4WV81WjIm0UK3CCN9ok2+X9JrM8vbZHVHjs3NN1UjJTNSrS3Kh6hwefnoRKmvzH9r2D1aN+ehcfWnZloiwqhjdg8rdw6ICUqF12CqDlDTI43Nntv3eZX8ZX8hO3L9y6up7pG1tyA4+Tj6qmnOy1MiiDbp8KigACfLXI3mOvWJNnHv0Diu6hHZ4OPtRVEU5vSw0sNqxOlVWXvKv0aRZ8pdfHKqDNB+Bkcndp6VRp2RBDWifeSdgc1rtNuKDq65BwxtMAQ/eCIMuES7bSuF9a8F/zWqVP/F1SVM3+nmlYNl81kbpS4vMSYdk1NqRkumdY8g3KCQb/ewrZUN9M7nUVXWZpahAgNiTC1eirslu4KDxU7ePlra6voqlySFc+/QOEa2IgdiWLylyQqsHUFVVV9H7iEtGKWx6BUcHu05Lf0g9qgqH54oY3e+nXWZ5RQGUK+nehl32XmjXCa9wuyqkcLqs/l3VgXlroZHkow6pdHpqfak1ylc3zOSvtEmru1ZsxIqr9LN2QpXo19bt1flo5NleFRt9K8tp3tDhQQ1ou15q6adPFVTFePnQvd+bfNaigJX3QWWqvyLfVsgY0ebvFR1UBNvNrA9x8bbR0s6VWXN1jpV5mR31eqd2T2sdVZ3hRl0zKjKcfkmp5JztuBVa/3mXCW5lR7C9ArTW5hHo6oqx0trpsKOtaCmTHOMOqVDG/O1hXK3F0XRehi1JM+kX7QZk06h2OnlTEXz11hVVTaeruBEVX2byQEWhTtW6mLzWRuvZxTXK7aXHmViWNWKG70CDo9aJ4kd6LDpsqZYDDpu6BVVJ8jalmPjH4dLeO1QMd/lVtbpAg5a8btre0bSO8rIvPTIOsXvRMNC6ydWdE7frYUzGdrtuBSY8tO2fb3IOJh1e839T/4HKoNf8XJicjg/6RPFqEQLO/PsnCxzcaa844uVBYPLq1ULBRgRb2mw19GAWDP9ok140VZD+VvptSF5lW625dTkDrQ0FyLP7qGs6gPh0uRwUv1M7K2mqio5NnfQWhycLHPy4YnSoE3DtFakUc9dA2O5fUBMi0oQmPSKb+VQ9QhPU77NrfQ1/by+ZyQTA0xC/j5Pm3ocEmdB38AH+dSuEViNNdNQh0ucviJ7AO8fL+N/DxT5Okd3RqqqYtIrGBRtKvuLrAr+tr+Q94+XcrTE6Rtt7BZh5Mbe0e2+fPtCJUGNaFuFOfDv1TX35/0KTO2Q5DZ8CvQZqd0uK4TPVgX9JcIMWufaLmEGekVrH6LBGCHoDLacraDY6SXSqGNKt8Y/mGakWrHoFc4FUOn1fF5VW+3kUaF3lJFBfhT4q65H0ifaxKUp4VgCrElyutzNqoxi3jhcEpTA5pzNzaFiJz92oj5KiqL4tWqleprqUJHT1626IXWSWbtF1KmsW+r0kN/C3kv5lW5OlrlQgFGNTP9ZDDpm1ZqGsugVqj/zbW4vmeUuChweIjswQbg5iqIwu0ck9wyNY2ZqBCnhBrxoAdq7x0s5Udp5A7LOrPNecXHhU1X4+G/gqvqFPnYWpA9un9dWFLj6l2CqSqrb/Tkc29NmL9erapnmsRD4RVS7NsysVGuTUzBWo45p3bV5/q9ybC3+4GrIjtxKsqvKrs9K9a/+ha8eSSurxu6rGo1ICFKeVHU+0OlyV0DNGIOp1OkJaHq0h9VIlEmHw6typJHWD06PymdnahLKx9Qqm3+y1MmrB4v5+GTLRvN2Vk159o02NZkP0yfa5At8ww2K72fwSIkTFS3XrTPk0zTHotcxMiGM2/rHsHhADGMTLYQZFD7NLMPeCafROjsJakSbUXb/G07u1+5EJ8K0W9v3BGISYXqt1/x4BThaN5pQ7WyFi01ZFRyrqk+THmlEBxQ6PBS1sPlhZ3R+bZjeLQgSBsea6R1lxKPCuszygJJ0C+0etmZrf+VP7e5f2XVVVZmZamVMooW+0SZUVeXHQjv/PFzsVyDh9Ki+4Ki6qWNrxZj1JIXpUYGjpW3bJbo56zLL+cv+Qo6U+DdqpCiKb7RmXyNTUCa9wk96RzMi3lIvmTUxzIBO0fo2fdvMaJ7d7fVNc41pwSqf6oT1QoeX7VUJ69WjdgPaoddTsCWGGbiyu5V7hsTxi0GxWEIsp6s9yFdMtAmLswL9v9+o2TB3CZg7YCni6BmQPkS7XZIH//5nUA57oszFt7mVHKiax7fodb7KsRfiFJTHq+LxqmwLoDaMoijMTLVi0ilkVbjZ6WdLA1VVWXe6DLeqBYfD/OjtU/36qVYj07pbfdNO3+VWcqbC7etP0xKHSxw4vSoxJh3dI4K3aql6tOZIB47ilbk8nCxz4fCoJFj8f29D4yxMTAprMnE7KdzArPM6OYO2vL16NE+rPdR4cLe3wI7Lq42ypFqbP8/wWgnr23Iq2XK2wpcw3hFVhINFr4Reknp7ka+aCD5VZfjp7SjOqr/KRkyFPiM65lx0Opi3BAxVv+C+WwunDrT6sLWXc1frHaUFNccvwOrC289V8tKBIrb5WRumWpRJ7/sL/cuzFX6NVu3Ot3O63I1Rh9/TTg1RFMX3V/6ufHuLE5ir67cMibMEdYl+9YdrZrkbj9Ix0yE/FjpQge4RhoCqwMaa9UzuGlFnJZPbq/Le8dIWJccPjjXTK1IbzVub2XidFrcKRh2MTgxr8TXoH2OiX7QJFXzfv3oF4gMI3sSFT4IaEXTK/q0kl57R7lhjYebtTT+hrcWlwJU/q7n/0V9r8nwCVB3UJNWqQ9IryoRRpxXjC9bqmfZS6fFir5qq8ac2TG3D482kWY24q6ahWvI1KHF6fMmlV3SN8DsHotjhYcPpck6dV3BvYKyZcINCmcvL4UbyQGordWojGdCy+i3+iLcYSLDo8QJl4W3fj+x8Wm0a7fs9WNNqqqry6akyjpQ4+eBEaZMJxFA1mtej1mheIyNok5LD+dXgOAb7kSSuKIovYR0gTK8VuxMXp4BC2RUrVvCnP/2J7OxsBg8ezPLly7nssssa3X/16tU888wzHDlyhOjoaGbNmsWzzz5LfHw8AKtWreL22+t/8FVWVmKxtH1bddECbhesfQXOnWp2V33t7ttX/wLCOsEvmEvmwI9fa0vLC7Phfx7Smmk2pLRAq60THgVGMzhsWiG/2GRQFLwqzK2qy5K0w6CtKY1JImH+Q9w/NB5DK5ZeFjs8HK1KdAwGj8dDYWQKO/Md6PWND/ufLnfhVrW/clpaG+Z82moOK68dKiKz3MVnZyqIayZIySjWpny6RxgaXenS3PN359spsHvqLDs36BRGJlj4OqeS7/MqGdjMh+ShqsAn1Wpok+TS/jEm9MVOdN72T/zMqXSTb/dgUKB/bOumZI6VOH3L0w+XONEpMLeF3aKjTXqu6BrOZ2cq+PJsBX2iGk4EDmTlmtWo48puEXyaWY7Tq1Lm8rIjt+n8nZb+bLSUSa/lHjW0BF20H7+DmjVr1vDAAw+wYsUKJk2axMsvv8zs2bM5cOAAPXr0qLf/V199xa233srzzz/P3LlzycrK4u677+bOO+/kgw8+8O0XFRVFRkZGnedKQNOJ7NwIuz5v0a7VP9LeQRPRRcbDO39ufOdeQ7W8l7am08M1v9KCGY8bCs42/5yKkrr3K49qhwK6Vm8rrvrfaUdRtJoTgXJ5Vd4+WkKxM8gffLG9OJfTstwSL+BuxShTjFnP5JQI/p1V4Svc1xyDAnN6RAY05dNUF+aRCWFsP1dJVoWb7ApXk00pxyRaSLTo2+wD6dLkcMYnmFh7uIBih4eiisavcbcIY1B7Fe0r0EZp+sWYW514ur/QXqd56+xUK+kN1DBqzMgEC4eKnSSH1+3HVGj3UOnx0i3A+kKgjbAdLHJwvMzlG/1rlh8/Gy1RaPcwRar+dii/g5rnnnuOxYsXc+eddwKwfPlyNmzYwEsvvcSyZcvq7f/NN9+Qnp7OfffdB0DPnj35xS9+wTPPPFNnP0VRSE5ODuQ9iPZw4Gu/di8Kj8c64w50Ocfgx68a3/HHryCuK/Qc0soTbIHEVJjzc9jwOjjbthhascNDtEnn1wd1dW2YCIPSYLG7QHi9Xs6ePUvXrl3R6ep+oHm8KkdKnXhV6BlppMjhodjpZX+hg0mt6Nw8OtGC3eOlyNGy4GxAjCmgqrOlTg9nq7swNxDUWI06BsaY+bHIwfd5duY28YGpU5SAuye3RO3vg2NlbjY38UG6oHcUPY3BORdVVTlbVQk4GNNqQ+MtHKwKJCclhzE03r8/PBVF4Sd9ouolE28/Z2NfoYOJSWFM7hpYUKAoCnPSItmaXUEjXRPqaOpnw19ur8rhEiff5VYyIMbkd1d3ETx+BTVOp5OdO3fyyCOP1Nk+Y8YMtm1ruCPyxIkTeeyxx1i7di2zZ88mNzeXd999l6uuuqrOfuXl5aSlpeHxeBgxYgRPPvkkI0eObPRcHA4HDkdNXkRpqda40OVy4XJd+LVCOpXyYgynDqIAanw33L94TqsDcz5VBacdl87Alo0bmW4KQ/F4mv0m827/CE/3/m1x5vUNm6L9a4T+/efQHfwGAPeNv0XtNwZl/1cYPnrRt8+eK5awPnok4xLMXJZc65e6S+vh8saxcvLsXhb1tRLfwqmMsza3rzbMjG5h9IoMzi9Fl8vFxn2HmT4qDaOx7jG/OmfHq0KCWcd1PcI4UOxifVYl+wvsjI0ztCpZdnyCfx/KgfzMHqzKE+karseCF1cDn2Qj4gyUONz0idQ3+hqqqrZL767q17coXlKaaICqVz2+fY+Wuog36wJK7q02p7uF7bkOulkC+zrX1s0CI+NMmPUKl8QbAz5edRq5V1UpdXp9qwjTInStOkczMC2lZYFWUz8bgfgUlUMlLj49VcbPelt9TThF84L5ma2ofmQ0nj17lm7duvH1118zceJE3/Y//vGP/P3vf683fVTt3Xff5fbbb8dut+N2u5k3bx7vvvuu7xvpm2++4ejRowwdOpTS0lJeeOEF1q5dy969e+nbt2+Dx/yv//ovli5dWm/7m2++SXh44H9livrS8w4x/Iz2QZ+RNIxDXUc1uF9sRS4Tj2wgOyaN44mDKI5IQO91Y3LX/6tUUVUuPbKOMJcNFfh80A3YzB3bTdfodjBz/xr0qheHwcKGITehKtpfcP1y9jIwezcAHkXHln5XUxCZjNFTPwk1M3EQFWGxdCk6QXxZ89NcXhROpIzAaQwnujyXroVHgvvGGuDWGTnadTSqTk/3vINEVhbiVXQc7jYOVacnLecHwp1lbX4erXGqyxBslugWf50b4kXhRPIIrPYiEksy0amdp9iZ3RjOyaRhKKh0LThCZGVhi57n1JuxWaKJqcht4zNsHYchjOz4PjiM4Xh1BiyOMnqe+6GjTytgbp2B4ykj8ehNJJRkklhyuvknCQBsNhs333wzJSUlREVFtepYAQU127ZtY8KECb7tf/jDH3jjjTc4dOhQveccOHCAadOm8eCDDzJz5kyys7N5+OGHGTt2LK+91nAHZa/Xy6hRo5g8eTIvvvhig/s0NFKTmppKdna2LwFZBId+9ZPoTu4DwLX4GUhOb3A/3br/Rb9rIwC7ekxiwE+WNPkXkO7r99H98CXeMbPwDp8Cpo7NodLt/Az9+lcB8Iybg3f6opoHVRX9p/+Dbu8m7W5YJO5Ff4C4+lOmO/MdbM6x0yNCz409m0+6/eqcnW/zHIQbFBb18W8pdXNcLhcbN25k+vTpda7FpuxKdhU4SQ7Tc3OvCN9IxbozNg4UuxifaGZSUufNabO5vfzPIa2T98/7RRJlCuxrdrjExb9O27AaFH7ev20bBjZ2LRpT5vLyyWkbZ23auMbYBBOXJlmaPMdjpS7WnbHh8MIN6eGkWzvvNEhupYfVx8qpDiPndA9jYDvWlvH3erRERomTT05XogN+1sdKYgDTqhejgoICUlJSghLU+DX9lJCQgF6vJycnp8723NxckpKSGnzOsmXLmDRpEg8//DAAw4YNIyIigssuu4ynnnqKlJSUes/R6XSMHTuWI0ca/4vVbDZjNtefIzYajUH7BhVoybKnftRuxyZj7N6n4aknlxMOaFOQqtFMdkw6Q5u7FpdeD5NvRK/T0Sl+9Pdv8d3Uj5yG/vxzn7dE6yN1fC9KZRnGNctg8X9DRN0fwn6xOjbn2Dlj8+DV6ZssopVjc/Ndnhacz0y1EhXWNlVQa/9clDo97C3URpgu7xqByVTzQTIxJYKxXVSSw1s3/dTWKpwuokw6wgw64iOa/5pVuLzsKbCTYNHXWa5+oERLKB0Sb8Fsap8P1Jb+joozwi39TGzKquD7PDs78p3k2L1ckx6F9bxEYq+qsjXbxvaqOi1dww10iTBjNHaKn6wGdTMaGZ/kYdu5SqwGHYPjwztkyiaYnxmD4w0cLvVwuMTJZ1l2bu0fLZ21WyCYn9l+/XljMpkYPXo0GzdurLN948aNdaajarPZbPWSsPR67QetsUEiVVXZs2dPgwGPaGeHvoPqIflBExoOaAAO7wC71glbHXAJbn0LvkkNRq04XmeQnwVnDmu3k9IhpWf9ffQGTsx6gJKY7tr9wmz4v2e0XKJaYs06Ykw6vCqcKmt8rtijqqzN1EYbAq0NE4htOZV4VG35cvp5uTsJFgMpEcZOHdAAdI0wcvegWG7q3bK/6n4osLM128a2HJvv906Fy+urPjs0yLVpgkWvKEzrbuXa9EhMOoXT5W5er1oyX63C5WXN0VJfQDMqwcItfaOJ9qPVREeZlBzOFV3Dua5XZEjkoNSumZNT6ea7ZpaVi+Dz+xPloYce4tVXX2XlypUcPHiQBx98kMzMTO6++24AHn30UW69tabfzty5c3n//fd56aWXOH78OF9//TX33Xcf48aNo2tXbWHs0qVL2bBhA8ePH2fPnj0sXryYPXv2+I4pOtCB7TW3BzUcuAKwZ5Pvpnfo5W14Qm1kb835M/yKRnfLdBtZPfYe7GHRYLTApOvqBXqKovh6JjXVMuHbc5XkVnqw6JWAa8MEIsqkw6RTmJwS0WTw0tJKvB1FURTCWzhVNyLBgkGBc5UezlStBvqxSKuymxJu6PTVZwfEmrmtfzQJFj0VbpWTVcUGz5S7eD2jmFPlLow6mJceyYzUCydJVa9TGJ8U3qql3J1Ndc0cgK3ZTbeFEMHn90/yggULKCgo4IknniA7O5shQ4awdu1a0tLSAMjOziYzM9O3/6JFiygrK+Ovf/0rv/71r4mJiWHq1Kk8/fTTvn2Ki4u56667yMnJITo6mpEjR7JlyxbGjRsXhLcoAmYrgxNViXvRidC1d8P7lRfDUS2JlqgE1PTBcNDPJLlzp+DbT2HwROg9ItAzDtwJLWcIRQfDGg/KzlW6KQ2P58Tc3zIw1gIpvRrcr3eUiZ15do6XuhpcXZNf6ebrHG3qY3r3iKDWJWnOxORwRidaGp0W86oq60+Xc7jYyZ0DY+tNdXS0cpeXML3i1wd3mEHH4DgzewscfJ9XSarV6Guc2FlHac4XbzFwa78YdudXMraqC3a+3UO5y0u8Wc91PSNJCOvcwdnFonbNnLWZ5dzSV6ah2ktAPwFLlixhyZIlDT62atWqetvuvfde7r333kaP9/zzz/P8888HciqiLWXs0CrrQtNTTz98WTNFNfxyLTDwx6kD8Ppj2u2S/I4Jau74IxzfB+dOgjWm0d1yK7WvR2SPvtBEEmaq1ciIeAu9ooyo1BQkBC1oWJtZjkfV+kUN8qMkfLA0leejUxQK7B7sHq3b9SVJnWs14brMMs5UuLmqh5V+fkzZjU4MY2+Bg8PFTo6UOMit9KBXaLbacGdi0it1rsfweO3cB8aapAFiJ1LdFuK1g8VkVbjZlWdnTJcOaOh7EZKfAtG4g7WnniY0vt/ezTW3hzdeA6ZRqf0hpirR/NhuyDvj/zFaS6fXmm5OurbRXWwuL+VVtVASm6gzAmDUKcyq+tA9/y+07/PsnLW5Meu07tbtlb+y5WwFJ0qdLerJVF2obX+ho1P1sXJ4vL5u0/7WbukSZqCHVQsyfyx0MCbRwtA4S1BXm7U3RVEYkdD4qJvoONEmPVO6aQHol9kVFPvR5FUETn4SRMPsFXBsj3Y7Mh669Wt4v+wT2ugGQPd+kNDN/9fS6WHc7Jr7333q/zHaQXUTy1izLuAPkSKHhy1ntYTqqd0iiGqnZM5zldoqkzXHSlvUhmFgjBm9Anl2D+cqO88v42MlLjwqxJn1JASwXHZMorZM/WSZi8kpEcySxoeiDY2It9DDasTlbXmTV9E6EtSIhh3+XuuRBDBofOOrlCrLagKZQEZpqo2cpiXeAuzZDJUVgR/LH56WJ/GdqwpquviRt3C2wsXW7Arsbi9q1WontwppViPD4ttv2uOrc1r+yOBYc4tGOCwGHf2qkp33FbZtSwl/ZJRoy9/7x5gCGuHqE20iwaKnX7Sp2c7SQrRWdZNXgwKnyl3sLXA0/yTRKpJVJhrW0lVPvYbBr/4CZ49qPZwCFRYBI6bAjnXgssPuz2HiNYEfr6XeWKrlAI2YAkMv00aNGuHwqhgUSPIjqPk0s5wCu4dEiwGb28vpcjdGHczu0X7TTjZzJKfK3eiAS1Nanh8zJE7r83Og0MHUrhEdvqLG5VU5XlrdwDKwgFCnKNwxIEaSNkW7iTXrmdw1gi+yKvgiq4JeUcZ2G6G9GElQI+pzVMKRXdpta6yW89IURYFuDbez8MslV2lBDcB3a2H81aDTk2NzU9GSDnV+MpTkknZyPwDO4jxOp00ApfGplm7hRq5JN+BV4VhJ40u1a4s36ymwe9iVX0lOVWXYy7tGENOKXj7+UFWVvGhtZeKweItfeSg9o4xEGBQq3CrHSp1+JeW2heOlTlxeiDbpSGomp6kpEtCI9jYm0cKhIgdnbW7WZZYzJrH5pGGrUUdSuHxE+0u+YqK+IzvBU1Xca8AlTY5eBFVCN+gzUlseXpwLGTvISBnJByea70Gk97hIyz9EblR3ysNiW/RykzI2klZ1e3vyJWxvwesEKrNcm7rqHmFgdEL7tR84Ve7GZolGr8DEZP9WX+gUhXFdwnB6tQrDHS2juGaUprMXBxSiNp2iMCfNyuuHijlR5uJEE0U5a7updxS92rB7fCjq+N9UovM50IJVT5UVUFYAXXoE97UvudpX88az/RM+G6uNAMWZ9Zj0jX+QpeQcZuY3L+LSm9g2bhEn0hs+b6dHpcjhIdKg+Jp0qiic63tpm3xwq6pKbqUHFUgOM3BVWmS7fiB/U9WCYXicKaAh7860nHtCUhixZh39oi+cJdhCVEuwGJiVamVXvp3msrkcHi9FDi/rM8tZPDBGVrf5QYIaUZfToY3UAIRHQdrghvfb9yWs/V9I6Q2z7oC0QcF5/d4jIL4bFGRhL8rDXVlBfGQkt/ePwdBUTkf/ieC6HuNX73P59le43J0JM+/QWjHU8vmZcr7P85CYd4Socq2LsdJzKDeNaqSwYJX9hXa+PVfJoFgzE5L9+6B/73gpR0qc9I0x+b0MubUmdbHw/tFCLkns2A7owZAYZiBRisuJC9jQeAtD45sfqXV5VV47WESx08vmszZmpsoqvZaS8E/UdXQXuKoy9AdcAvpGPoSr2yJkHwNzEP+a1+lgxm1kz3uYv055EocxnDk9rPUDGq+nbs8l73m5MDvWawX9ivPqbM6xadNAfU9tq9k4ovlVW9k2N3l2Dza3/7k9vauGj4830TIhWLyq6lt6Dlp/p97Zu1rcTqAhHq9KRrGDf58pD8YpCiGaYdRpq6YAdufbOVXW9r87QoUENaKulqx6yjutrXYCSO4JyelBPQVHn9G8bxqAqugYm2ip3xemrAj+/v/g+w0123R6mLYQ5v0KqptpZh2Bl3/tm87yqirnKt0YPE4GZH0PgGqywMDxzZ5TbgDLuav1itLOp9DhadNlxBUuL28fLeWfh0vq9JvRqa1LsnZ4VD46UcaOPDt5le3fx6a68WdGsQOv1PkQF4m0SBMjq/Lv1mWW4/TI935LSFAjaricWrdtAIsVeg5peL9azStbVZumEZuybJS5vMSYdEzuGlH3wVMHtEDl1I+w/jUtcKlt1DRYvKymQnFlGfzzSdj0Ng6XmzSriRH5e7G4q7rnDpoApqaHg6vzYiCwoCbKpGdR/xjuHRKHsY2WRZ8ud/H6oWJf9+ZiR/BWi4Ubdb4GnfsL27fOhkdV+SKrgh8KHGw4LSNF4uJyRddwoow6ip1etma3U+2uC5wENaLGsT3grCq0NmAc6Bv4APd6tF5PoI2ODL0sqKdwqszJngLtHOb0iNSCgLzT4HbB1x/CqsehvEjbOTwKvA18eHftDb94FvqPrdqgwpdrCFvzR+Z31TEtf4dvV2X41GbPqcTpxeFR0SkEVMUWIDnc0CZLiVVV5bvcSt48UkK520uCRc9t/aN9QUiwVLdN+LGw/UZLypwe3jpSws487fthYlK4LMcWFxWzXuerer0jz05WRctWTV3MJOtO1GjJqqfj+6CsULvdZ1STzR/95fSorMvU/hofmWChR+lJ+PBNLdjq0gNya7q/03Mo3PBQ468fZoUFj8C2D+Hfq7WGmxWlWiDmqcq/iU5sUYJz9dRTgkXf6gJ01WXSg7ECyuHxsjaz3LfUeVCsmVmp1iZXiQWqd5QJi16h3K31XmrrZaYny5x8fLIMm1vFrFO4Ks2/5pVChIpeUSaGxJnZX+hgbWZ584smLnIS1AiN2wUZ32m3zeHQa3jD++2tNfXUggRbf2zJrqDY6SXKqOOKruGQ6ajpP1U7oLlsPkz5SfP1c3Q6uPR6rTDgpy9TecOvsZgsKLcthaJzuIty2VfowO2FsU100G3N1FNtm7MqOFDk4NqekXQ9P08oADvz7GQUO9EpMK1bBCMTLG22XNygUxgUa2ZXvp0PT5Rx16BYrEZtoDe30s3Zivq5NvEWPd0jDH6f0/YcG1uybahAlzA91/WMavdVY0J0Jld2i+BEqZMCu4evc2xcfv60vPCRoEZoTvwADpt2u//YekuhAbDb4KBW2wWLFfqNCdrLnyl38X3VNMOsHlatLkP6YEhKr2mYabHC9ff7/7o9h+L95XJW7C/GmFPIbf1jiI5N4pQulg3HSzHrFYbHWxod4TDpFeIter/aIzSk2Omh1OXlWKkzKEHNJUlh5FW6GdslLCjHa87QOC2ocXpVih0eX1BzqszFv7Manu+PNeuY0yOSVGvLz8+lqqhVrzcj1dpmeUhCXCjCDDpmpFr54EQZ35yrpH+MuVMUxOyM5KsiNC2ZejqwDdxVSwuHXNpw4BMAt7dm2mlInLlmakNRYObt8H/PQFIaXHs/xHYJ6DUKXaB1WlCJrPow7hVlJM6sp9DhYX+hnVGNlC4f1yWMcU2M5LRUrygTh4qdHCt1cVlKqw+HXlG4pmdU6w/UQsnhBi5PCeeszY3FUBNoxJh19D0vh8erqmSWuyhyeIky1aTulbu8hBkU9OeN3qiq6hvRuTQ5nK7hRvoEOS9IiAtZ/xgzA2IcHCp2sjazjNv6x9T7ORIS1AjQOlUf+la7bbRoBfAaEt9Vq11z+PugTj19nWOjwOEhwqBwZbfzhlV7DYPfvaEFOK1QXZ8mKawmYVdRFEYnWth4poLv8+xtOn0D+IK16l5WEcbA8vTzKt1EmXTtXmVUUZQGCw/2jTbTt4Eqv06PyulyF9G1Khmvyywj2+ZmSJyFYfFm4s169hY42Fdo56d9ojHoFHSKIgGNEA2Y3t3KqbIicis9fHOukkl+FgK9GEhQI+DkfqisWi7bbwwYG0nITBuk/asohfDgVKjNsbn55py2vHpmqpWwhorEBSHQ8AU15w3ZDokzs+WsjUKHhxMNJMC6vSp6JTiJvVajjuQwAzmVbo6XOltUWbQhH58so9Dh4cbeUaRHdt4Pf5NeqbMKy+XVlsbb3NqKre9yK4k16yiqWn7+Q0Hjo2VCCIgw6pjWPYJ/nSpnW46NftEmqbJ9HlnSLZqfejp/CW9EVFACDY9X5dNTZajAgBhTm65uqQ5qks/7BWDW6xgar73u97mV9Z63t8DOcz8U8EUjOSP+6hWtTdkdC7C6cKHdQ57dg6rWfy+dnVGncPfgWG7oFUmfaBMKUOTwoqDV4xjZjo0+hbhQDYo10zvKiEfVivJJQcq6LqzfiiFOVVWcXrV9pxW8nprkX4MJ+o6qeczlhHWvasump94c9Jf+JreSPLuHML3C9O5t19ukupIw0GBy3ZjEML7Ps3O8zEWB3U28pWaf3Eo3Li8YgjQr1TvKxLacSk6UufCqqt91VzKKteJ3aZFGLK1ofdBR9Irim64qd3nJKHaQHG6oXzVaCNEgRVGYlWrl1YPFnLW52V7Vk66z0inUmYJuaxLUdCKfZpbzY6GDn/WLbr9f8qcOgq1Uu913dE113aJzWoJu9nHtfvf+0G900F42r9LN1znaaqtp3SMCzi9pCa09ARh12jLj88WY9fSNNuFVVc7vYnAuSMu5q6WEG0gJN9A1woDTo9ZJuG2JQ1VBTf8QqNliNeoYLdNNQvgt0qRnarcI1p0uZ2u2ja3Zto4+pUbFmfXcNSi23V5PgppO4lCxw1eCfm++vf2CmgO1GjtWTz1l7IAPXgB71ZSLwVSz3DsIvKrK2sxyvCr0jjK2+V8ZBkVhTKIFr0qjIyPX9Yys95hXVcmvbDgXJ1A6ReG2/jEBPbfY4eFcpQcF6CeJtEJc1IbFm8ksd3G0pHM3uzS1c0kGCWo6gUq3l421+tocLnEyU1Xbfrme11sz9aQ3Qp+R8Pk/4av3avaJS4GbfhvUppU7civJtrkx67Vh1LZccQTaSMy0Zqa3Ggp2Cu0e3Kr2Qxlj6vipnuqpp1SrkfA2HNkSQnR+iqIwNz04CzZCifxm7AT+nVVBhVsl3qwn3KBg96hklrVDj4/Th2r6KKUPhjVP1w1oBo6Hu/4U1ICm0O7xDZVO7RZBZDvOtbZEiVOr2Omt1cQyMUwf9MDLo6qcKnNic7e88eThqr/I+sfIKI0QQjRERmo62LESp2/aaU6alX0FDvYUaOXve7Zxf506q56yjtRMNyk6mH4rTJgXlFVO1VRVZW1mGW4V0iONDItr+7wQr6rVSkkONzSbgO1VVf6eUYzNrZJo0fuSi4OVT1Pb/x0t5VS5i9mpVoa3cNXPNemRZBQ7QyKfRggh2oKM1HQgh8fL+qppp7GJFrpFGH1/hR8uaeNuyF4vHKwV1FQHNNZYWPQkTLwmqAENwK58O2cq3Bh1tMu0E2hJwm8dLeVv+4t8zSQbo1MUhlXVjvk+z05imJ4+USa/Svy3VI9I/5d2R5n0jO0S5mtPIIQQoi757diBNmXZKHN5iTHpmFzVoKxHpBGLXsHm1kYY2szZo1BaoN3u2gdGTNU6X9/9XIs6V/ur2OFh81ktcLqiawQx7dSgsLo+TUunkEYlWFCAzHIXXcIMzO8d1SaJzL2rRuFOlrnwnL/kSgghREAkqOkgp8qc7CnQGjjO7lHTtE+vKL6VLRnFbZjVXnvV09hZcM09sPD/aTVpgkxVVdafLsflhe4RBka1Y5E1X9G9Fq5eijLpfaNl3+fVL8YXLElheiIMCk6vyumKpoPXCpeXd46VsLfA3uxokxBCXMwkqOkATk9NA8eRCRbSzit1X50zcbjY2TYfYqpak0+j6LSu3IoCurYZPfmh0MHJMhcGBeb0iPR72snlVQOeimusknBTxlTVTvmhwOFXIq8/FEXxtWQ4Xtp0UHOkRGuCuTvP3i5TdkIIcaGSoKYDbMmuoNjpJcqo44qu9RuSpUcaMesVyt1esircwT+B7ONQnKvd7jkUwtuu03OZy+NrMXBZSjhxDRS/a8w5m5s1R0v4894CPj1V3vwTztNcJeHGdIuo2fftoyV+v25LVU9BNZdXk+EruCernoQQoikS1LSzM+Uuvs/Tpp1m9bA2uCJHr1PoU/WBV11BNqhqr3qKiofK4PQ1Op+qqmzIrMDhUUkJNzC2S/PVY9218kv0OjhRtbT9QJGDMpfHr9dvrpJwYxRF4ad9oog165jSNaL5JwQoPdKIAhTYPRQ7Gn5vdreXU1VfA1n1JIQQTZOgph25vTXTTkPizPU6Qtc2ILYmryaoU1CqWjefZs8XsPrJ4B2/lkMlLo6WOtEpMKeHtdFqvna3l115lazKKObTU2W+7QkWAzO6R5AcZkAFfiz0L8CrnnrqEmbwu8dSWqSJXwyKa9Nl9RaDjtk9rCzqH0N0I8X9jpQ48QKJFr1fo1xCCHExkjo17ejrHBsFDg8RBoUruzU9AtAz0oRJp1Dm8pJtc9M1WG0Tzp2Cwuy62waMC86xa3HrDGzK1kakJiWHk9hATsvZChc78+xkFDtwV8VthXYFl1f1JU6PSgxDpyisP13O/kIHl3QJa3FeSfcIIzO6R2DWd948lOol5I0JpV5PQgjR1iSoaSc5NjffnNNW08xMtRLWTIdlg06hT7SJA0UODhU7gxfU1B6lqTZwQnCOXcu52F5UelS6hOkZn1R/2umczc0/D5dQnYabaNEzLN7C4FizL6CpNiDWxOdnIN/uIcfmJqWFX4sYs55RF3DDRIfHy0nf1JPk0wghRHNk+qkdeLwqn54qQwUGxJjo19hf3bYyOHUAvFp+RfUHWUaxI3hTULXzaQCS0iE+JTjHrnKk1EVpRCIK2mqnhnpY7cirxIu2xPu2ftHcMSCGsV3CGuxpZNHrfF+zH4vaIMeogx0rcfLJqTJOldVNGLa5VbpFGIm36EmQqSchhGhWQCM1K1as4E9/+hPZ2dkMHjyY5cuXc9lllzW6/+rVq3nmmWc4cuQI0dHRzJo1i2effZb4+HjfPu+99x6PP/44x44do3fv3vzhD3/guuuuC+T0Op3v8yrJs3sI0ytMb6yxoq0UXv4NlOTB5Bth6s30ijJh1EGJ08u5So9fK3galHsa8s/U2eQdOJ53jpb4EnKDaWyCucFzVlWVEqcWuE3tFtGikZexiRZ6RxkbDwjPU+b0cLzMRUq4oU3aHATTkapWGWa9Umd5f6xZz819o/F4VVnKLYQQLeD3SM2aNWt44IEHeOyxx9i9ezeXXXYZs2fPJjMzs8H9v/rqK2699VYWL17Mjz/+yDvvvMOOHTu48847ffts376dBQsWsHDhQvbu3cvChQu56aab+PbbbwN/Z52EqqrsLdBGF67oGkFEYyXu16/UAhqA7zeAx4NRV1PLJCMYq6AObq+3aV/SyDYJaMzOciZ0aTgAURSFW/rGcMeAmBZPq6VEGBkcZ6k3NdWYU+Uu1mWWs+G0/0vB21uvKO1rcLyRpd36Fr5nIYS42Pn9J+xzzz3H4sWLfUHJ8uXL2bBhAy+99BLLli2rt/8333xDeno69913HwA9e/bkF7/4Bc8884xvn+XLlzN9+nQeffRRAB599FG+/PJLli9fzltvvRXQG+ss8u0eCh0e9ErNiqZ6Dn8PP3xZc99WCpkHoOdQBsSYySh2cqjYweSU8Nb9xX7e1JM7vhufOeIAmJkaQb/o4CSjutwuNn/2NQZdtyb3a8sRFH8rCXektEgjOgWKHF4K7R7iLHqKHVpQ22gQLIQQoh6/fuM7nU527tzJI488Umf7jBkz2LatgQRUYOLEiTz22GOsXbuW2bNnk5uby7vvvstVV13l22f79u08+OCDdZ43c+ZMli9f3ui5OBwOHI6a0YvS0lIAXC4XLlcb9kzy04FCbQVQutWAzuvB5T2vHondhuFfL3F+qOLZ/xXe7gPoEaZgqPrAyy53kBhobkXBWYznTtY9t+SReFTt3AZH6VHwrw5MYxTVgwINXod8uwerUYclgBVJqqqyI9/JoRIn89MjCG8i2Tq7qvVAoknpVN8PDdEB3cP1ZFZ4OFJUyagEM5uzbGSUuJiSYmFkfODBZvV77+xfg4uBXIvORa5H5xHMa+BXUJOfn4/H4yEpKanO9qSkJHJychp8zsSJE1m9ejULFizAbrfjdruZN28ef/nLX3z75OTk+HVMgGXLlrF06dJ62zdt2kR4eP0qvR3lePIIMEVQeeIAa3/Mq/f48MxtpJcVApBnTSauIg+96sG1dysbPMmg6LAkDKA8PJ61Ow+SWNLwNF9z+ub8wPltKr9PHInO68GQsYN1B4LfZ2rjxo117qvAyaThOIxhdM8/hNVe7PcxTyQNw26O5P3te4kry25wHxXI7j4edHoOf/81p1xt18MpWOyRXSG2J9+dyObsdwc50n0cqs7Asd3fke0sa/4AzTj/WoiOI9eic5Hr0fFsNlvQjhXQ2Pz5UyCq2ngi44EDB7jvvvv4z//8T2bOnEl2djYPP/wwd999N6+99lpAxwRtiuqhhx7y3S8tLSU1NZUpU6bUSUDuSAUODwePlKNT4LrLxtQbnVBO7MOw+zAAqslCzKLHUT5bBYd3YHFXctXQ3qg9BnKw2MnaM5V4u6QxZ9KQgM7F8FrN9JZt7NVknTlDblQqV3YNY8SwaQG/x4a4XC42btzI9OnTMRprcmayKtwcOlGBXoGrJ49vcqSlMbsLHHyRbUdN6cOcy0Y2uE+B3cOho+UYFLhm2hV+F97rCAUOD6uOlGMPj6XvpCvJOF2J1aBww5WXtmrKsbFrIdqfXIvORa5H51FQUBC0Y/kV1CQkJKDX6+uNoOTm5tYbaam2bNkyJk2axMMPPwzAsGHDiIiI4LLLLuOpp54iJSWF5ORkv44JYDabMZvrD8sbjcZO8w16vEAbUkuPNBJpOS+fxlEJa1/x3VWm34YxoSsMmQSHdwBgOPwd9B5Gvzg967MqKXR4KXErJPibi1KYAzknAFBTevNRv/mc6uoi1WpgTFJEm62sOf9a7CnSRkwGx5qJDgtsSmVogp7NOXZy7V6K3EqDeTn5Zdo0WlK4AbPpwqjvkmQwEG2yYdIp7C7Uvm/6xZgxBen8O9PPxcVOrkXnItej4wXz6+/Xn8omk4nRo0fXG67buHEjEydObPA5NpsNna7uy+j1Wl5Ide2VCRMm1DvmZ5991ugxLxRNVoP9YjUUn9Nupw2C0TO02/3GgL7qg/rAN+D1YtHr6BmpXfSMkgCmiQ5+47uZkz6WU+WBd8wOVKnTQ0axdu6jW1EQL8yg8/XF2t9I24QLKUm4mqIo3DEghkUDYiiw161TJIQQomX8Hv9/6KGHePXVV1m5ciUHDx7kwQcfJDMzk7vvvhvQpoVuvfVW3/5z587l/fff56WXXuL48eN8/fXX3HfffYwbN46uXbsCcP/99/PZZ5/x9NNPc+jQIZ5++mk+//xzHnjggeC8yw5Q5PCQW6klzPaLPu/DKfMgfLtWu20wwbx7oDrws0RA7xHa7bICyNKmp6oDo0OBFJ+rteppvXUoAJO7RhBrbr+Cbrvy7ahAqtVAUiuDjSFxVYX4Cu14GyhKOCk5nJt6RzG8mRYEnY1ZryOzzIXdoxJuUEi1yl+PQgjhD78/XRYsWEBBQQFPPPEE2dnZDBkyhLVr15KWlgZAdnZ2nZo1ixYtoqysjL/+9a/8+te/JiYmhqlTp/L000/79pk4cSJvv/02v//973n88cfp3bs3a9as4ZJLLgnCW+wY1XVl0iKNdVsiuBzw0V/R0lmBqTfXr+g7cIK2zBu00ZrUAfSNNqED8uwe37LfFinO8wVGdksUqstB1zA9YxLb7wPf5VXZk6+tAhsThLYFvaNMhOkVKtwqJ0pd9D4vaAwz6JpsFtqZZVW4CdMr9I4yXRC5QEII0ZkE9CfzkiVLWLJkSYOPrVq1qt62e++9l3vvvbfJY86fP5/58+cHcjqdUvVUS70phM1roOCsdrtbPxh/df0n9x8LOr3WLuHANphxG2EGHWmRRk6UucgodjAhuYUrvGpNPVnspdyx+QmKbnkKnRIbyNsKSFaFC6dHJdqko+/5o1YB0OsUhsdbKHV5Q66Oi0Wv4FFhRMKFNcokhBCdwYWTdHABKXF6yLa5q6aeauXTZB2FbR9pt/UGuOZXWvByvvBI6DkMju3WqgyfPQbd+jAgxlwV1DhbHtSc18DSGRZFbO8Bgb2xAKVHmvjlkFhKHN6gjT5c0UiX85NlTk6WuegZaazTcuBCMSLBQv8YE5Em6fUkhBD+Cq0/czuJ6lGaVKuxZiTB7dKmndSqvtSX3wRdejR+kEG1OmdXBSZ9o00oQE6lm2JHCwrllRbC6UN1NhkGTWg4kGpjkUY93dshR+RoiZNvzlVyOJCE6k7AoFMkoBFCiABJUNMGMnyrnmqNFHz1PuSe0m4n94RJzTTrHHAJKFWX58B2UFXCjTp6VAUGLeoFdeibept0tYOldlDqDE6V4sbkVbr5Pq+muJ5v5VMnb2IphBAi+CSoCbJSp4esCu2DtV91UHPuFGx5V7ut6OCae2qWbTcmIgrSB2u3i3Ig5yRQEyhVjwY1xfPjea0rwqw1x2wHxQ4PL/1YxJqjJXi89VcptZbN5WXloWI+P1NBod2DqqrkVmpB1IW0nFsIIURwyG/+IKue9ugeYSDSqAePR5t28mqBDpdeDym9WnawQRPhxD7t9oFtkNKTfjFmPjtTwVmbm1cOFDX61AhbIT89daDuxv7jmg+mgmh3obN6jVebdJoON+roGWXkeKmL/YV2BseZcXpVDArEB9ojSwghxAVLRmqCLOP8gnvffAxnj2q3E7pruTQtNeASqG51WTUFZTXq6BWlTUEVOjwN/7O7uWTHP9Bx3uhIO049eRQ9+4u0AC8Yy7gbMzROWyW0v9BBdtXUU1K4QZZDCyHERUhGaoKo3OXldHmtqaf8LPjirapHFW3ayeBHsmxkLKQNhFMHoCAL8k5Dlx5c1zOKczb3+SGLT/iBrcSf+wHQquEoAOZw6DU8wHfmv5KILji9EGfW+4KwttA32oRZr1Dq8vJdrpZbI1NPQghxcZLf/kF0uGqUpmu4gWiDok07eapaqk+YC6n9/T/ooIlaUAPaaE2XHhh1SuMricqLYdPrvru+8Yp+Y/wLqFpBVVWKIrWCgqMTLW3aisGgUxgYY2ZPgb0mn0aShIUQ4qIk009BVKfg3o51NcupY5Nhys2BHXTg+Jrb59WcadDa/4XKcgAOpozizJwHYMilMPSywF4/ACfK3TiNYZh0NdNDbam6bYJRB7f3jwlKgT8hhBAXHvmTNkhsLi+Z5dqozECK4fN/1jx4za/AFFhXaqLioXt/OJMBuZmQdwYSuze874HtvsDHZrJyYvLtzBnYHcZdHthrB+jHIu3rMDTWhEnf9rkt3SIMxJp12N0qHlXFYpBYXQghLkby2z9IjpRoK32SLDqi1r8MLq3XEWNmQfqQ1h28doLvwe0N72Mrg09f8d39cvhPubyP1jBUVVUK7O7WnYMfZncPI6XgCCPjAwzk/KQoCjf2iuaeIXF0jZAmkEIIcbGSoCZIDlXl00zO2Q4ntCRdohJg2sLWH7xOdeFGgpoNK6GiGACXzkifvn2JMOood3n5nwNFrMooxuHxtv5cGlHi9GBzacc36BRiKnKJNrXft1ecRd8my8aFEEJcOCSoCYJKt5dTZS6slUX0/ObNmgfm/hIsLezR1JSYLtC1j3Y75wQUZtd9/PBO2LvZd9foddFnwwvgqCTCoKBXFFzelhXsC8TxUievHyrm41NleNXgF9kTQgghWkKCmiA4UuLEq6rM278ancOmbRwxFfqOCt6L1BmtqdX+wG6Dj/9Wb3elSw9QVRRF8SXS7iu0B+98AK+qsjW7gv87Vordo/r+CSGEEB1BgpogyCh2MOjMt/Q4u1fbYI2FmbcH90UG1m9wCcAHy6G8VmVhnV577Zse9o0SVQc1p8tb2AizBWxuL/93rJSvc7TaMCMTLPysbzThkqQrhBCig8gnUCvZPV7O5RUwfd/bNRuv+oXWZymY4lO0RpigVSguOgef/A9k7PDt4g6PhkVPwoR5UKs2TJRJT1pVXZv9hS1ohNmMrAoXrx8q5mSZC4MCV6dZmZlqxSA5LUIIITqQBDWtdLTEyZU/vEmYq0LbMHgSDLykbV6s9hTUm3+A7zf47hZakyhd/GfoMbDBpw6tWom0v9CO2oq8F6+qsi6znDKXlzizntv6xzCkHWrRCCGEEM2RoKaVyvZ+zcCzO7U7YZEw+862e7FBE2tu55323SwNiyXjp88QFx/f6FP7RZsx6RSKnV7O2gJf3q1TFOalRzI41sxt/aNJlOq9QgghOonQ+0Ry2sFR2S4v5bCVM+ybf9RsmPNzsMa03QsmdIMuPbQifFXcip6NU3/LdV0jm3yqSa8wrXsEsWY9XQPojeRRVfRVU1pdwgzMTW/69YQQQoj2FnJBjfHFX4C5fQqwmav+Aaj9xqAMubTtX3TghDpBzdZB13Hp4D4t6ko9LD6waaIyl4c3DpcwMSmc4fHmNu3lJIQQQgRKpp+CwG0KR7n67jrJuW1mcM0U1NmYnugmzCOpDbtSq6rKZ6crKHV62Vtgb7QzuBBCCNHRQm6kxps2GMLD2v51VJXT5S5cOiNxV1xLXFTj+SxBU5wHXXrgmfsrco/8yJd953JjV/9WWZU4PXx7rhK7R2VeC6aQMoqdHClxolNgdg9ri0aEhBBCiI4QckGN58bfQhMJs8FyuNjBhyfKiDbpuHtAbJu/HsV58MLdkDYI/aU3kPKT+7nJq/rdGsCrwq58OwowpWs4kSZ9o/tWur18dkbr+D0hKYwukhQshBCiE5PppwAdrmo50D+mnXJMdqwD1Qsn92sduyGgXkexZj3dIwyowI9FTdes+fxMBTa3SoJFz4SkILR7EEIIIdqQBDUBcHtVjpZoQc2AGFPbv6DTDjs3AuDRGTjVf0qras0Mraors6/Q0ehxjpU4+bHIgQLM6SGF9YQQQnR+EtQE4ESZE6dXJcqoI6UNk3R9fvgS7No00IFuY/mkwEBr+m33jzVhUKDA7iGnkZo1eXY3CjAm0ULXiPZZTSaEEEK0hiRJBOBQkTZK0y/G1PZTT6oK337qu/t9rysZlWDx1YwJhEWvo1+MmQNFDvYVOkhpIGgZnxROmtVIvEW+RYQQQlwYZKTGT26vytHSmnyaNnd8r6968Om4PhTEpjEiofVtCaqbXB4ocuD2NjwFlRJhxKSXaSchhBAXBglq/HSqzIXDo2I16Oge0Q6jGN984rv5fe9pDI4zExaETtjpkUZSwg2MSLDgrsqrcXlV/nWyjHx74G0UhBBCiI4iQY2fMoq1FUPtMvVUcBaOaH2lSsLiOJw8gtGJwanBo1MUbusfwxVdI7DotW+Dr7Nt/Fjk4J1jpXhbkYgshBBCdAQJavzgUVUOl1RPPbXDqqfv1vpu7uo5hR5RljarFZNjc/NtrtYza1r3CCmyJ4QQ4oIjQY0fMstc2D0q4QaFVGs7rAjqOwZ6j8BrMHOm3+WM6dL6XJrzeVWVw8UOVmUUowIDY0z0jW6HXCEhhBAiyGRpix8yqgru9Ys2t89IRp8R0GcEuvJifhYR3SYvsbfAzobTFQCE6RWmdfev7YIQQgjRWchITQt5VZXDJVo+TbtMPdVmjUFRlDbJ4RlQawXXld0jiDDKt4QQQogLU8iN1GzNqSSysrzRx3WKwtB4Mwl+1l85Xe7C5lax6BV6RLZPMboz5S5yK90MibO02dLqMIOOG3pFUuFSGRwr005CCCEuXCEX1OwpdGFx2pvc53CJgzsGxGL0o/R/zdSTqVWF71rk8zcgdQDb9X04VuahyOHhyjacFpIcGiGEEKEgoLmGFStW0LNnTywWC6NHj2br1q2N7rto0SLf1Entf4MHD/bts2rVqgb3sdubDk4aMirexPguYY3+sxp1FDm8bM22tfiYqqr6lnK3ecG9c6fgq/fhrT8yesOzAIxMCM4ybiGEECKU+T1Ss2bNGh544AFWrFjBpEmTePnll5k9ezYHDhygR48e9fZ/4YUX+O///m/ffbfbzfDhw7nxxhvr7BcVFUVGRkadbRaL/6t9JiVZiI+PaPTx7lYj7x4vZUduJQNiTC3qa3Smwk2FW8WsV0hv66mnWi0RjicNpXeUkTiLvm1fUwghhAgBfgc1zz33HIsXL+bOO+8EYPny5WzYsIGXXnqJZcuW1ds/Ojqa6OialTsffvghRUVF3H777XX2UxSF5OTkFp+Hw+HA4XD47peWlgLgcrlwuVyNPi8tXGFgtJGDJS4+PVXGz3o334H6YKFWv6V3pAGvx43X0+LT9I+tDMMPm1EAh8HCDz0mMTfW2OT76Yyqz/dCO+9QJNei85Br0bnI9eg8gnkN/ApqnE4nO3fu5JFHHqmzfcaMGWzbtq1Fx3jttdeYNm0aaWlpdbaXl5eTlpaGx+NhxIgRPPnkk4wcObLR4yxbtoylS5fW275p0ybCw8ObPAe3zoA+ZSQFDhOrt/9IYklmo/uqwNGuY8BgpvTID6z9obDpN9gKfc7tY7Bbu7j7ekwCVH7cupEDbfaKbWvjxo0dfQqiilyLzkOuReci16Pj2WwtTwdpjl9BTX5+Ph6Ph6SkpDrbk5KSyMnJafb52dnZrFu3jjfffLPO9gEDBrBq1SqGDh1KaWkpL7zwApMmTWLv3r307du3wWM9+uijPPTQQ777paWlpKamMmXKFOLj45s9l8MlLv512kZhdCqzRw2kS1jDUzxnbW4OHa/AqIMbLr+k2VGdgHk9GP72LwBUFL7vOZXJaXEMHzmnbV6vDblcLjZu3Mj06dMxGttnpZhomFyLzkOuReci16PzKCgoCNqxAlr9dH69FFVVW1RDZdWqVcTExHDttdfW2T5+/HjGjx/vuz9p0iRGjRrFX/7yF1588cUGj2U2mzGb6yftGo3GFn2DDk4wcrjMTUaxk8/OVnJr/5gGVzUdK9dWPfWNNhNmbsP6ND9+B6Xahc3uPhxHdBLDEiIwXsBdslt6LUTbk2vReci16FzkenS8YH79/Vr9lJCQgF6vrzcqk5ubW2/05nyqqrJy5UoWLlyIydR0cKDT6Rg7dixHjhzx5/T8Nr27FYte4Vylh2/PVdZ7vO6qpzYuuFerG3fXKddy9+DYNqtNI4QQQoQiv4Iak8nE6NGj681Bbty4kYkTJzb53C+//JKjR4+yePHiZl9HVVX27NlDSkqKP6fnN6tRx7Tu2kqpr3Ns5NvddR4/V+mhxOnFqINeUW0Y1Jw9BqcPabcTU6HXMMx6qewrhBBC+MPvT86HHnqIV199lZUrV3Lw4EEefPBBMjMzufvuuwEt1+XWW2+t97zXXnuNSy65hCFDhtR7bOnSpWzYsIHjx4+zZ88eFi9ezJ49e3zHbEuDY830jjLiUWHtqXK8qup77FDVKE3vKJNfhfr8dnyv76Zt9ByQDtlCCCGE3/zOqVmwYAEFBQU88cQTZGdnM2TIENauXetbzZSdnU1mZt3VRCUlJbz33nu88MILDR6zuLiYu+66i5ycHKKjoxk5ciRbtmxh3LhxAbwl/yiKwsxUK68dLOaszc33eXbGdQlr34J7l16P2ncUP3z2Lz7XD+UWm5vk8JAr9iyEEEK0qYA+OZcsWcKSJUsafGzVqlX1tkVHRze5ZOv555/n+eefD+RUgiLKpGdKtwjWny5ny9kK+kabcHpUihxeDIo2UtPWzkV2Z92Qn2LSKSRIsT0hhBDCb5K4UWV4vJk0qxG3Cusyy32jND2jTO2SsHusVFtllRZpbLtl40IIIUQIk6CmiqIozO5hxaiDzHIX3+Zqq6EGtOWqp7Ii8HoBOF4V1LTHqJAQQggRiiRxo5YYs57JKRH8O6sCjwp6BXpHt1GQoarw1h/BYcM5ZjZnzeNA0dErSuolCCGEEIGQkZrzjE600C1Ci/XSI41Y2mpp9ekMOHsUCs7i2fUFKgqJFj1RJsmnEUIIIQIhIzXn0SkK16RHsv1cJaMT/O8S3mLf1hTbO9R/OiiKTD0JIYQQrSBBTQOiTHpmplrb7gVK8uHAdu12RDSDLptKeCXEy6onIYQQImAS1HSEHetA1RKEGTMTs9lM/zYuhSOEEEKEOsmpaW9OB+z8TLutM8CYWR17PkIIIUSIkKCmve37EirLtdtDJvFpoYGt2RVUuLwde15CCCHEBU6mn9qTqsK3n/ruVo6ew75CrcjfyISwjjorIYQQIiTISE17OrEPcqv6YnXvz1FrDwCSwwxYjXIphBBCiNaQT9L2FBUPI68EvRHGX+1rjdArWgruCSGEEK0l00/BUnAWLFaIiGp8n4RucM09MG0hXnM4Jw6UAtIaQQghhAgGCWqCZf1KOLYXBoyFkdOg93DQNVJ3JiKarHIXDo9KmF4hJVwugxBCCNFa8mkaDKUFcHS3VnvmwHbtX1Q8jJiq/YtLrveU6gaWvaJM6BTpyi2EEEK0lgQ1gVBV+OJN6DMSegwERQcT5sLezVBRou1TWgBb3tH+AfQdDfN/DeaaVU4WvSINLIUQQoggkUThQGQfh63vwuuPwbt/hshYmLEIHnoVFjwC/cZqgU5tR3bC8z/3BT2Xd43gvqFxDIiRUsJCCCFEMMhITSD2bKq53XNYzW29AQZeov0rLYQfNsPuf2tJxACpAyAi2re7TlFAZp6EEEKIoJCgxl9uF+zbot3WG2HwpIb3i4qDS6+HSddB5kEozIZBEwEodXqINOpQJJdGCCGECBoJavx1ZBdUlmm3B1wCYRFN768okDZI+wd4vCqvHizGolf4Wb9ookzSmVsIIYQIBsmp8dfeWlNPI6b4/fTTFS6cXhWPqhIpVYSFEEKIoJFPVX9UlMLhndpta6xWi8ZPx0tdgLaUW6afhBBCiOCRoMYf+7eC163dHnZ548X1mlDdGkGqCAshhBDBJUGNP/a0buqp2OGhwO5BAdIjpT6NEEIIEUwS1LRU7mnIPqbdTukNXXr4fYjqKsLdrQYsBvnSCyGEEMEkq59aKqEbLHpKSxROHRDQIXxduSNl6kkIIYQINglqWkqng/TB2r8Aje0SRoxZT98YCWqEEEKIYJOgph2lR5pIl1EaIYQQok1IYocQQgghQoIENc2xV8Df/xN2btRuB2hbjo1TZU68qhrEkxNCCCFENQlqmvPj13BiH/xrBWx6O6BDFNo9bMm2seZYKS6vBDVCCCFEW5Cgpjm1a9MMvyKgQxwucQCQGmHErJcvuRBCCNEWJFG4KQXZcPqQdjsxFVJ6+fV0VVXZdq6Srdk2AFn1JIQQQrQhCWqacn7zSj96NVW6vfzrVJmv19OweDMj4y3BPkMhhBBCVJGgpjFeL+zdrN1WdFqvp5Y+VVVZfaSEfLsHgwIzUq0Mk4BGCCGEaFMBJXisWLGCnj17YrFYGD16NFu3bm1030WLFqEoSr1/gwfXLWL33nvvMWjQIMxmM4MGDeKDDz4I5NSC4nS5iw1ffQcledqG3sMhMq7Fz9cpCuOTwogx6VjYL0YCGiGEEKId+B3UrFmzhgceeIDHHnuM3bt3c9lllzF79mwyMzMb3P+FF14gOzvb9+/06dPExcVx4403+vbZvn07CxYsYOHChezdu5eFCxdy00038e233wb+zgKUb3fz7vFSUo7UBGqbE8dxqszZ5POcHpX8Srfv/pA4C4sHxpIULoNhQgghRHvw+xP3ueeeY/Hixdx5550ALF++nA0bNvDSSy+xbNmyevtHR0cTHR3tu//hhx9SVFTE7bff7tu2fPlypk+fzqOPPgrAo48+ypdffsny5ct56623GjwPh8OBw+Hw3S8tLQXA5XLhcrn8fVsAVLi9/N+xcrwOOwOzdwJgN4Txffwweno9vuM6PSpGHShVOTaFDg8fZ9pweFQW9rESXqtZpcsT0Klc0Kq/ToFeBxE8ci06D7kWnYtcj84jmNfAr6DG6XSyc+dOHnnkkTrbZ8yYwbZt21p0jNdee41p06aRlpbm27Z9+3YefPDBOvvNnDmT5cuXN3qcZcuWsXTp0nrbN23aRHh4eIvO5XwFkV0pje1Jn9wDGNzayEx2TA8Si0+xe/MO9lTtlx3bm4qwGKLLz2H0ODkX2wuvTo/e42Tdpt2EuQIv0hdKNm7c2NGnIKrIteg85Fp0LnI9Op7NZgvasfwKavLz8/F4PCQlJdXZnpSURE5OTrPPz87OZt26dbz55pt1tufk5Ph9zEcffZSHHnrId7+0tJTU1FSmTJlCfHx8S95OPaqqsqvASa++l+EePwzdj1vpnj6Um2st5faqKq8eLsPlUsmPqQnMuofruSo1HuvwlicUhyqXy8XGjRuZPn06RqOxo0/noibXovOQa9G5yPXoPAoKCoJ2rIASPpTzljarqlpvW0NWrVpFTEwM1157bauPaTabMZvN9bYbjUa/v0Frv9b4lKpaMlYLTJ6PvoH97xoUx+FiB3sLHJypcDE2MYzLu4aj82PJ98UgkGsh2oZci85DrkXnItej4wXz6+9XUJOQkIBer683gpKbm1tvpOV8qqqycuVKFi5ciMlUtwhdcnJyQMcMhp15lRwrcXJNz8gWV/s16hQGx1kYHGdpcUAnhBBCiLbl1+onk8nE6NGj681Bbty4kYkTJzb53C+//JKjR4+yePHieo9NmDCh3jE/++yzZo/ZWkdLnHx+poLjZS4OFjlBVcHjX2avBDRCCCFE5+D39NNDDz3EwoULGTNmDBMmTOCVV14hMzOTu+++G9ByXbKysvjHP/5R53mvvfYal1xyCUOGDKl3zPvvv5/Jkyfz9NNPc8011/DRRx/x+eef89VXXwX4tpqXY3Pz0clSVGB4vJnh8WY4cxjWPA3DJsPoGRDftc1eXwghhBDB5XdQs2DBAgoKCnjiiSfIzs5myJAhrF271reaKTs7u17NmpKSEt577z1eeOGFBo85ceJE3n77bX7/+9/z+OOP07t3b9asWcMll1wSwFtqXonTwzvHSnB5oWekkRmpVm3EZe8mKC+CbR9BYg8JaoQQQogLSECJwkuWLGHJkiUNPrZq1ap626Kjo5tdsjV//nzmz58fyOn4xe7x8s6xUircKokWPdf2jESvKOBywv6qkSGjGQZNaPNzEUIIIUTwBNQm4UL26aly8u0erAYdN/aOqkkOPrwD7FX1ZQZOAHNYx52kEEIIIfx20dXwn5QcToHdw7z0SKJMtRZs7zmvI7cQQgghLigXXVCTHG7gzoExdWvKlBfD0d3a7agESK+fzCyEEEKIzu2im34C6hfJ++FLUL3a7eGXg+6i/LIIIYQQF7SLaqTmQKEDgw56WI1YajWdZO/mmtvDZepJCCGEuBBdVEMSn2eV8/6JMoqd3pqN2Sfg3Entdvd+kNCtQ85NCCGEEK1z0QQ1To+Kza0CEGOu9baLz0F4lHZbRmmEEEKIC9ZFM/1U7NTaH1j0CpbaPZ4Gjoe+o+HoLkgb3EFnJ4QQQojWumiCmpKqoCba1MDglMEIA9qmerEQQggh2sdFM/1U7NDyaGLM+mb2FEIIIcSF6KIJaqpHamKqC+45KrX6NEIIIYQICRfN9FP1SI1v+mnvZlj/GvQZBVN/Csk9O+7khBBCCNFqF81IzeVdw7kmPZKeUSZtw95N4PVoPZ9QmnyuEEIIITq/i2akJjHMQGJY1dvNOwNZR7TbyT0hOb3DzksIIYQQwXHRjNTUsbdW80qpTSOEEEKEhItipKbY4eFIiZNEi550q76mLYJOD0Mv69BzE0IIIURwXBRBzVmbm39nVdA9wkC67iSUFWoP9BkF1piOPDUhhBBCBMlFMf1U4qguvKevO/U0QqaehBBCiFBxUQQ11S0S4hU7HPxG22ixQr8xHXhWQgghhAimiyOoqapR0+PU9+B2ahuHXqq1RxBCCCFESLgocmqqqwlHleVAlx5aNWFZ9SSEEEKElJAParyqSqlTG6lh+q1guh1UtWNPSgghhBBBF/JBTZnLixfQK2A1Vs22KVJBWAghhAg1IR/URBh03Novmgq3F50EM0IIIUTICvmgxqBT6BohCcFCCCFEqAv5oMZHVeH1x8Bg0no9zVjU0WckhBBCiCAK+aDmx0I7lW6V3hEQm3lQ2+hxdexJCSGEECLoQj6o2ZVvJ6vCTXSSSmz1RlNYR56SEEIIIdpAyBffK65ukaA4azaaLB10NkIIIYRoKyEd1Li8KhVurSZNlFpryklGaoQQQoiQE9JBTXUlYbNOwey21zwgIzVCCCFEyAntoKaq51O0WYfiqhXUmGWkRgghhAg1IR3UVHfnjjbpwSkjNUIIIUQoC+2gpipJOMakk6BGCCGECHEhvaR7YnI4A2PNWPQ6OFtZ84AkCgshhBAhJ6CRmhUrVtCzZ08sFgujR49m69atTe7vcDh47LHHSEtLw2w207t3b1auXOl7fNWqVSiKUu+f3W5v4qjNCzPo6BphJM6ih5RecNl8uOQq6NKjVccVQgghROfj90jNmjVreOCBB1ixYgWTJk3i5ZdfZvbs2Rw4cIAePRoOFm666SbOnTvHa6+9Rp8+fcjNzcXtdtfZJyoqioyMjDrbLJYgThOl9tf+CSGEECIk+R3UPPfccyxevJg777wTgOXLl7NhwwZeeuklli1bVm//9evX8+WXX3L8+HHi4uIASE9Pr7efoigkJyf7ezqNsnu8fJ1tI8asZ1SCBUU6dAshhBAhza+gxul0snPnTh555JE622fMmMG2bdsafM7HH3/MmDFjeOaZZ3jjjTeIiIhg3rx5PPnkk4SF1eS2lJeXk5aWhsfjYcSIETz55JOMHDmy0XNxOBw4HA7f/dLSUgBcLhcul4v8Sg878uxEGBSGxYR06lCn43K56vwvOo5ci85DrkXnItej8wjmNfDr0z4/Px+Px0NSUlKd7UlJSeTk5DT4nOPHj/PVV19hsVj44IMPyM/PZ8mSJRQWFvryagYMGMCqVasYOnQopaWlvPDCC0yaNIm9e/fSt2/fBo+7bNkyli5dWm/7pk2bCA8PpzQsHhIH4K0oYe3arzB4XHgVBa+iBxm1aRcbN27s6FMQVeRadB5yLToXuR4dz2azBe1Yiqqqakt3Pnv2LN26dWPbtm1MmDDBt/0Pf/gDb7zxBocOHar3nBkzZrB161ZycnKIjo4G4P3332f+/PlUVFTUGa2p5vV6GTVqFJMnT+bFF19s8FwaGqlJTU0lOzub+Ph4vstzsPWcnQHRRq5KDUe/5r/RHd2Fqii47/9fiIhq6dsWfnK5XGzcuJHp06djNBo7+nQuanItOg+5Fp2LXI/Oo6CggJSUFEpKSoiKat1ns18jNQkJCej1+nqjMrm5ufVGb6qlpKTQrVs3X0ADMHDgQFRV5cyZMw2OxOh0OsaOHcuRI0caPRez2YzZbK633Wg0YjQaKfdoAU+cxaB9w7q0+4qqYoywgnwTt7nqayE6nlyLzkOuReci16PjBfPr79eSbpPJxOjRo+sN123cuJGJEyc2+JxJkyZx9uxZysvLfdsOHz6MTqeje/fuDT5HVVX27NlDSkqKP6dXh687t1mvbaguvqfowGAK+LhCCCGE6Jz8rlPz0EMP8eqrr7Jy5UoOHjzIgw8+SGZmJnfffTcAjz76KLfeeqtv/5tvvpn4+Hhuv/12Dhw4wJYtW3j44Ye54447fFNPS5cuZcOGDRw/fpw9e/awePFi9uzZ4ztmIEqcWt+nGFPVW3RWFd8zWSSnRgghhAhBfi8LWrBgAQUFBTzxxBNkZ2czZMgQ1q5dS1paGgDZ2dlkZmb69rdarWzcuJF7772XMWPGEB8fz0033cRTTz3l26e4uJi77rrLl3czcuRItmzZwrhx4wJ6U6qq+jp0R5vOG6mRasJCCCFESAporfOSJUtYsmRJg4+tWrWq3rYBAwY0mWH+/PPP8/zzzwdyKo365eA4SpweonwjNVVBjVn6PgkhhBChKCQLuCiKgtWoYDVWBTSqKiM1QgghRIgL6S7dPi4nqFqOjXToFkIIIUJTSI7UHCxykG1z0zvKSFqkqSZJGGSkRgghhAhRITlSc6zUyXe5lWRVVDXNdNbq9i0jNUIIIURICsmRmuoaNTHVK58i4+Dnz2jBTZi1A89MCCGEEG0lJIMaX40ac9VAlNEE3RruISWEEEKI0BByQY3bq1Lm0tpZ+WrUCCGEECLkhVxOTZlLG6Ux6iDcIJWDhRBCiItFyI3UlDm9gI5okx6luh1CfhZkH9eShFN6Q1Rch56jEEIIIYIv5IKaEnd1z6daU0/H9sC6V7Xb1z8Awy5v9/MSQgghRNsKuaBmSIyJMWlxuL1qzUZZ0i2EEEKEvJALarQWCeelCknxPSGEECLkhVyicINkpEYIIYQIeSEX1GzMsvFFVgX2qtwaABwyUiOEEEKEupALag6VuPkutxKdUms5t4zUCCGEECEv5IIagDCDgkkvQY0QQghxMQnJoCbm/ErCEtQIIYQQIS9Eg5pGVj/pDWAwtv8JCSGEEKLNhdySboBo83kjNUazliAsAY0QQggRskIyqKk3/bR4mfa/qtbfWQghhBAh4eKYfqqmSINLIYQQIlSF3EjN7X2tdLXKNJMQQghxsQm5kRqrUYdRJyMyQgghxMUm5EZq6rGVwdpXtKXc3fvDqGkdfUZCCCGEaAMhN1Kzv8hZd0NlGez/CnZ9Dif3d8xJCSGEEKLNhVxQk2Nz190ghfeEEEKIi0LIBTVR5698kmaWQgghxEUh9IMaGakRQgghLgqhF9QYJagRQgghLkYXQVBTa/rJLNNPQgghRKgKuaAmwnBejRqn5NQIIYQQF4OQC2qU81shyPSTEEIIcVEIuaCmHglqhBBCiItC6FcUTu4Jwy7XgpvIuI4+GyGEEEK0kdAPaoZcqv0TQgghREgLKKhZsWIFf/rTn8jOzmbw4MEsX76cyy67rNH9HQ4HTzzxBP/85z/Jycmhe/fuPPbYY9xxxx2+fd577z0ef/xxjh07Ru/evfnDH/7AddddF8jpCSGE8JPX68XpdDa/Y4hwuVwYDAbsdjsej6ejTyekGY1G9Hp9u7yW30HNmjVreOCBB1ixYgWTJk3i5ZdfZvbs2Rw4cIAePXo0+JybbrqJc+fO8dprr9GnTx9yc3Nxu2vaGWzfvp0FCxbw5JNPct111/HBBx9w00038dVXX3HJJZcE/u6EEEI0y+l0cuLECbxeb0efSrtRVZXk5GROnz5df4GJCLqYmBiSk5Pb/Gvtd1Dz3HPPsXjxYu68804Ali9fzoYNG3jppZdYtmxZvf3Xr1/Pl19+yfHjx4mL03Ja0tPT6+yzfPlypk+fzqOPPgrAo48+ypdffsny5ct56623/D1FIYQQLaSqKtnZ2ej1elJTU9HpQn/9CGgjU+Xl5Vit1ovmPXcEVVWx2Wzk5uYCkJKS0qav51dQ43Q62blzJ4888kid7TNmzGDbtm0NPufjjz9mzJgxPPPMM7zxxhtEREQwb948nnzyScLCtLox27dv58EHH6zzvJkzZ7J8+fJGz8XhcOBwOHz3S0tLAW1I0eVy+bbrX/8PlOJcCI/C/Yvn/Hm7IkDVX//a10F0DLkWnUdnvRZut5uKigq6du2KxXLxrBBVVRWn04nZbJaRmjZmNpvxer3k5eURGxtbbyoqmD8TfgU1+fn5eDwekpKS6mxPSkoiJyenweccP36cr776CovFwgcffEB+fj5LliyhsLCQlStXApCTk+PXMQGWLVvG0qVL623ftGkT4eHhvvvT8nOIcJbjcDpZv3Zti9+raL2NGzd29CmIKnItOo/Odi0MBgPJyck4nU7fH4cXk7Kyso4+hYuC1+ulsrKSf//733XSTwBsNlvQXiegROHzo1pVVRuNdL1eL4qisHr1aqKjowFtCmv+/Pn87W9/843W+HNM0KaoHnroId/90tJSUlNTmTJlCvHx8b7thoz3wQkmaxRz5szx742KgLhcLjZu3Mj06dMxGo0dfToXNbkWnUdnvRZ2u53Tp09jtVovupGasrIyIiMjZaSmHdjtdsLCwpg8eXK977OCgoKgvY5fQU1CQgJ6vb7eCEpubm69kZZqKSkpdOvWzRfQAAwcOBBVVTlz5gx9+/YlOTnZr2OCNpxlNpvrbTcajXV/YVQV31NMYZ3qF8nFoN61EB1GrkXn0dmuhcfjQVEUdDrdRZVbUp0UXf3eRdvS6XQoitLg938wfx78upImk4nRo0fXGz7duHEjEydObPA5kyZN4uzZs5SXl/u2HT58GJ1OR/fu3QGYMGFCvWN+9tlnjR6zxTwecFctUZRmlkIIIURI8zs8feihh3j11VdZuXIlBw8e5MEHHyQzM5O7774b0KaFbr31Vt/+N998M/Hx8dx+++0cOHCALVu28PDDD3PHHXf4pp7uv/9+PvvsM55++mkOHTrE008/zeeff84DDzzQunfnkhYJQgghmvfKK6/4Vn81tUjFHydPnkRRFPbs2RPQ8xcuXMgf//jHoJxLNUVR+PDDDwFtRiQxMZGsrKygvkZH8juoWbBgAcuXL+eJJ55gxIgRbNmyhbVr15KWlgZAdnY2mZmZvv2tVisbN26kuLiYMWPGcMsttzB37lxefPFF3z4TJ07k7bff5vXXX2fYsGGsWrWKNWvWtL5GjaN2h24JaoQQIlQsWrQIRVF8UxpJSUlMnz6dlStX+l1vp7S0lHvuuYff/e53ZGVlcdddd7XJOW/evBlFUSguLm523x9++IFPP/2Ue++9t03OBaBLly4sXLiQ//f//l+bvUZ7CyhReMmSJSxZsqTBx1atWlVv24ABA5rN+J8/fz7z588P5HQaJ80shRAiZM2aNYvXX38dj8fDuXPnWL9+Pffffz/vvvsuH3/8MQZDyz7iMjMzcblcXHXVVW1eR6Wl/vrXv3LjjTcSGRnZpq9z++23M27cOP70pz8RGxvbpq/VHkI7O8pZe6RGcmqEEKI5qqri9HTMP1VV/TpXs9lMcnIy3bp1Y9SoUfzHf/wHH330EevWravzB3ZJSQl33XUXXbp0ISoqiqlTp7J3715A+0N86NChAPTq1QtFUTh58iTHjh3jmmuuISkpCavVytixY/n888/rvH7tqZxqMTExDf5xf/LkSaZMmQJAbGwsiqKwaNGiBt+X1+vlnXfeYd68eb5tjz76KOPHj6+377Bhw3wjLTt27GD69OkkJCQQHR3N5Zdfzq5du5r8Gg4dOpTk5GQ++OCDJve7UIR2Q0sZqRFCCL+4vPDcD8FbYuuPh4bFY2pli6CpU6cyfPhw3n//fe68805UVeWqq64iLi6OtWvXEh0dzcsvv8z06dPZsWMHCxYsIC0tjWnTpvHdd9+RmppKYmIi+/fvZ86cOTz11FNYLBb+/ve/M3fuXDIyMhptCdSU1NRU3nvvPW644QYyMjKIiory5ZWe74cffvClbFS75ZZb+O///m9ff0SAH3/8kX379vHuu+8CWs2d2267zZfe8ec//5k5c+Zw5MiRJkd8xo0bx9atW+v0Y7xQhfZITWIq3PgwXHMPDJrQ0WcjhBCiHQwYMICTJ08CWkHWffv28c477zBmzBj69u3Ls88+S0xMDB999BFhYWG+2maJiYkkJyej1+sZPnw4v/jFLxg6dCh9+/blqaeeolevXnz88ccBnZNer/e1CurSpQvJycl1Sp3UdvLkSfR6PV26dPFtGzJkCMOGDePNN9/0bVu9ejVjx46lX79+gBbQ/exnP2PgwIEMHDiQl19+GZvNxpdfftnkuXXr1s339brQhfZIjTUGBrdyWbgQQlxEjDptxKSjXjsYahdv3blzJ+Xl5XWKsgJUVlZy4sSJRo9RUVHB0qVL+eSTTzh79ixut5vKyso6C2HaSmVlZYPtG2655RZWrlzJ448/jqqqvPXWW3VWCefm5vKf//mffPHFF5w7dw6Px4PNZmv2nMPCwoJa1bcjhXZQI4QQwi+KorR6CqijHTx4kJ49ewJafkpKSgqbN2+us4/X663Xg6i2hx9+mA0bNvDss8/Sp08fwsLCmD9/Pk6n07ePoij18oCC0ccoISEBm82G0+nEZDL5tt9888088sgj7Nq1i8rKSk6fPs1PfvIT3+OLFi0iLy+P5cuXk5aWhtlsZsKECXXOuSGFhYUkJia2+rw7AwlqhBBChIwvvviCffv2+Zokjxo1ipycHAwGA+np6b79vF5vk72utm7dyqJFi7juuusAKC8vrzdFk5iYSHZ2tu/+kSNHmhzxqA5QPB5Pk+9hxIgRABw4cMB3G6B79+5MnjyZ1atXU1lZybRp0+pU3t+6dSsrVqzwtQQ6ffo0+fn5Tb4WwP79+7niiiua3e9CENo5NYU5cPoQnDsFTkfz+wshhLhgOBwOcnJyyMrKYteuXfzxj3/kmmuu4eqrr/YVgZ02bRoTJkzg2muvZcOGDZw8eZJt27bx+OOPs3v37kaP3adPH95//3327NnD3r17ufnmm+vVv5k6dSp//etf2bVrF99//z133313kyX/09LSUBSFTz75hLy8vDqV9mtLTExk1KhRfPXVV/Ueu+WWW3j77bd55513+NnPflbvnN944w0OHjzIt99+yy233NJoMnI1m83Gzp07mTFjRpP7XShCO6j5fgO89ii89ACcPdrRZyOEECKI1q9fT0pKCunp6cyaNYtNmzbx4osv8tFHH/mmlhRFYe3atUyePJk77riDfv368ZOf/ISTJ082OeXy/PPPExsby8SJE5k7dy4zZ85k1KhRdfb585//TGpqKpMnT+bmm2/mN7/5DeHh4Y0es1u3bixdupRHHnmEpKQk7rnnnkb3veuuu1i9enW97TfeeCMFBQXYbDauvfbaOo+tXLmSoqIiRo4cycKFC7nvvvvqJBs35KOPPqJHjx5cdtllTe53oVBUfwsDdFKlpaVER0eTn59fkxD2yf9ogQ3AXc9C194dd4IXEZfLxdq1a5kzZ06natx3MZJr0Xl01mtht9s5ceIEPXv2vKi6dFdPP0VFRXXKhpZ2u53+/fvz9ttvM2FC263eHTduHA888AA333xzm70GNP19VlBQQEJCAiUlJURFRbXqdTrflQym2nVqpKGlEEKIC4TFYuEf//hHi3JiApWbm8v8+fP56U9/2mav0d5CO1FYiu8JIYS4QF1++eVtevwuXbrw29/+tk1fo72F9kiNQ9okCCGEEBeL0A5qao/UGM0ddx5CCCGEaHMhHtRUjdQYLdAJE8GEEEIIETyh/UlfPVIj+TRCCCFEyAvxoKZqpEaCGiGEECLkhXhQUzVSI8u5hRBCiJAX2ku6H30TXA7wuDv6TIQQQgjRxkJ7pMZghDArWGM6+kyEEEJ0Yq+88gqpqanodDqWL18elGOePHkSRVHYs2dPQM9fuHAhf/zjH4NyLg1RFIUPP/ywxft/8sknjBw5sl4PrM4ktIMaIYQQIWnRokUoioKiKBiNRpKSkpg+fTorV670+0O3tLSUe+65h9/97ndkZWVx1113tck5b968GUVRKC4ubnbfH374gU8//ZR7773Xty09PT1oARdAdnY2s2fPbvH+V199NYqi8OabbwbtHIJNghohhBAXpFmzZpGdnc3JkydZt24dU6ZM4f777+fqq6/G7W552kFmZiYul4urrrqKlJSUJptStpe//vWv3HjjjURGRvr1PI/H0+KgLjk5GbPZvxput99+O3/5y1/8ek57Ct2gpigXNv4DvnwHTu7v6LMRQogLitOjNvrP7VVbvK+rhfsGwmw2k5ycTLdu3Rg1ahT/8R//wUcffcS6detYtWqVb7+SkhLuuusuunTpQlRUFFOnTmXv3r0ArFq1iqFDhwLQq1cvFEXh5MmTHDt2jGuuuYakpCSsVitjx47l888/r/P6DU3fxMTE1HntaidPnmTKlCkAxMbGoigKixYtavB9eb1e3nnnHebNm+fbdsUVV3Dq1CkefPBB3whV9fnHxMTwySefMGjQIMxmM6dOnWLHjh1Mnz6dhIQEoqOjufzyy9m1a1ej5189Vfb+++8zZcoUwsPDGT58ONu3b6/znHnz5vHdd99x/PjxBs+9o4VuonBRDnz9gXb7shsgfUjHno8QQlxAnvuhoNHHekcZubF3tO/+X/YX4GpkcCDVauCWvjG++y8dKKTSXT+IeWRkQsDnWtvUqVMZPnw477//PnfeeSeqqnLVVVcRFxfH2rVriY6O5uWXX2b69Ons2LGDBQsWkJaWxrRp0/juu+9ITU0lMTGR/fv3M2fOHJ566iksFgt///vfmTt3LhkZGfTo0cPv80pNTeW9997jhhtuICMjg6ioKMLCGl6Z+8MPP1BcXMyYMWN8295//32GDx/OXXfdxc9//vM6+9tsNpYtW8arr75KfHw8Xbp04cSJE9x22228+OKLAPz5z39mzpw5HDlypMnRn8cee4xnn32Wvn378thjj/HTn/6Uo0ePYjBo4UJaWhpdunRh69at9OrVy++vQ1sL3aDGKX2fhBDiYjRgwAB++OEHADZt2sS+ffvIzc31TbU8++yzfPjhh3z00Ufcd999xMfHA5CYmEhycjIAw4cPZ/jw4b5jPvXUU3zwwQd8/PHH3HPPPX6fk16vJy4uDtAaScbExDS678mTJ9Hr9XTp0sW3LS4uDr1eT2RkpO8cq7lcLlasWFHnfKdOnVpnn5dffpnY2Fi+/PJLrr766kZf+ze/+Q1XXXUVAEuXLmXw4MEcPXqUAQMG+Pbp1q0bJ0+ebPY9d4TQDWqkmaUQQgTsoWHxjT6mU+rev3dI4/sq5+37y0FxrTmtFlFV1Tc9s3PnTsrLy32BS7XKykpOnDjR6DEqKipYunQpn3zyCWfPnsXtdlNZWUlmZmabnnv1uZnNZt97aI7JZGLYsGF1tuXm5vKf//mffPHFF5w7dw6Px4PNZmv2/GsfJyUlxXes2kFNWFgYNputpW+nXYVuUFO7maVUFBZCCL+Y9C37QG3LfQN18OBBevbsCWj5KSkpKWzevLnOPl6vF71e3+gxHn74YTZs2MCzzz5Lnz59CAsLY/78+TidTt8+iqKgqnWn0lwuV6vPPyEhAZvNhtPpxGQyNbt/WFhYvQBo0aJF5OXlsXz5ctLS0jCbzUyYMKHO+TfEaDT6blcf8/zE48LCQhITE1v6dtqVBDVCCCFCxhdffMG+fft48MEHARg1ahQ5OTkYDAbS09N9+3m9XkpLSxs9ztatW1m0aBHXXXcdAOXl5fWmXBITE8nOzvbdP3LkSJMjGNUBisfjafI9jBgxAoADBw74blc/v7nn1j7/FStWMGfOHABOnz5Nfn5+i57bFLvdzrFjxxg5cmSrj9UWQnf1U+2cGmmTIIQQIcfhcJCTk0NWVha7du3ij3/8I9dccw1XX301t956KwDTpk1jwoQJXHvttWzYsIGTJ0+ybds2Hn/8cXbv3t3osfv06cP777/Pnj172Lt3LzfffHO9EYupU6fy17/+lV27dvH9999z99131xnpOF9aWhqKovDJJ5+Ql5dHeXl5g/slJiYyatQovvrqqzrb09PT2bJlC1lZWc0GKH369OGNN97g4MGDfPvtt9xyyy2NJib745tvvvGN+nRGIRzUyEiNEEKEsvXr15OSkkJ6ejqzZs1i06ZNvPjii3z00Ue+qSVFUVi7di2TJ0/mjjvuoF+/fvzkJz/h5MmTTU6hPP/888TGxjJx4kTmzp3LzJkzGTVqVJ19/vznP5OamsrkyZO5+eab+c1vftNkjZtu3bqxdOlSHnnkEZKSkppMOL7rrrtYvXp1nW1PPPEEJ0+epHfv3s1O/6xcuZKioiJGjhzJwoULue++++okHgfqrbfe4pZbbukUtXwaoqjnTwheoEpLS4mOjiY/P19LCPvXS7DzM+3Bu5+D5J4de4IXEZfLxdq1a5kzZ06Tf7WItifXovPorNfCbrdz4sQJevbsicVy8fwBWD39FBUVhU7X+f6+t9vt9O/fn7fffrvTjIrk5eUxYMAAvv/+e1/OUks19X1WUFBAQkICJSUlREVFteocO9+VDBZZ/SSEEOICZbFY+Mc//hGUPJhgOXHiBCtWrPA7oGlPoZsonNANegzScmvMnXOYTAghhGjM5Zdf3tGnUMe4ceMYN25cR59Gk0I3qLligfZPCCGEEBeF0J1+EkIIIcRFRYIaIYQQQoSEgIKa6kQhi8XC6NGj2bp1a6P7bt682ddRtPa/Q4cO+fZZtWpVg/vY7fZGjyuEEEIIUZvfOTVr1qzhgQceYMWKFUyaNImXX36Z2bNnc+DAgSY7l1Z3Ja12/hr7qKgoMjIy6mxr1fLCVx7W/k/oDtffH/hxhBBCCHFB8Duoee6551i8eDF33nknAMuXL2fDhg289NJLLFu2rNHnNdeVVFGUep1HA6aqkH0cVK/2TwghhBAhz6+gxul0snPnTh555JE622fMmMG2bduafO7IkSOx2+0MGjSI3//+90yZMqXO4+Xl5aSlpeHxeBgxYgRPPvlkk70lHA4HDofDd7+6h4fL5cJVacNYFcx4jRY8QWgwJlquuqFbMBq7idaRa9F5dNZr4XK5UFUVr9dbrw1AKKuuO1v93kXb8nq9qKqKy+Wq10g0mD8TfgU1+fn5eDwekpKS6mxPSkoiJyenweekpKTwyiuvMHr0aBwOB2+88QZXXnklmzdvZvLkyQAMGDCAVatWMXToUEpLS3nhhReYNGkSe/fupW/fvg0ed9myZSxdurTe9k2bNhFj1DG76n5ucSnfrl3rz9sUQbJx48aOPgVRRa5F59HZroXBYCA5OZny8vJmOziHorKysnZ/zczMTIYPH86WLVsYOnRok/v+4Q9/8HXbDpZhw4bxy1/+kl/+8pc4HA5Gjx7NP//5zzrNM4PN6XRSWVnJli1bcLvddR5rqgmovwKqU3N+i3NVVettq9a/f3/69+/vuz9hwgROnz7Ns88+6wtqxo8fz/jx4337TJo0iVGjRvGXv/yFF198scHjPvroozz00EO++6WlpaSmpjJlyhTi9R7Y/zYAXbr38HUpFe3D5XKxceNGpk+f3qnKwV+M5Fp0Hp31Wtjtdk6fPo3Var2g2iTcfvvt/OMf//Ddj4uLY8yYMTz99NMMGzas2eerqkpZWRmRkZGNfn4tXbqUjz76iF27djV5rJbuV81qtQIQERHRZFuAc+fO8fLLL7Nnz55Wtw+oTafTYbFYfMd8+OGHeeqpp/jss8+C9hrns9vthIWFMXny5AbbJASLX0FNQkICer2+3qhMbm5uvdGbpowfP55//vOfjT6u0+kYO3YsR44caXQfs9mM2Wyut91oNGJ010xL6Szh6DrRL5CLidFo7FS/vC9mci06j852LTweD4qioNPpOmUPpMYoisKsWbN4/fXXAcjJyeH3v/898+bNIzMzs9nnV085Vb/3xl4DaPbr0tL9qlXv19zX/PXXX2fChAn06tWrRcf1R+33/bOf/Yzf/va3ZGRkMHDgwKC/FmjvVVGUBr//g/nz4Nd3sMlkYvTo0fWGTzdu3MjEiRNbfJzdu3eTkpLS6OOqqrJnz54m92mS9H0SQoiQZzabSU5OJjk5mREjRvC73/2O06dPk5eX59snKyuLBQsWEBsbS3x8PNdccw0nT570Pb5582bGjRtHREQEMTExTJo0iVOnTrFq1SqWLl3K3r17fWVGVq1a1aLz8nq9PPHEE3Tv3h2z2cyIESNYv359vf0OHTrExIkTsVgsDB48mM2bN9d5/O2332bevHm++y+//DLdunWrlwM0b948brvtNgCOHTvGNddcQ1JSElarlbFjx/L55583eb7x8fFMnDiRt956q0XvrzPze/rpoYceYuHChYwZM4YJEybwyiuvkJmZyd133w1o00JZWVm+YcHly5eTnp7O4MGDcTqd/POf/+S9997jvffe8x1z6dKljB8/nr59+1JaWsqLL77Inj17+Nvf/hbYu3LWqm9junCGU4UQolN4+TdQXtz+r2uNgV88G9BTy8vLWb16NX369CE+Ph7QcjWmTJnCZZddxpYtWzAYDDz11FPMmjWLPXv24Ha7uf766/n5z3/OW2+9hdPp5LvvvkNRFBYsWMD+/ftZv369LyiIjo5u0bm88MIL/PnPf+bll19m5MiRrFy5knnz5vHjjz/WyRN9+OGHWb58OYMGDeK5555j3rx5nDhxgvj4eIqKiti/fz9jxozx7X/jjTdy3333sWnTJq688koAioqK2LBhA//61798X4c5c+bw1FNPYbFY+Pvf/87cuXPJyMhosuzKuHHjmqw5d6HwO6hZsGABBQUFPPHEE2RnZzNkyBDWrl1LWloaANnZ2XWG/pxOJ7/5zW/IysoiLCyMwYMH8+mnn9bJcykuLuauu+4iJyeH6OhoRo4cyZYtWwJvnOWUkRohhAhYeTGUBS/Poa188sknvvyUiooKUlJS+OSTT3zTKm+//TY6nY5XX33VN0X0+uuvExMTw+bNm+nfvz8lJSVcffXV9O7dG6DO9IvVavUlUvvj2Wef5Xe/+x0/+clPAHj66afZtGkTy5cvr/PH+j333MMNN9wAwEsvvcT69et57bXX+O1vf8upU6dQVZWuXbv69o+Li2PWrFm8+eabvqDmnXfeIS4uznd/+PDhDB8+3Pecp556ig8++ICPP/6Ye+65p9Fz7tatW50RrAtVQInCS5YsYcmSJQ0+dv7w3G9/+1t++9vfNnm8559/nueffz6QU2lYnaBGRmqEEMIv1pgL4nWnTJnCSy+9BEBhYSErVqxg9uzZfPfdd6SlpbFz506OHj1KZGRknefZ7XaOHTvG+PHjue2225g5cybTp09n2rRp3HTTTYGnPqAtWjl79iyTJk2qs716RW9tEyZM8N02GAyMGTOGgwcPAlBZqX2OnZ9Ue8stt3DXXXexYsUKzGYzq1ev5ic/+YlvmXRFRQVLly7lk08+4ezZs7jdbiorK5vNMwoLCwvqKqSOEppdurv2gRmLtGmo7v06+myEEOLCEuAUUHuLiIigT58+vvujR48mOjqa//3f/+Wpp57C6/UyevRoVq9eXe+51VNUK1eu5P7772f9+vWsWbOG3//+92zcuLHOitxA+LNKuKHnJSQkANr0Uu0K/HPnzsXr9fLpp58yduxYtm7dynPPPed7/OGHH2bDhg08++yz9OnTh7CwMObPn9/scv3CwsJ6lf4vRBdOqrs/uvSAidfAFQuga++OPhshhBDtoHpFT/Uox6hRozhy5AhdunShT58+df7Vzo8ZOXIkjz76KNu2bWPIkCG8+eabgLY4xuPx+HUOUVFRdO3ala+++qrO9m3bttVbWfTNN9/4brvdbnbu3MmAAQMA6N27N1FRURw4cKDOc8LCwrj++utZvXo1b731Fv369WP06NG+x7du3cqiRYu47rrrGDp0KMnJyS2aVtq/f3+TBW8vFKEZ1AghhAh5DoeDnJwccnJyOHjwIPfeey/l5eXMnTsX0KZqEhISuOaaa9i6dSsnTpzgyy+/5P777+fMmTOcOnWK//iP/2D79u2cOnWKzz77jMOHD/uCj/T0dE6cOMGePXvIz8+vU8W+KQ8//DBPP/00a9asISMjg0ceeYQ9e/Zw//11+xD+7W9/44MPPuDQoUP86le/oqioiDvuuAPQlkBPmzatXnBU/b4+/fRTVq5cyc9+9rM6j/Xp04f333+fPXv2sHfvXm6++eYWVUzeunUrM2bMaNH768xCc/pJCCFEyFu/fr0v/yUyMpIBAwbwzjvvcMUVVwAQHh7Oli1b+N3vfsf1119PWVkZ3bp148orryQqKgq73c6hQ4f4xz/+QUFBASkpKdxzzz384he/AOCGG27g/fffZ8qUKRQXF/P666+zaNGieufh9XoxGGo+Tu+77z5KS0v59a9/TW5uLoMGDeLjjz+uVyH/v//7v3n66afZvXs3vXv35qOPPvJNOwHcddddLF68mGeeeaZOPZupU6cSFxdHRkYGN998c51jPv/889xxxx1MnDiRhIQEfve73/naCDVm+/btlJSUMH/+/Oa/6J2colY3wLjAlZaWEh0dTX5+PvFmPXi9WpKwOQxaMI8pgsflcrF27VrmzJnTqYqMXYzkWnQenfVa2O12Tpw4Qc+ePS+oisL/v707j4rqvPsA/h1mYFiEwYI6Q1BBcYloQCEGsJK478HoaTCvx6MxNaEvKERjFXFLaytag8Sj2FKTWFMTaBWrr6chEsOWoo2xoMQodWERC3UHXBi25/2DcusIKAPDDF6+n3PuOdztmd/Mj4Hfee69z9NRDQ0NqKyshJOTU4cHHQwLC0NpaSmOHj1qougaCSEQEBCAqKgovPHGGyZt+1E/+clPMHLkSKxZs6bTXuNJv2e3bt2Cq6srKioqOjxysjwvP32xB4h7C4idD9y98fTjiYiIjFRVVYWsrCykpKRg4sSJJm9foVAgMTGx2VxJpqTX6+Hj44N33323017DnOR5+YmD7xERUSdbv3499u/fj9dee00agNbUHh93xtTUajXWrl3bae2bm0yLGo5TQ0REncvkY6xRh8nz8lNTT42VElB1nWvXRERE1HnkWdQ0TWhpY8ubhImIiLoJeRY1TT01nPeJiIio25B5UcP7aYiIiLoL+RU1QrCoISIi6obkV9TU6gH8ZzxBNS8/ERERdRfyK2pqHpmbgz01RETUxRQVFUGhUCAvL8/ocwsKCqDValFVVWX6wABs3LgRvr6+Rp3z4osvIiUlpVPiMZb8ihr7HsDSBOCdOGDSQktHQ0REnWDRokVQKBTS4uLigqlTp+Ls2bMme422/oNvTyHQXjExMQgPD4ejoyMAYO/evXB2djZZ+++99x6OHz9u1Dnr1q3D6tWr2zRxZmeTX1FjpQRcdIDOE3B9ztLREBFRJ5k6dSrKyspQVlaG48ePQ6VSYebMmZYOq9OUlpbiyJEjePPNN40+t6ampk3H9ejRAy4uLka1PWPGDFRUVODLL780Oi5Tk19RQ0RE3YJarYZWq4VWq4Wvry9WrVqFq1ev4saN/875d+3aNYSGhqJnz55wcXFBSEgIioqKpP0ZGRkYPXo0HBwc4OzsjDFjxqC4uBh79+7F+++/jzNnzki9QXv37m1TXA0NDfjFL34Bd3d3qNVq+Pr6IjU1tdlxFy5cQFBQEGxtbeHt7Y2MjIwntvunP/0JPj4+cHd3l2J/8803UVFRIcW4ceNGAICHhwc2bdqERYsWQaPRYMmSJQCAVatWYfDgwbC3t8eAAQOwbt061NbWSq/xeK/TokWLMHv2bGzbtg06nQ4uLi4IDw83OEepVGL69On4/PPP2/T5dCZ5TpNAREQdk3MYOPF/Tz9ONwD4n8dmd/7s10DZlaefGzgLCAppX3yPuXfvHvbv3w8vLy+pp+HBgwcYN24cxo4di6ysLKhUKmzatAlTp05FXl4e6urqMGfOHCxZsgSff/45ampq8O2330KhUCA0NBTff/89UlNT8dVXXwEANBpNm2L58MMP8cEHH+B3v/sdRo4ciY8//hivvvoqzp07h0GDBknHrVy5EvHx8Rg2bBji4uLw6quvorCwsNWekqysLPj7+0vrQUFBiI+Px/r161FQUACgsaelyW9+8xusW7fOYG4nR0dH7N27F25ubsjPz8eSJUvg6OiIn//8562+n/T0dOh0OqSnp+PSpUsIDQ2Fr6+vVCgBwOjRo7F169Y2fT6dSX5Fze0y4MqpxpuE3QcDLm6WjoiI6NmjfwhU3Xr6cZoW/gE/qGjbufqHTz/mCY4ePSr9E79//z50Oh2OHj0KK6vGixBJSUmwsrLCnj17oPjP6PKffPIJnJ2dkZGRgSFDhqCiogIzZ87EwIEDAQDPP/+81H6PHj2gUqmg1WqNimvbtm1YtWoV5s2bBwDYsmUL0tPTER8fj127dknHRUREYO7cuQCA3bt3IzU1FR999FGrBUZRURH8/PykdRsbG2g0GigUihZjHD9+PN577z2DbY8WOB4eHlixYgWSk5OfWNT07NkTO3fuhFKpxNChQzFjxgwcP37coKh57rnnUFJSgoaGBunztwTZFTWKaxeBjH2NKzPeYVFDRNQeajvAsQ33Vti30Hthr2nbuR0cdmPcuHHYvXs3AOD27dtISEjAtGnT8O2336J///44ffo0Ll26JN1U26S6uhqXL19GQEAAFi5ciClTpmDSpEmYOHEiXn/9deh0unbHVFlZiX/9618YM2aMwfYxY8bgzJkzBtsCAwOln1UqFfz9/XH+/PlW23748CFsbdv+VO+jvTpNDhw4gPj4eFy6dAn37t1DXV0dnJycntiOt7c3lEqltK7T6ZCfn29wjJ2dHRoaGqDX62FnZ7nhVORX1NRW/3eF49QQEbVPUEj7Lw09fjmqkzg4OMDLy0ta9/Pzg0ajwe9//3ts2rQJDQ0N8PPzw/79+5ud23SJ5+OPP0ZkZCRSU1ORnJyMtWvXIi0tDQEBAR2KTfHYvINCiGbb2nLeo1xdXXHnzp02x+Dg4GCwfvLkScybNw/vv/8+pkyZAo1Gg6SkJHzwwQdPbMfa2nBiaIVC0exJp9u3b8Pe3t6iBQ0gxxuFax4pajhODRFRt6FQKGBlZYWHDxsva40aNQoXL15E79694eXlZbA8en/MyJEjER0djZycHAwfPhyfffYZgMbLO/X19UbF4OTkBDc3N3zzzTcG23NycgwubQGNRUaTuro6nD59GkOHDm217ZEjR+KHH34w2GZMjH/729/Qv39/xMTEwN/fH4MGDUJxcXGbzn2a77//HqNGjTJJWx0hw6Lm0cH32FNDRCRXer0e5eXlKC8vx/nz57F06VLcu3cPs2bNAgDMnz8frq6uCAkJQXZ2NgoLC5GZmYnIyEiUlpaiuLgYa9aswYkTJ1BcXIxjx47hn//8p1R8eHh4oLCwEHl5ebh58yb0ev2TwpGsXLkSW7ZsQXJyMgoKCrB69Wrk5eUhMjLS4Lhdu3bh0KFDuHDhAsLDw3Hnzh0sXry41XanTJmCEydOGBQxHh4euHfvHo4fP46bN2/iwYMHrZ7v5eWFkpISJCUl4fLly9ixYwcOHTrUpvf0NNnZ2Zg8ebJJ2uoI+RU1teypISLqDlJTU6HT6aDT6fDSSy/h1KlT+POf/4xXXnkFAGBvb4+srCz069cPc+bMwfPPP4/Fixfj4cOHcHJygp2dHS5cuIC5c+di8ODBePvttxEREYF33nkHADB37lxMnToV48aNQ69evVp9ZLmhoQEq1X/v5li2bBlWrFiBFStWYMSIEUhNTcWRI0cMnnwCgNjYWGzZsgU+Pj7Izs7G4cOH4erq2ur7nT59OqytraWnsYDGJ6DCwsIQGhqKXr16PfEJpJCQELz77ruIiIiAr68vcnJysG7duqd+zk9z7do15OTktGv8HFNTCCGEpYMwhcrKSmg0Gtz5NBbOl/7Tpfe/O4DefS0bWDdUW1uLv/71r9IXkCyHueg6umouqqurUVhYCE9PT6NuQn3WNTQ0oLKyEk5OTh1+WicsLAylpaU4evSoiaJrXUJCAg4fPtwlBrprsnLlSlRUVCAxMbHVY570e3br1i24urqioqLiqTctP438empqeKMwERF1vqqqKmRlZSElJQUTJ040y2u+/fbbCA4O7rS5n9qjd+/e+OUvf2npMADI8OknXn4iIiJzWL9+Pfbv34/XXnsNYWFhZnlNlUqFmJgYs7xWW61cudLSIUhkWNRwlm4iIup827dvx/bt2y0dBj1CfkWNnSOg6QXU1wFK+b09IiIiapns/uvXz14GGDnDKBFRdyeTZ0aoi3p8sL7OIruihoiI2s7a2hoKhQI3btxAr1692jTqrRw0NDSgpqYG1dXVFp2rSO6EEKipqcGNGzdgZWUFGxubTn09FjVERN2YUqmEu7s7SktLUVRUZOlwzEYIgYcPH8LOzq7bFHKWZG9vj379+nV6Acmihoiom+vRowcGDRqE2tpaS4diNrW1tcjKykJwcHCXGjdIjpRKJVQqlVmKR9kVNcoD2wDnnoD7YGDMbEuHQ0T0TFAqlQYzMcudUqlEXV0dbG1tWdTIiOyKGquifEBtDQjz3JREREREXUO7Lm4lJCRIQx37+fkhOzu71WMzMjKgUCiaLRcuXDA47uDBgxg2bBjUajWGDRvW8Um2OJklERFRt2J0UZOcnIyoqCjExMQgNzcXY8eOxbRp01BSUvLE8woKClBWViYtj07sdeLECYSGhmLBggU4c+YMFixYgNdffx1///vfjX9HTTjwHhERUbdi9OWnuLg4vPXWW/jpT38KAIiPj8eXX36J3bt3Y/Pmza2e17t3bzg7O7e4Lz4+HpMmTUJ0dDQAIDo6GpmZmYiPj291VlS9Xm8wDXxFRQUAoFLfeKNbvb4eDbduGfv2yARqa2vx4MED3Lp1i9eqLYy56DqYi66F+eg6bt++DcBEYyUJI+j1eqFUKkVKSorB9mXLlong4OAWz0lPTxcAhIeHh9BqtWL8+PHi66+/Njimb9++Ii4uzmBbXFyc6NevX6uxbNiwQQDgwoULFy5cuMhguXz5sjElSYuM6qm5efMm6uvr0adPH4Ptffr0QXl5eYvn6HQ6JCYmws/PD3q9Hp9++ikmTJiAjIwMBAcHAwDKy8uNahNo7M1Zvny5tH737l30798fJSUl0Gg0xrwtMrHKykr07dsXV69e7fA08tQxzEXXwVx0LcxH11FRUYF+/frhRz/6UYfbatfTT48/ay6EaPX58yFDhmDIkCHSemBgIK5evYpt27ZJRY2xbQKAWq2GWq1utl2j0fAXtItwcnJiLroI5qLrYC66Fuaj6zDFwHxGteDq6gqlUtmsB+X69evNelqeJCAgABcvXpTWtVpth9skIiKi7s2oosbGxgZ+fn5IS0sz2J6WloagoKA2t5ObmwudTietBwYGNmvz2LFjRrVJRERE3ZvRl5+WL1+OBQsWwN/fH4GBgUhMTERJSQnCwsIANN7rcu3aNezbtw9A45NNHh4e8Pb2Rk1NDf74xz/i4MGDOHjwoNRmZGQkgoODsWXLFoSEhODw4cP46quv8M0337Q5LrVajQ0bNrR4SYrMi7noOpiLroO56FqYj67DlLlQCGH8M1QJCQnYunUrysrKMHz4cGzfvl26P2bRokUoKipCRkYGAGDr1q1ITEzEtWvXYGdnB29vb0RHR2P69OkGbR44cABr167FlStXMHDgQPzqV7/CnDlzOvwGiYiIqHtoV1FDRERE1NV07hzgRERERGbCooaIiIhkgUUNERERyQKLGiIiIpIFWRQ1CQkJ8PT0hK2tLfz8/JCdnW3pkLqFrKwszJo1C25ublAoFPjLX/5isF8IgY0bN8LNzQ12dnZ45ZVXcO7cOcsEK2ObN2/Giy++CEdHR/Tu3RuzZ89GQUGBwTHMhfns3r0bL7zwgjRSbWBgIL744gtpP3NhGZs3b4ZCoUBUVJS0jbkwn40bN0KhUBgsWq1W2m+qXDzzRU1ycjKioqIQExOD3NxcjB07FtOmTUNJSYmlQ5O9+/fvw8fHBzt37mxx/9atWxEXF4edO3fi1KlT0Gq1mDRpEqqqqswcqbxlZmYiPDwcJ0+eRFpaGurq6jB58mTcv39fOoa5MB93d3fExsbiu+++w3fffYfx48cjJCRE+gPNXJjfqVOnkJiYiBdeeMFgO3NhXt7e3igrK5OW/Px8aZ/JctHhKTEtbPTo0SIsLMxg29ChQ8Xq1astFFH3BEAcOnRIWm9oaBBarVbExsZK26qrq4VGoxG//e1vLRBh93H9+nUBQGRmZgohmIuuoGfPnmLPnj3MhQVUVVWJQYMGibS0NPHyyy+LyMhIIQS/F+a2YcMG4ePj0+I+U+bime6pqampwenTpzF58mSD7ZMnT0ZOTo6FoiIAKCwsRHl5uUFu1Go1Xn75Zeamk1VUVACANOMtc2E59fX1SEpKwv379xEYGMhcWEB4eDhmzJiBiRMnGmxnLszv4sWLcHNzg6enJ+bNm4crV64AMG0u2jVLd1dx8+ZN1NfXN5v4sk+fPs0myCTzavr8W8pNcXGxJULqFoQQWL58OX784x9j+PDhAJgLS8jPz0dgYCCqq6vRo0cPHDp0CMOGDZP+QDMX5pGUlIR//OMfOHXqVLN9/F6Y10svvYR9+/Zh8ODB+Pe//41NmzYhKCgI586dM2kunumipolCoTBYF0I020aWwdyYV0REBM6ePdvivGnMhfkMGTIEeXl5uHv3Lg4ePIiFCxciMzNT2s9cdL6rV68iMjISx44dg62tbavHMRfmMW3aNOnnESNGIDAwEAMHDsQf/vAHBAQEADBNLp7py0+urq5QKpXNemWuX7/erOIj82q6q525MZ+lS5fiyJEjSE9Ph7u7u7SduTA/GxsbeHl5wd/fH5s3b4aPjw8+/PBD5sKMTp8+jevXr8PPzw8qlQoqlQqZmZnYsWMHVCqV9HkzF5bh4OCAESNG4OLFiyb9XjzTRY2NjQ38/PyQlpZmsD0tLQ1BQUEWiooAwNPTE1qt1iA3NTU1yMzMZG5MTAiBiIgIpKSk4Ouvv4anp6fBfubC8oQQ0Ov1zIUZTZgwAfn5+cjLy5MWf39/zJ8/H3l5eRgwYABzYUF6vR7nz5+HTqcz7feiHTcxdylJSUnC2tpafPTRR+KHH34QUVFRwsHBQRQVFVk6NNmrqqoSubm5Ijc3VwAQcXFxIjc3VxQXFwshhIiNjRUajUakpKSI/Px88cYbbwidTicqKystHLm8/OxnPxMajUZkZGSIsrIyaXnw4IF0DHNhPtHR0SIrK0sUFhaKs2fPijVr1ggrKytx7NgxIQRzYUmPPv0kBHNhTitWrBAZGRniypUr4uTJk2LmzJnC0dFR+l9tqlw880WNEELs2rVL9O/fX9jY2IhRo0ZJj7JS50pPTxcAmi0LFy4UQjQ+prdhwwah1WqFWq0WwcHBIj8/37JBy1BLOQAgPvnkE+kY5sJ8Fi9eLP096tWrl5gwYYJU0AjBXFjS40UNc2E+oaGhQqfTCWtra+Hm5ibmzJkjzp07J+03VS4UQghhgp4kIiIiIot6pu+pISIiImrCooaIiIhkgUUNERERyQKLGiIiIpIFFjVEREQkCyxqiIiISBZY1BAREZEssKghIiIiWWBRQ0RERLLAooaIiIhkgUUNERERycL/A+Yzo/bQl1mcAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(json.loads(metadata_default[\"val_accuracy\"]), color=\"skyblue\", label=\"Default (val)\")\n",
    "plt.plot(json.loads(metadata_default[\"accuracy\"]), color=\"skyblue\", linestyle=\"--\", label=\"Default (train)\")\n",
    "plt.plot(json.loads(best_job[\"m:val_accuracy\"]), color=\"coral\", linewidth=2, label=\"Best Job(val)\")\n",
    "plt.plot(json.loads(best_job[\"m:accuracy\"]), color=\"coral\", linestyle=\"--\", linewidth=2, label=\"Best Job (train)\")\n",
    "plt.legend()\n",
    "plt.xlim(0,50)\n",
    "plt.ylim(0.5, 0.9)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ornl_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
