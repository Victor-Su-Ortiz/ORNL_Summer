{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import seaborn as sn\n",
    "try:\n",
    "    import deephyper\n",
    "    print(deephyper.__version__)\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install deephyper\n",
    "\n",
    "try:\n",
    "    import ray\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    !pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X_train, X_val, X_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def load_data():\n",
    "    (X_train, Y_train), (X_val_test, Y_val_test) = tf.keras.datasets.mnist.load_data()\n",
    "    X_val, X_test = np.split(X_val_test, 2)\n",
    "    Y_val, Y_test = np.split(Y_val_test, 2)\n",
    "    X_train, X_val, X_test = reshape(X_train, X_val, X_test)\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_dataset(X_train, train_labels, X_test, test_labels, X_val, val_labels):\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, train_labels))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_test, test_labels))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, val_labels))\n",
    "    return train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = np_to_dataset(X_train, Y_train, X_test, Y_test, X_val, Y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dataset(config: dict, train_dataset, test_dataset, val_dataset):\n",
    "    batch_size = config['batch_size']\n",
    "    train_dataset = train_dataset.shuffle(60000).batch(batch_size)\n",
    "    test_dataset = test_dataset.shuffle(5000).batch(batch_size)\n",
    "    val_dataset = val_dataset.shuffle(5000).batch(batch_size)\n",
    "    return train_dataset, test_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'batch_size': 36,\n",
    "        'patience': 10,\n",
    "        'scheduler_factor': 0.8,\n",
    "        'dropout_rate': 0.5,\n",
    "        'units1': 128,\n",
    "        'units2': 64,\n",
    "        'units3': 32,\n",
    "        'units4': 10,\n",
    "        'units5': 32,\n",
    "        'units6': 16,\n",
    "        'activation1': 'relu',\n",
    "        'activation2': 'sigmoid',\n",
    "        'activation3': 'sigmoid',\n",
    "        'activation4': 'softmax',\n",
    "        'num_layers1': 2,\n",
    "        'num_layers2': 2,\n",
    "        'num_layers3': 2,\n",
    "        'num_layers4': 2,\n",
    "        'num_layers5': 2,\n",
    "        'num_layers6': 2,\n",
    "        'lr': 0.00005,\n",
    "        'num_epochs': 5,\n",
    "        'use_batch_norm': True,\n",
    "        'optimizer': 'adam'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import json\n",
    "\n",
    "def count_params(model: tf.keras.Model) -> dict:\n",
    "    \"\"\"Evaluate the number of parameters of a Keras model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): a Keras model.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary with the number of trainable ``\"num_parameters_train\"`` and\n",
    "        non-trainable parameters ``\"num_parameters\"``.\n",
    "    \"\"\"\n",
    "\n",
    "    def count_or_null(p):\n",
    "        try:\n",
    "            return K.count_params(p)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    num_parameters_train = int(\n",
    "        np.sum([count_or_null(p) for p in model.trainable_weights])\n",
    "    )\n",
    "    num_parameters = int(\n",
    "        np.sum([count_or_null(p) for p in model.non_trainable_weights])\n",
    "    )\n",
    "    return {\n",
    "        \"num_parameters\": num_parameters,\n",
    "        \"num_parameters_train\": num_parameters_train,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(config: dict):\n",
    "    input_layer = keras.layers.Input(shape=(784,))\n",
    "    X = keras.layers.Dense(config[\"units1\"], activation=config[\"activation1\"])(input_layer)\n",
    "    X = keras.layers.Dropout(config[\"dropout_rate\"])(X)\n",
    "    X = keras.layers.Dense(config[\"units2\"], activation=config[\"activation2\"])(X)\n",
    "    X = keras.layers.Dense(config[\"units3\"], activation=config[\"activation3\"])(X)\n",
    "    output_layer = keras.layers.Dense(config[\"units4\"], activation=config[\"activation4\"])(X)\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation4\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model(config)\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m---> 15\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m (X_train, Y_train), (X_test, Y_test) \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     24\u001b[0m X_train \u001b[38;5;241m=\u001b[39m X_train \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'optimizer'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = model(config)\n",
    "model.compile(\n",
    "    optimizer=config[\"optimizer\"],\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train = np.reshape(X_train, (-1, 784))\n",
    "X_test = np.reshape(X_test, (-1, 784))\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "\n",
    "model.fit(\n",
    "    dataset, epochs=config[\"num_epochs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config: dict):\n",
    "    X_train, Y_train, X_val, Y_val, X_test, Y_test = load_data()\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = batch_dataset(config, X_train, Y_train, X_test, Y_test, X_val, Y_val)\n",
    "\n",
    "    keras.layers.Input(shape=(784,))\n",
    "    keras.layers.Dense(config[\"units1\"], input_shape=(784,), activation=config[\"activation1\"])\n",
    "    keras.layers.Dropout(config[\"dropout_rate\"])\n",
    "    keras.layers.Dense(config[\"units2\"], activation=config[\"activation2\"])\n",
    "    keras.layers.Dense(config[\"units3\"], activation=config[\"activation3\"])\n",
    "    keras.layers.Dense(config[\"units4\"], activation=config[\"activation4\"])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=config[\"optimizer\"],\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=config[\"num_epochs\"], validation_data=val_dataset, verbose=0\n",
    "    )\n",
    "\n",
    "    objective = history.history[\"val_accuracy\"][-1]\n",
    "    metadata = {\n",
    "        \"loss\": history.history[\"loss\"],\n",
    "        \"val_loss\": history.history[\"val_loss\"],\n",
    "        \"accuracy\": history.history[\"accuracy\"],\n",
    "        \"val_accuracy\": history.history[\"val_accuracy\"],\n",
    "    }\n",
    "\n",
    "    metadata = {k:json.dumps(v) for k,v in metadata.items()}\n",
    "    metadata.update(count_params(model))\n",
    "\n",
    "    return {\"objective\": objective, \"metadata\": metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:56:52.811095: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype uint8 and shape [60000,784]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-02 14:56:52.811282: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-02 14:56:53.827762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [5000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-02 14:56:53.827890: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [5000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'objective': 0.9336000084877014,\n",
       " 'metadata': {'loss': '[1.0581825971603394, 0.587068498134613, 0.5091872811317444, 0.4797973334789276, 0.4662189781665802]',\n",
       "  'val_loss': '[0.37744295597076416, 0.2940126359462738, 0.24692827463150024, 0.22580227255821228, 0.2243204563856125]',\n",
       "  'accuracy': '[0.690416693687439, 0.815500020980835, 0.8431666493415833, 0.851016640663147, 0.8554666638374329]',\n",
       "  'val_accuracy': '[0.8988000154495239, 0.9175999760627747, 0.9277999997138977, 0.9314000010490417, 0.9336000084877014]',\n",
       "  'num_parameters': 0,\n",
       "  'num_parameters_train': 111146}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration space object:\n",
       "  Hyperparameters:\n",
       "    activation1, Type: Categorical, Choices: {relu, sigmoid}, Default: relu\n",
       "    activation2, Type: Categorical, Choices: {relu, sigmoid}, Default: sigmoid\n",
       "    activation3, Type: Categorical, Choices: {relu, sigmoid}, Default: sigmoid\n",
       "    activation4, Type: Categorical, Choices: {softmax, sigmoid}, Default: softmax\n",
       "    batch_size, Type: UniformInteger, Range: [16, 64], Default: 32\n",
       "    dropout_rate, Type: UniformFloat, Range: [0.0, 0.6], Default: 0.5\n",
       "    num_epochs, Type: UniformInteger, Range: [10, 100], Default: 50\n",
       "    optimizer, Type: Categorical, Choices: {adam, sgd}, Default: adam\n",
       "    units1, Type: UniformInteger, Range: [64, 256], Default: 128\n",
       "    units2, Type: UniformInteger, Range: [32, 128], Default: 64\n",
       "    units3, Type: UniformInteger, Range: [16, 64], Default: 32\n",
       "    units4, Type: UniformInteger, Range: [4, 32], Default: 10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deephyper.problem import HpProblem\n",
    "# from deephyper.search.nas.model.space.structure import KerasStructure\n",
    "# Define the search space\n",
    "problem = HpProblem()\n",
    "\n",
    "problem.add_hyperparameter((64, 256), \"units1\", default_value=128)\n",
    "problem.add_hyperparameter((32, 128), \"units2\", default_value=64)\n",
    "problem.add_hyperparameter((16, 64), \"units3\", default_value=32)\n",
    "problem.add_hyperparameter((4, 32), \"units4\", default_value=10)\n",
    "problem.add_hyperparameter((16, 64), \"batch_size\", default_value=32)\n",
    "problem.add_hyperparameter(['relu', 'sigmoid'], \"activation1\", default_value='relu')\n",
    "problem.add_hyperparameter(['relu', 'sigmoid'], \"activation2\", default_value='sigmoid')\n",
    "problem.add_hyperparameter(['relu', 'sigmoid'], \"activation3\", default_value='sigmoid')\n",
    "problem.add_hyperparameter(['softmax', 'sigmoid'], \"activation4\", default_value='softmax')\n",
    "problem.add_hyperparameter(['adam', 'sgd'], \"optimizer\", default_value='adam')\n",
    "problem.add_hyperparameter((0.0, 0.6), \"dropout_rate\", default_value=0.5)\n",
    "problem.add_hyperparameter((10, 100), \"num_epochs\", default_value=50)\n",
    "\n",
    "problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == \"GPU\"]\n",
    "\n",
    "\n",
    "n_gpus = len(get_available_gpus())\n",
    "if n_gpus > 1:\n",
    "    n_gpus -= 1\n",
    "\n",
    "is_gpu_available = n_gpus > 0\n",
    "\n",
    "if is_gpu_available:\n",
    "    print(f\"{n_gpus} GPU{'s are' if n_gpus > 1 else ' is'} available.\")\n",
    "else:\n",
    "    print(\"No GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:20:57.338983: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-02 14:20:57.339119: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [60000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-07-02 14:20:58.487538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [5000,784]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-02 14:20:58.487671: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [5000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Default Configuration:  0.981\n",
      "Metadata Default Configuration\n",
      "\t- loss: [0.5662249326705933, 0.2660263776779175, 0.2244025617837906, 0.2033109813928604, 0.1887427270412445, 0.17741304636001587, 0.17287389934062958, 0.16452796757221222, 0.15707066655158997, 0.15595892071723938, 0.14892783761024475, 0.14711366593837738, 0.14289157092571259, 0.14096654951572418, 0.13569745421409607, 0.1317821890115738, 0.13539882004261017, 0.130406454205513, 0.12922418117523193, 0.1279146671295166, 0.12358496338129044, 0.12500524520874023, 0.12238642573356628, 0.12483339011669159, 0.12225890159606934, 0.11522342264652252, 0.1191898062825203, 0.11746633052825928, 0.11566296964883804, 0.11472216248512268, 0.11230812221765518, 0.11197367310523987, 0.11225045472383499, 0.11071150749921799, 0.10877447575330734, 0.11051873117685318, 0.10900618135929108, 0.10886643081903458, 0.10985436290502548, 0.10907238721847534, 0.10724543780088425, 0.10592464357614517, 0.10539309680461884, 0.1045684888958931, 0.10192792117595673, 0.10197754204273224, 0.10373252630233765, 0.10248073935508728, 0.09884505718946457, 0.09996916353702545]\n",
      "\t- val_loss: [0.17164047062397003, 0.13022272288799286, 0.10823904722929001, 0.10841032862663269, 0.0985662192106247, 0.0953638032078743, 0.0883624255657196, 0.08658620715141296, 0.09088358283042908, 0.08528866618871689, 0.08035199344158173, 0.0778198316693306, 0.0790090262889862, 0.07109544426202774, 0.08021677285432816, 0.07963336259126663, 0.07389242202043533, 0.07262151688337326, 0.07381047308444977, 0.07322195172309875, 0.070614293217659, 0.07269728183746338, 0.07458502799272537, 0.06932618468999863, 0.06918540596961975, 0.07253909856081009, 0.0734696164727211, 0.0732596218585968, 0.07251419872045517, 0.07047849148511887, 0.06756401062011719, 0.07080309092998505, 0.06895892322063446, 0.06874607503414154, 0.07162421196699142, 0.07299972325563431, 0.07525952160358429, 0.07648652046918869, 0.074337437748909, 0.0711865946650505, 0.07401550561189651, 0.07218695431947708, 0.07481038570404053, 0.07069604843854904, 0.06942964345216751, 0.07211629301309586, 0.07237602770328522, 0.07756780833005905, 0.07327234745025635, 0.07867784053087234]\n",
      "\t- accuracy: [0.866683304309845, 0.9225999712944031, 0.9334333539009094, 0.9399833083152771, 0.9437500238418579, 0.9465833306312561, 0.9477499723434448, 0.948366641998291, 0.9520333409309387, 0.9534666538238525, 0.9545000195503235, 0.9548166394233704, 0.9563666582107544, 0.9567333459854126, 0.9582499861717224, 0.9591666460037231, 0.9579333066940308, 0.959933340549469, 0.9603000283241272, 0.9613333344459534, 0.9613166451454163, 0.9621833562850952, 0.962149977684021, 0.9617166519165039, 0.9625166654586792, 0.9641833305358887, 0.9634333252906799, 0.9637666940689087, 0.9638333320617676, 0.9642999768257141, 0.9654333591461182, 0.9660500288009644, 0.9650999903678894, 0.9658833146095276, 0.9660333395004272, 0.9648333191871643, 0.965416669845581, 0.9662500023841858, 0.965316653251648, 0.9667333364486694, 0.9669833183288574, 0.9673833250999451, 0.9677166938781738, 0.9680333137512207, 0.9678000211715698, 0.9683499932289124, 0.9675833582878113, 0.9679833054542542, 0.9692000150680542, 0.9693666696548462]\n",
      "\t- val_accuracy: [0.9570000171661377, 0.9634000062942505, 0.97079998254776, 0.9693999886512756, 0.973800003528595, 0.974399983882904, 0.9757999777793884, 0.9782000184059143, 0.9761999845504761, 0.977400004863739, 0.9801999926567078, 0.9797999858856201, 0.9797999858856201, 0.9789999723434448, 0.9783999919891357, 0.977400004863739, 0.9807999730110168, 0.9814000129699707, 0.9815999865531921, 0.9796000123023987, 0.9829999804496765, 0.9805999994277954, 0.9782000184059143, 0.9801999926567078, 0.9789999723434448, 0.9789999723434448, 0.9793999791145325, 0.9793999791145325, 0.9810000061988831, 0.980400025844574, 0.9819999933242798, 0.9775999784469604, 0.9815999865531921, 0.9807999730110168, 0.9797999858856201, 0.9793999791145325, 0.9810000061988831, 0.9801999926567078, 0.9807999730110168, 0.9800000190734863, 0.9801999926567078, 0.9800000190734863, 0.9805999994277954, 0.982200026512146, 0.9805999994277954, 0.9801999926567078, 0.9793999791145325, 0.9797999858856201, 0.9810000061988831, 0.9807999730110168]\n",
      "\t- num_parameters: 0\n",
      "\t- num_parameters_train: 111146\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "# We launch the Ray run-time depending of the detected local ressources\n",
    "# and execute the `run` function with the default configuration\n",
    "# WARNING: in the case of GPUs it is important to follow this scheme\n",
    "# to avoid multiple processes (Ray workers vs current process) to lock\n",
    "# the same GPU.\n",
    "if is_gpu_available:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=n_gpus, num_gpus=n_gpus, log_to_driver=False)\n",
    "\n",
    "    run_default = ray.remote(num_cpus=1, num_gpus=1)(run)\n",
    "    out = ray.get(run_default.remote(problem.default_configuration))\n",
    "else:\n",
    "    if not(ray.is_initialized()):\n",
    "        ray.init(num_cpus=1, log_to_driver=False)\n",
    "    run_default = run\n",
    "    out = run_default(problem.default_configuration)\n",
    "\n",
    "objective_default = out[\"objective\"]\n",
    "metadata_default = out[\"metadata\"]\n",
    "\n",
    "print(f\"Accuracy Default Configuration:  {objective_default:.3f}\")\n",
    "\n",
    "print(\"Metadata Default Configuration\")\n",
    "for k,v in out[\"metadata\"].items():\n",
    "    print(f\"\\t- {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new evaluator with 1 worker and config: {'num_cpus': 1, 'num_cpus_per_task': 1, 'callbacks': [<deephyper.evaluator.callback.TqdmCallback object at 0x38269ea70>]}\n"
     ]
    }
   ],
   "source": [
    "from deephyper.evaluator import Evaluator\n",
    "from deephyper.evaluator.callback import TqdmCallback\n",
    "\n",
    "def get_evaluator(run_function):\n",
    "    # Default arguments for Ray: 1 worker and 1 worker per evaluation\n",
    "    method_kwargs = {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"callbacks\": [TqdmCallback()]\n",
    "    }\n",
    "\n",
    "    # If GPU devices are detected then it will create 'n_gpus' workers\n",
    "    # and use 1 worker for each evaluation\n",
    "    if is_gpu_available:\n",
    "        method_kwargs[\"num_cpus\"] = n_gpus\n",
    "        method_kwargs[\"num_gpus\"] = n_gpus\n",
    "        method_kwargs[\"num_cpus_per_task\"] = 1\n",
    "        method_kwargs[\"num_gpus_per_task\"] = 1\n",
    "\n",
    "    evaluator = Evaluator.create(\n",
    "        run_function,\n",
    "        method=\"ray\",\n",
    "        method_kwargs=method_kwargs\n",
    "    )\n",
    "    print(f\"Created new evaluator with {evaluator.num_workers} worker{'s' if evaluator.num_workers > 1 else ''} and config: {method_kwargs}\", )\n",
    "\n",
    "    return evaluator\n",
    "evaluator_1 = get_evaluator(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator.create(\n",
    "    run,\n",
    "    method=\"ray\",\n",
    "\n",
    "    method_kwargs={\n",
    "        \"address\": \"auto\",\n",
    "        \"num_cpus\": n_gpus,\n",
    "        \"num_gpus\": n_gpus,\n",
    "        \"num_cpus_per_task\": 1,\n",
    "        \"num_gpus_per_task\": 1,\n",
    "        \"num_workers\": 3,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deephyper.search.hps import CBO\n",
    "search = CBO(\n",
    "    problem,\n",
    "    evaluator_1,\n",
    "    initial_points=[problem.default_configuration]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot convert a Tensor of dtype variant to a NumPy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/deephyper/search/_search.py:159\u001b[0m, in \u001b[0;36mSearch.search\u001b[0;34m(self, max_evals, timeout, max_evals_strict)\u001b[0m\n\u001b[1;32m    156\u001b[0m             cb\u001b[38;5;241m.\u001b[39mset_max_evals(max_evals)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SearchTerminationError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# Collect remaining jobs\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_evals_strict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, MaximumJobsSpawnReached):\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/deephyper/search/hps/_cbo.py:424\u001b[0m, in \u001b[0;36mCBO._search\u001b[0;34m(self, max_evals, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGathering jobs...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    423\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 424\u001b[0m new_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_results, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    426\u001b[0m     local_results, other_results \u001b[38;5;241m=\u001b[39m new_results\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/deephyper/evaluator/_evaluator.py:343\u001b[0m, in \u001b[0;36mEvaluator.gather\u001b[0;34m(self, type, size)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloop\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_at_least_n_tasks(size))\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_done:\n\u001b[0;32m--> 343\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_done(job)\n\u001b[1;32m    345\u001b[0m     local_results\u001b[38;5;241m.\u001b[39mappend(job)\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/deephyper/evaluator/_evaluator.py:281\u001b[0m, in \u001b[0;36mEvaluator._execute\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, job):\n\u001b[0;32m--> 281\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(job)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(job\u001b[38;5;241m.\u001b[39moutput, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    285\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe output of the job is not standard. Check if `job.set_output(output) was correctly used when defining the Evaluator class.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/deephyper/evaluator/_ray.py:116\u001b[0m, in \u001b[0;36mRayEvaluator.execute\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, job: Job) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Job:\n\u001b[1;32m    114\u001b[0m     running_job \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mcreate_running_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopper)\n\u001b[0;32m--> 116\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote_run_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrunning_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_function_kwargs\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     job\u001b[38;5;241m.\u001b[39mset_output(output)\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m job\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/remote_function.py:139\u001b[0m, in \u001b[0;36mRemoteFunction.__init__.<locals>._remote_proxy\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remote_proxy\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remote\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_default_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mauto_init_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     20\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/util/tracing/tracing_helper.py:310\u001b[0m, in \u001b[0;36m_tracing_task_invocation.<locals>._invocation_remote_span\u001b[0;34m(self, args, kwargs, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ray_trace_ctx\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n\u001b[1;32m    313\u001b[0m tracer \u001b[38;5;241m=\u001b[39m _opentelemetry\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mget_tracer(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/remote_function.py:304\u001b[0m, in \u001b[0;36mRemoteFunction._remote\u001b[0;34m(self, args, kwargs, **task_options)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_descriptor \u001b[38;5;241m=\u001b[39m PythonFunctionDescriptor\u001b[38;5;241m.\u001b[39mfrom_function(\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_uuid\n\u001b[1;32m    294\u001b[0m )\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# There is an interesting question here. If the remote function is\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# used by a subsequent driver (in the same script), should the\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# second driver pickle the function again? If yes, then the remote\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# first driver. This is an argument for repickling the function,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# which we do here.\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickled_function \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_dumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCould not serialize the function \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepr\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_export_cluster_and_job \u001b[38;5;241m=\u001b[39m worker\u001b[38;5;241m.\u001b[39mcurrent_cluster_and_job\n\u001b[1;32m    310\u001b[0m worker\u001b[38;5;241m.\u001b[39mfunction_actor_manager\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/_private/serialization.py:67\u001b[0m, in \u001b[0;36mpickle_dumps\u001b[0;34m(obj, error_msg)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrap cloudpickle.dumps to provide better error message\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mwhen the object is not serializable.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     69\u001b[0m     sio \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mStringIO()\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/cloudpickle/cloudpickle.py:1479\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m   1478\u001b[0m     cp \u001b[38;5;241m=\u001b[39m Pickler(file, protocol\u001b[38;5;241m=\u001b[39mprotocol, buffer_callback\u001b[38;5;241m=\u001b[39mbuffer_callback)\n\u001b[0;32m-> 1479\u001b[0m     \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/ray/cloudpickle/cloudpickle.py:1245\u001b[0m, in \u001b[0;36mPickler.dump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(e\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecursion\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1085\u001b[0m, in \u001b[0;36m_EagerTensorBase.__reduce__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1085\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_tensor, (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,)\n",
      "File \u001b[0;32m~/miniconda3/envs/ornl_env/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1128\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1126\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numpy_internal()\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1128\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot convert a Tensor of dtype variant to a NumPy array."
     ]
    }
   ],
   "source": [
    "results = search.search(max_evals=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b1/89wsk5t517v75qvdm2x4ygwc0000gn/T/ipykernel_9213/3944348463.py\", line 14, in <module>\n",
      "    model.fit(X_train_normal, Y_train, epochs=5)\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/var/folders/b1/89wsk5t517v75qvdm2x4ygwc0000gn/T/__autograph_generated_filezsp_59h1.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/training.py\", line 993, in train_step\n",
      "        y_pred = self(x, training=True)\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n",
      "        raise ValueError(\n",
      "\n",
      "    ValueError: Input 0 of layer \"sequential_13\" is incompatible with the layer: expected shape=(None, 784), found shape=(32, 28, 28)\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 89, in get_style_by_name\n",
      "    mod = __import__('pygments.styles.' + mod, None, None, [cls])\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1133, in get_records\n",
      "    style = get_style_by_name(self._tb_highlight_style)\n",
      "  File \"/Users/victorsu-ortiz/opt/anaconda3/envs/myenv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 91, in get_style_by_name\n",
      "    raise ClassNotFound(\"Could not find style module %r\" % mod +\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(64, activation='sigmoid'),\n",
    "    keras.layers.Dense(32, activation='sigmoid'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train_normal, Y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 455us/step - loss: 0.2524 - accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25240427255630493, 0.9265999794006348]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flat, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = tf.keras.layers.Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4983 - accuracy: 0.4542 - val_loss: 1.3734 - val_accuracy: 0.5285\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1482 - accuracy: 0.5930 - val_loss: 1.2032 - val_accuracy: 0.5726\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9954 - accuracy: 0.6498 - val_loss: 0.9850 - val_accuracy: 0.6492\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.8893 - accuracy: 0.6873 - val_loss: 0.9504 - val_accuracy: 0.6744\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.8175 - accuracy: 0.7149 - val_loss: 0.9077 - val_accuracy: 0.6829\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.7612 - accuracy: 0.7326 - val_loss: 0.8939 - val_accuracy: 0.6908\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7090 - accuracy: 0.7518 - val_loss: 0.8686 - val_accuracy: 0.7052\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6623 - accuracy: 0.7665 - val_loss: 0.8366 - val_accuracy: 0.7132\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6238 - accuracy: 0.7804 - val_loss: 0.9436 - val_accuracy: 0.6886\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5882 - accuracy: 0.7923 - val_loss: 0.9014 - val_accuracy: 0.7039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feda8fae6b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(32)\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ornl_env)",
   "language": "python",
   "name": "jupyter_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
